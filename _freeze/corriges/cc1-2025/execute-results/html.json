{
  "hash": "5e38d5eccc05c05a93176b6e2178783c",
  "result": {
    "engine": "knitr",
    "markdown": "---\n#title: \"Exercices : semaine IV\"\n# subtitle: \"M1 ISIFAR MA1AY010\"\n\n# date: \"2025-09-08\"\n\nformat:\n  pdf:\n    output-file: cc1-2025.pdf\n    include-in-header:\n      - file: before_header_td.tex\n      - text: |\n          \\copypagestyle{style-td1}{mystyle}\n          \\makeevenhead{style-td1}{\\sffamily\\small Probabilités et Extrêmes}{}{\\sffamily\\small CC I}\n          \\makeoddhead{style-td1}{\\sffamily\\small Probabilités et Extrêmes}{}{\\sffamily\\small CC I}\n          \\pagestyle{style-td1}\n\n\n\n\nengine: knitr\ndraft: true\n---\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n\n::: {.callout-note}\n\n### CC I  :    \n\n- 7 Octobre 2025\n\n- Master I ISIFAR\n\n- Durée : 1 heure 30 \n\n- **Probabilités** \n\n:::\n\n\n::: {.callout-caution}\n\n- Aide-mémoire : une feuille A4 recto verso autorisée\n- Aucun autre document autorisé\n- Aucun moyen de communication électronique autorisé\n\n:::\n\n\n::: {#exr-   name=\"\"} \n\n:::\n\n\n\n<!-- Fonctions génératrices -->\n\n<!-- Grimmet et Striztacker p. 175 -->\n\nSoit  $X$ une variable binomiale à paramètres $n$ (fixé) et $V$ aléatoire  uniformément distribué sur $[0,1]$  ($X \\sim  \\text{Binom}(n, V)$). \n\ni. Calculer la fonction génératrice des probabilités de la loi de $X$ \ni. Quelle est l'espérance de $X$ ?\ni. Que vaut $P\\{X = k\\}$ pour $k \\in \\{0,n\\}$ ?\n\n\n::: {.content-visible when-profile=\"solution\"}\n\n::: {.callout-note}\n\n### Solution \n\n(@) \n\n    On utilisera la fait que si $Y_i \\sim_{\\text{i.i.d.}} \\text{Berp}(p)$, alors $\\sum_{i=1}^n Y_i \\sim \\text{Binom}(n, p)$. La fonction génératrice de $\\text{Binom}(n, p)$ s'écrit donc \n\n    $$s \\mapsto  \\left(1-p + p s\\right)^n$$\n\n    et \n\n    $$\\mathbb{E} \\left[ s^{X} \\mid \\sigma(V) \\right] = \\left(1-p + p s\\right)^n$$\n\n\n    \\begin{align*}\n    G_X(s)  \n      & =\\mathbb{E} \\left[ s^{X} \\right] \\\\\n      & = \\mathbb{E} \\left[ \\mathbb{E} \\left[ s^{X} \\mid \\sigma(V) \\right]\\right] \\\\\n      & = \\mathbb{E} \\left[ \\left(1-V + Vs\\right)^n\\right] \\\\\n      & = \\int_{[0,1]} \\left(1-v + vs\\right)^n  \\mathrm{d}v \\\\\n      & = \\left[ \\frac{1}{(n+1)(s-1)}\\left(1-v + vs\\right)^{n+1}\\right]_0^1 \\\\\n      & = \\frac{s^{n+1} - 1}{(n+1)(s-1)} \\\\\n      & =  \\sum_{k=0}^n \\frac{1}{n+1} s^{k} \\, .\n    \\end{align*}\n\n    On reconnnaît la fonction génératrice des probabilités de la loi uniforme sur $\\{0, \\ldots, n\\}$\n\n(@) L'espérance coïncide avec la dérivée de $G_X$ en $1$. Elle vaut $\\frac{n}{2}$. \n\n(@) $P\\{X=k\\} = \\frac{G_X^{(k)}(0)}{k!} = \\frac{1}{n+1}$. \n\n\n\n\n\n:::\n\n:::\n\n::: {#exr-   name=\"\"} \n\n:::\n\n\n\n<!-- Variation sur les processus de branchements -->\n\nOn se donne un processus de branchement avec une distribution de reproduction Poissonienne de paramètre $\\mu>0$. On note $Z_0=1, Z_1, \\ldots$ les effectifs des différentes générations.  \n\ni. Calculer la fonction génératrice de la loi de $Z_2$\ni. Quelle est la probabilité que l'extinction ait lieu exactement à la génération $2$? \ni. Quelle est la probabilité que que l'extinction ait lieu exactement à la génération $n$? \n\n::: {.content-visible when-profile=\"solution\"}\n\n::: {.callout-note}\n\n### Solution \n\n(@)  On  $G_\\mu$ la fonction génératrice des probabilités de $\\text{Poisson}(\\mu)$, $G_n$ la fonction génératrice des probabilités de la loi de $Z_n$. \n\n    $$G_n = \\underbrace{G_\\mu \\circ G_\\mu \\circ \\ldots \\circ G_\\mu}_{n \\text{ fois}}$$\n\n    avec \n\n    $$G_\\mu(s) =  \\exp(\\mu(s-1))$$\n\n(@) \n\n    $$P\\left\\{ \\text{Extinction à la génération } 2\\right\\} = P\\left\\{ Z_2=0 \\vee Z_1 >0 \\right\\} = P\\left\\{ Z_2=0 \\right\\} - P\\left\\{ Z_1 =0 \\right\\}$$\n\n    $$P\\left\\{ \\text{Extinction à la génération } 2\\right\\} = G_2(0) - G_1(0)$$\n\n    \\begin{align*}\n      P\\left\\{ \\text{Extinction exactement à la génération } 2\\right\\}\n      & = \\exp(-\\mu(1-\\exp(-\\mu))) - \\exp(-\\mu) \\\\\n      & = \\exp(-\\mu) \\left( \\exp\\left(\\exp(-\\mu)\\right)-1\\right)\n    \\end{align*}\n\n(@) \n\n    \n    \\begin{align*}\n    P\\left\\{ \\text{Extinction exactement à la génération } n\\right\\} \n      & = P\\left\\{ Z_n=0 \\vee Z_{n-1} >0 \\right\\} \\\\\n      & = P\\left\\{ Z_n=0 \\right\\} - P\\left\\{ Z_{n-1} =0 \\right\\}\n    \\end{align*}\n\n\n    $$P\\left\\{ \\text{Extinction exactementà la génération } n\\right\\} = G_n(0) - G_{n-1}(0)$$\n\n    \\begin{align*}\n      & P\\left\\{ \\text{Extinction exactement à la génération } n\\right\\} \\\\\n      & = \\underbrace{G_\\mu \\circ G_\\mu \\circ \\ldots \\circ G_\\mu}_{n \\text{ fois}} (0) \n      - \\underbrace{G_\\mu \\circ G_\\mu \\circ \\ldots \\circ G_\\mu}_{n-1 \\text{ fois}} (0) \\\\\n      & = ...\n    \\end{align*}\n:::\n\n\n\n::: {.callout-caution  title=\"Solution Chat-GPT 3.5\"}\n\nOn a un processus de Galton–Watson avec loi de reproduction $\\mathrm{Poisson}(\\mu)$. Notons la fonction génératrice de la loi des descendants\n$$\nf(s)=\\mathbb{E}[s^{\\xi}]=\\exp\\big(\\mu(s-1)\\big),\n$$\noù $\\xi\\sim\\mathrm{Poisson}(\\mu)$.\n\ni) Fonction génératrice de $Z_2$\n\nLa fonction génératrice de $Z_n$ est la $n^{\\text{ième}}$ composition de $f$ avec elle-même, donc pour $n=2$\n\n$$\nG_{Z_2}(s)=f\\big(f(s)\\big)\n=\\exp\\Big(\\mu\\big(\\exp(\\mu(s-1))-1\\big)\\Big).\n$$\n\nii) Probabilité que l'extinction ait lieu *exactement* à la génération (2)\n\nL'évènement «extinction exactement à la génération 2» est ${Z_1>0  \\text{ et } Z_2=0}$. On peut écrire\n$$\n\\mathbb{P}(Z_2=0,Z_1>0)=\\mathbb{P}(Z_2=0)-\\mathbb{P}(Z_1=0).\n$$\n\nOr \n\n$$\n\\mathbb{P}(Z_1=0)=f(0)=e^{-\\mu}) et (\\mathbb{P}(Z_2=0)=G_{Z_2}(0)=f(f(0))=\\exp!\\big(\\mu(e^{-\\mu}-1)\\big).\n$$\nDonc\n$$\n\\boxed{\\mathbb{P}(\\text{extinction exactement en 2})=\\exp!\\big(\\mu(e^{-\\mu}-1)\\big)-e^{-\\mu}}\n$$\n\nOn peut obtenir la même formule en conditionnant sur $Z_1=k$ et sommant \n$$\\sum_{k\\ge1}\\mathbb{P}(Z_1=k) \\times e^{-\\mu k})$$\n\n:::\n:::\n\n::: {#exr-   name=\"\"} \n\n:::\n\n\n\n<!-- Lois image. Formule de transfert -->\n\nSoit $X \\sim \\mathrm{U}(-\\pi/2,\\pi/2)$ (loi uniforme sur $[-\\pi/2,\\pi/2]$), on définit $Y =\\cos(X)$.\n\ni. La loi de $Y$ est-elle absolument continue?\ni. Si oui, déterminer une version de sa densité.\n\n::: {.content-visible when-profile=\"solution\"}\n\n::: {.callout-note}\n\n### Solution \n\n(@)\n\n    Sur $[-\\pi/2,\\pi/2]$, $\\cos$ croit de $0$ à $1$ puis décroit de $1$ à $0$. La fonction $\\cos$ est paire. \n\n    Pour $x \\in [0,1]$\n\n    $$P \\left\\{ \\cos(U) \\leq x \\right\\} \n    = 2 \\times P \\left\\{ \\arccos(x) \\leq U \\leq \\frac{\\pi}{2}\\right\\} = 1 - \\frac{2\\arccos(x)}{\\pi}$$\n\n    La fonction de répartition est continue, dérivable et elle égale à l'intégrale de sa dérivée qui s'annule en $0$. La loi de $Y$ est donc absolument continue, à support  $[0,1]$.\n\n    \n\n(@)\n    Une version continue de la densité est obtnue en dérivant la fonction de répartition:\n\n    $$x \\mapsto \\frac{2}{\\pi \\sin(\\arccos(x))} = \\frac{2}{\\pi \\sqrt{1-x^2}}$$ \n\n    pour $x\\in [0,1]$ \n    \n:::\n\n::: {.callout-caution title=\"Solution Chat-GPT 3.5\"}\n\nLa loi  de $Y$ est absolument continue (sans atome) et on peut donner explicitement sa densité.\n\nRemarquons d'abord que $\\cos$ envoie l'intervalle $[-\\pi/2,\\pi/2]$ sur $[0,1]$. Pour $y\\in(0,1)$ les équations $\\cos x=y$ ont exactement deux solutions dans $[-\\pi/2,\\pi/2]$, à savoir $x_1=\\arccos y$ et $x_2=-\\arccos y$. La densité de (la loi de ) $X$ est $f_X(x)=\\dfrac{1}{\\pi}$ sur $[-\\pi/2,\\pi/2]$.\n\nEn utilisant la formule de changement de variable pour fonctions non monotones :\n$$\nf_Y(y)=\\sum_{x:\\cos x=y}\\frac{f_X(x)}{|(\\cos)'(x)|}\n=\\frac{1}{\\pi}\\left(\\frac{1}{|,-\\sin(\\arccos y),|}+\\frac{1}{|,-\\sin(-\\arccos y),|}\\right).\n$$\nOr $\\sin(\\arccos y)|=\\sqrt{1-y^2}$ et les deux termes sont égaux, d'où pour $y\\in(0,1)$\n$$\n\\boxed{,f_Y(y)=\\frac{2}{\\pi\\sqrt{1-y^2}},.}\n$$\nEnfin $f_Y(y)=0$ pour $y\\notin[0,1]$. (Les points $y=0$ et $y=1$ n'ont pas d'atome : la densité diverge en $0$ et $1$ mais ces points ont probabilité nulle.)\n\n\n:::\n\n::: {.callout-caution  title=\"Critique de Chat-GPT 3.5\"}\n\nLa propriété *absolue continuité* n'est pas équivalente à  la propriété *être sans atome* (*diffuse*). \nLa ou plutôt les lois de Cantor sont des exemples de lois sans atomes qui ne sont pas absolument continues.\n\nLa *formule de changement de variable pour fonctions non monotones* est vaseuse, on ne sait pas d'où elle sort, ni quel est son domaine d'application.\n\nLa discussion sur la divergence de la densité à la fin est elle aussi vaseuse. \n\n:::\n\n\n:::\n\n::: {#exr-   name=\"\"} \n\n:::\n\n\n\n\nSoit $X_1, \\ldots, X_n, \\ldots$ des variables aléatoires distribuées indépendamment selon une\nloi de Pareto de paramètre $\\alpha>0$, $P\\{ X_1\\geq t \\} =  t^{-\\alpha}, t \\geq 1$. \nSoit $N$ indépendante des $X_i$, distribuée selon une loi de Poisson de paramètre $\\mu>0.$ On définit $Z$ par $Z = \\max_{i \\leq N} X_i$.\n\n*Remarque:* Si $N=0$, on convient de $\\max_{i\\leq N} X_i = 0$. \n\ni. Calculer la fonction de répartition de la loi de $Z$.\ni. La loi de $Z$ possède-t-elle une espérance finie?  \n\n::: {.content-visible when-profile=\"solution\"}\n\n::: {.callout-note}\n\n### Solution \n\n(@)\n\n    On note $F_{\\alpha}(x) = 1 - t^{-\\alpha}$  pour $t>1$, $0$ sinon.\n\n    Pour $x> 1$, on a \n    \\begin{align*}\n      F_Z(x) \n        & = P\\left\\{Z \\leq x\\right\\} \\\\\n        & = \\mathbb{E}\\left[ \\mathbb{I}_{Z \\leq x}\\right] \\\\\n        & = \\mathbb{E}\\left[ \\mathbb{E}\\left[ \\prod_{i=1}^N \\mathbb{I}_{X_i \\leq x}\\mid  \\sigma(N)\\right]\\right] \\\\\n        & = \\mathbb{E}\\left[ \\prod_{i=1}^N  \\mathbb{E}\\left[ \\mathbb{I}_{X_i \\leq x} \\right] \\right] \\\\\n        & = \\mathbb{E}\\left[ (1-x^{-\\alpha})^N  \\right] \\\\\n        & = \\exp\\left(\\mu \\left(1-x^{-\\alpha} -1\\right)\\right) \\\\\n        & = \\exp\\left(- \\mu x^{-\\alpha} \\right)\n    \\end{align*}\n\n    Par ailleurs, pour $x\\in [0,1]$, $F_Z(x) = P \\{ N=0\\} = \\exp(-\\mu) = \\lim_{x \\downarrow 1} F_Z(x)$ \n\n(@)  \n    $Z$ est positive, son espérance est bien définie et donnée par \n\n    $$\\mathbb{E}Z = \\int_0^\\infty (1 -F_Z(t)) \\mathrm{d}t$$\n\n    \\begin{align*}\n       \\int_0^\\infty (1 -F_Z(x)) \\mathrm{d}x \n          & =  (1- \\exp(-\\mu)) + \\int_1^\\infty \\left( 1-  \\exp\\left(- \\mu x^{-\\alpha} \\right)\\right)\\mathrm{d}x\n    \\end{align*}\n\n    Si $\\alpha > 1$, en utilisant $1-\\exp(-x)\\leq x$ oon vérifie que l'intégrale à droite est finie. L'espérance de $Z$ est finie\n\n    Si $\\alpha\\leq 1$, l'intégrale est divergente, $\\mathbb{E}Z$ est infinie ($Z$ n'est pas intégrable).\n\n:::\n\n::: {.callout-caution title=\"Solution Chat-GPT 3.5\"}\n\n\nRappel : $N\\sim\\mathrm{Poisson}(\\mu)$ indépendant des $X_i$, et pour tout $t\\ge 1$\n$P(X_1\\ge t)=t^{-\\alpha}$, donc $P(X_1\\le t)=1-t^{-\\alpha}$.\n\ni) Fonction de répartition de $Z=\\max_{1\\le i\\le N} X_i$ (avec convention $\\max_{i\\le0}X_i=0$)\n\nPour $t<0$ on a évidemment $F_Z(t)=0$.\nPour $0\\le t<1$ tous les $X_i$ valent $\\ge1$, donc ${Z\\le t}={N=0}$ et\n$$\nF_Z(t)=P(Z\\le t)=P(N=0)=e^{-\\mu}.\n$$\nPour $t\\ge1$, conditionnons sur $N$ :\n$$\nP(Z\\le t)=\\sum_{k=0}^{\\infty}P(N=k) \\times P\\big(\\max_{1\\le i\\le k}X_i\\le t\\big)\n=\\sum_{k=0}^{\\infty} e^{-\\mu}\\frac{\\mu^k}{k!}\\big(1-t^{-\\alpha}\\big)^k.\n$$\nLa somme donne une exponentielle :\n$$\nF_Z(t)=e^{-\\mu}\\exp!\\big(\\mu(1-t^{-\\alpha})\\big)=\\exp\\big(-\\mu t^{-\\alpha}\\big),\\qquad t\\ge1.\n$$\n\nAinsi, de façon compacte (et continue en (t=1)) :\n$$\n\\boxed{F_Z(t)=\\begin{cases}\n0 & t<0\\\\ \ne^{-\\mu} & 0\\le t<1 \\\\\n\\exp\\big(-\\mu t^{-\\alpha}\\big) & t\\ge1.\n\\end{cases}}\n$$\n\nii) Existence (ou non) de l'espérance de $Z$\n\nUtilisons la formule $E[Z]=\\int_{0}^{\\infty}P(Z>t) dt$. Avec la CDF ci-dessus :\n\n$$\n\\mathbb{E}[Z]=\\int_0^1\\big(1-e^{-\\mu}\\big) dt+\\int_1^{\\infty}\\big(1-e^{-\\mu t^{-\\alpha}}\\big) dt\n=1-e^{-\\mu}+\\int_1^{\\infty}\\big(1-e^{-\\mu t^{-\\alpha}}\\big) dt.\n$$\n\nPour étudier la convergence de la seconde intégrale, posons $u=t^{-\\alpha}$ (donc pour $t\\in[1,\\infty)$, $u\\in(0,1])$. On obtient\n$$\n\\int_1^{\\infty}\\big(1-e^{-\\mu t^{-\\alpha}}\\big) dt\n=\\frac{1}{\\alpha}\\int_0^1\\big(1-e^{-\\mu u}\\big)u^{-1/\\alpha-1} du.\n$$\nQuand $u\\to0^+$, $1-e^{-\\mu u}\\sim\\mu u$, donc l'intégrande se comporte comme une constante fois $u^{-1/\\alpha}$. L'intégrale $\\int_0 u^{-1/\\alpha} du$ converge près de $0$ si et seulement si $-1/\\alpha>-1$, i.e. si et seulement si $\\alpha>1$.\n\nConclusion :\n$$\n\\boxed{\\text{E}[Z]<\\infty\\ \\Longleftrightarrow\\ \\alpha>1.}\n$$\n\nSi $\\alpha>1$, une expression utile est\n$$\n\\boxed{\\mathbb{E}[Z]=1-e^{-\\mu}+\\frac{1}{\\alpha}\\int_0^1\\big(1-e^{-\\mu u}\\big)u^{-1/\\alpha-1},du.}\n$$\n(Autrement dit l'espérance est finie pour $\\alpha>1$ et infinie pour $\\alpha\\le1$.)\n\n\n\n:::\n\n\n::: {#exr-   name=\"\"} \n\n:::\n\n\n\n<!-- Transformation,  -->\n\nLe couple aléatoire $(X,Y)$ à valeur sur $]0,\\infty)^2$ admet pour densité $f$. \n\ni. Si elle existe, quelle est la densité de la loi de $XY$ (une expression intégrale peut suffire) ? \ni. Préciser la densité lorsque $X, Y$ sont indépendantes et uniformément distribuées sur $[0,1]$\n\n\n::: {.content-visible when-profile=\"solution\"}\n\n::: {.callout-note}\n\n### Solution \n\ni. La transformation $]0, \\infty)^2 \\to ]0, \\infty)^2$, $\\begin{pmatrix} x \\\\ y \\end{pmatrix}\\mapsto \\begin{pmatrix} x \\\\ xy \\end{pmatrix}$ est bijective, continuement différentiable, de matrice Jacobienne $\\begin{pmatrix} 1 & 0 \\\\ y & x \\end{pmatrix}$ partout inversible et de déterminant Jacobien $x$. \n\n    La loi de $\\begin{pmatrix} X \\\\ XY \\end{pmatrix}$ admet une densité sur $]0,\\infty)^2$ :\n\n    $$\\begin{pmatrix} u \\\\ v \\end{pmatrix}  \\mapsto \\frac{f(u, v/u)}{u}$$\n\n    La densité de la loi de $XY$ sur $]0,\\infty)$ en $v$ est obtenue en intégrant:\n\n    $$\\int_{]0,\\infty)} \\frac{1}{u} f(u, v/u) \\mathrm{d}u$$\n\nii. Dans cette configuration $f(x,y) = \\mathbb{I}_{0<x< 1}\\mathbb{I}_{0<y< 1}$. Pour $v \\in (0,\\infty)$ \n\n    \\begin{align*}\n    \\int_{]0,\\infty)} \\frac{1}{u} f(u, v/u) \\mathrm{d}u\n      & = \\int_{]0,\\infty)} \\mathbb{I}_{0<u< 1}\\mathbb{I}_{0<v/u< 1}\\frac{1}{u}  \\mathrm{d}u \\\\\n      & = \\int_v^ 1 \\frac{1}{u}\\mathrm{d}u \\\\\n      & = \\ln \\frac{1}{v} \\, .\n    \\end{align*}\n\n    La fonction de répartition associée est $v \\mapsto v - v \\ln v.$\n\n:::\n\n:::",
    "supporting": [
      "cc1-2025_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}