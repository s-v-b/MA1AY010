{
  "hash": "257252e701725b35b4444a29fa9b7eb7",
  "result": {
    "engine": "knitr",
    "markdown": "---\n#title: \"Exercices : semaine IV\"\n# subtitle: \"M1 ISIFAR MA1AY010\"\n\n# date: \"2025-09-08\"\n\nformat:\n  pdf:\n    output-file: td4.pdf\n    class: exam\n    include-in-header:\n      - text: \"\\\\lhead{{\\\\sf  Probabilités \\\\\\\\ TD IV}}\"\n  html:\n    output-file: td4.html\n\nengine: knitr\ndraft: false\n---\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {.callout-note}\n\n### TD IV : Espérance conditionnelle/Catactérisations   \n\n- 29 Septembre 2025-2 octobre 2025\n\n- Master I ISIFAR\n\n- **Probabilités** \n\n:::\n\n\n\n\n::: {.callout-note}\n\n### Conventions \n\nDans les 3 exercices qui suivent, $X_1, \\ldots, X_n, ...$ constituent une famille indépendante\nde variables aléatoires identiquement distribuées à valeur dans $\\{-1,1\\}$.\n\nL'univers des possibles est $\\Omega = \\{-1,1\\}^{\\mathbb{N}}$. Les $X_i$ sont les projections\ncanoniques.\n\nOn note $\\mathcal{F}_n$ la tribu engendrée par les $n$ premières coordonnées :\n\n$$\n\\mathcal{F}_n =  \\sigma(X_1, \\ldots, X_n) \\,\n$$\n\nL'univers est muni de la tribu des cylindres $\\mathcal{F} = \\sigma\\left(\\bigcup_n \\mathcal{F}_n\\right)$.\n\nOn note $\\Delta$ une constante à valeur dans $(0,1)$ (la *dérive* de la marche aléatoire).\n\nOn note $\\mathbb{P}$ la loi produit infini, telle que pour tout $x \\in \\{-1, 1\\}^n$\n\n$$\n\\mathbb{P}\\left\\{\\bigwedge_{i=1}^n X_i = x_i\\right\\} = \\prod_{i=1}^n \\frac{1}{2}\\left(1 + x_i \\Delta\\right)\n$$\n\n\nOn étudie la marche alétoire sur $\\mathbb{Z}$ de dérive $\\Delta$.\n\nOn note $S_n = \\sum_{i=1}^n X_i$.\n\nL'indice $n$ représente le temps, $S_n$ la position à l'instant $n$.\n\n:::\n\n\n### Exercice 1 (marches aléatoires biaisées i)\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\na. Quelle est la loi de $S_n$ ?\na. $S_n$ est-elle $\\mathcal{F}_n, \\mathcal{F}_{n-1}, \\mathcal{F}_{n+1}$ mesurable ?\na. Quelle est l'espérance de $S_n$ ?\na. Quelle est la variance de $S_n$ ?\n\n::: {.callout-note}\n\n### On admettra l'inégalité de Hoeffding:\n\nSi $Y_1, \\ldots, Y_n$ sont des variables aléatoires indépendantes telles que\n$a_i \\leq Y_i \\leq b_i$ (les $Y_i$ sont bornées), alors \n$$\nP \\left\\{  Z - \\mathbb{E} Z \\geq t  \\right\\} \\leq \\mathrm{e}^{- 2 \\frac{t^2}{\\sum_{i=1}^n (b_i-a_i)^2}}\n$$\navec $Z = \\sum_{i=1}^n Y_i$.\n\n:::\n\n\n\n\n\n### Exercice 2  (marches aléatoires biaisées ii)\n\n\n::: {.cell}\n\n:::\n\n\n\n\nPour $0 \\leq \\tau \\leq  n \\Delta$,\n\na. Majorer $\\mathbb{P}\\{ S_n \\leq \\tau \\}$ à l'aide de l'inégalité de Chebyshev\na. Majorer $\\mathbb{P}\\{ S_n \\leq \\tau \\}$ à l'aide de l'inégalité de Hoeffding\na. L'ensemble \n$$\nE = \\left\\{ \\omega :  \\forall n,  S_n(\\omega) < \\tau \\right\\}\n$$\nappartient-il à la tribu $\\mathcal{F}_m$ pour un $m$ donné ? est-il un événement de $\\mathcal{F}$ ?\na.  Si $E$ est  un événement, quelle est sa probabilité ?\n\n\n::: {.callout-note}\n\n### Convention\n\n\nOn suppose $\\tau \\in \\mathbb{N} ∖  \\{0\\}$.\n\nOn note $T = \\inf \\left\\{ n : S_n \\geq \\tau \\right\\}$. Si $\\forall n, \\quad S_n(\\omega)< \\tau$,\nalors $T(\\omega) = \\infty$.\n\nOn note $S_T$, la fonction définie par \n$$\nS_T(\\omega) = \\sum_{n=1}^\\infty \\mathbb{I}_{T(\\omega)=n} S_n(\\omega)\\qquad \\text{si } T(\\omega) < \\infty\n$$\net $S_T(\\omega) =0$ si $T(\\omega) =\\infty$.\n\n:::\n\n\n### Exercice 3 (marches aléatoires biaisées iii)\n\n\n::: {.cell}\n\n:::\n\n\n  \n\na. Pourquoi peut-on considérer que $T$ est une variable aléatoire (à valeur dans $\\mathbb{N} \\cup \\{\\infty\\}$) ?\na. Quelle est la probabilité que $T = \\infty$ ?\na. L'événement $\\{ T \\leq n \\}$ est-il $\\mathcal{F}_{n-1}, \\mathcal{F}_n, \\mathcal{F}_{n+1}$ mesurable ?\na. Pourquoi peut-on considérer que $S_T$ est une variable aléatoire ?\na. Quelle est l'espérance de $S_T$ ?\na. Montrer que $\\mathbb{E} S_T = \\Delta \\mathbb{E} T$ En déduire $\\mathbb{E} T$.\n\n\n### Exercice 4 \n\n\n::: {.cell}\n\n:::\n\n\n\nLes variables $X_1, X_2, \\ldots, X_n, \\ldots$ sont des variables de Bernoulli de probabilité\nde succès $p \\in (0,1)$, indépendantes. On définit $T_1 = \\min \\{i : X_i=1\\}$ (temps du premier succès), $T_1 = \\min \\{i : i > T_1, X_i=1\\}$ (temps du premier succès après $T_1$),\net récursivement $T_{n+1} = \\min \\{ i : i > T_n, X_i =1\\}$ (temps du $n+1$eme succès).\n\nOn admet l'existence d'un espace de probabilité $(\\Omega, \\mathcal{F}, P)$ où $\\Omega = \\{0,1\\}^{\\mathbb{N}}$, $\\mathcal{F}$ est\nune tribu pour laquelle les $X_i$ sont mesurables, et $P$ tel  que $X_1, \\ldots, X_n, \\ldots$ est une famille indépendante.\n\n\na. $T_1$ et plus généralement $T_n$ sont-elles des variables aléatoires?\na. Calculer $P \\{ T_1 > k  \\}$ pour $k \\in \\mathbb{N}$.\na. Calculer $P \\{ T_1 = k  \\}$ pour $k \\in \\mathbb{N}$\na. Calculer $\\mathbb{E}T_1$.\na. Calculer $P \\{ T_1 = k  \\wedge T_2 = k+j\\}$ pour $k, j \\in \\mathbb{N}$\na. Calculer $P \\{ T_2 = k  \\}$ pour $k \\in \\mathbb{N}$\na. Calculer $\\mathbb{E}T_2$\na. Calculer $\\mathbb{E} T_n$\n\n\n### Exercice 5 \n\n\n::: {.cell}\n\n:::\n\n\n\n\n\nOn dispose de $n$ urnes numérotées de $1$ à $n$ et de $n$ boules. Les boules sont réparties de manière uniforme dans les urnes (chaque boule se comporte de manière indépendante des autres et a probabilité $1/n$ de tomber dans chaque urne). On note $U_i$ la variable aléatoire désignant le nombre de boules qui tombent dans l'urne $i$. Soit $\\alpha >1$ un réel.\n\n\na. Déterminer la loi de $U_i$.\na. Montrer que l'on a :\n$$\\mathbb{P}( \\max_{1 \\leq i \\leq n} U_i > \\alpha \\log n) \\leq n \\mathbb{P}( U_1 > \\alpha \\log n).$$\na. Calculer $\\mathbb{E}(\\exp(U_1))$.\na. Montrer que pour tout $\\beta > -n$, on a $(1+\\beta/n)^n \\leq \\exp(\\beta)$. \na. Montrer que $\\mathbb{P}(U_1 > \\alpha \\log n) \\leq \\frac{\\exp(\\exp(\\alpha)-1)}{n^\\alpha}$.\na. En déduire que si $\\alpha >1$, on a $$\\mathbb{P}( \\max_{1 \\leq i \\leq n} U_i > \\alpha \\log n) \\rightarrow_{n \\rightarrow \\infty} 0.$$\n\n\n\n### Exercice 6  (Restitution Organisée de Connaissances)\n\n\n::: {.cell}\n\n:::\n\n\n\n\n- Soient $A, B, C$ trois événements dans un espace probabilisé. A-t-on  toujours: $A \\perp\\!\\!\\!\\perp B \\text{ et } B \\perp\\!\\!\\!\\perp C \\Rightarrow A \\perp\\!\\!\\!\\perp C$?\n- Soient $P$ et $Q$ deux lois de probabilités sur $(\\Omega, \\mathcal{F})$, on définit l'ensemble $\\mathcal{M} = \\big\\{ A : A \\in \\mathcal{F}, P(A)=Q(A)\\}$.  Répondre par *vrai/faux/je ne sais pas* aux questions suivantes:\n\n\n    a. $\\mathcal{M}$ est-il toujours une classe monotone ?\n    a. $\\mathcal{M}$ est-il toujours une $\\sigma$-algèbre ?\n    a. $\\mathcal{M}$ est-il toujours une $\\pi$-classe ?\n\n- Soient $G$ et $F$  sont deux fonctions génératrices de probabilité.   Répondre par *vrai/faux* aux questions suivantes:\n\n    a. Est-il vrai que $G \\times F$ est toujours une fonction génératrice ?\n    a. Est-il vrai que $G + F$ est toujours une fonction génératrice de probabilité ?\n    a. Est-il vrai que $\\lambda G + (1-\\lambda) F$ avec $\\lambda \\in [0,1]$ est toujours une fonction génératrice de probabilité ?\n\n\n- Si $\\widehat{F}$ est la fonction caractéristique de la loi de $X$, et si $\\epsilon \\perp\\!\\!\\!\\perp X$,\n  avec $P\\{\\epsilon=1\\}= P\\{\\epsilon=-1\\}=1/2$, quelle est la fonction caractéristique de la loi de $\\epsilon X$?\n\n\n### Exercice 7\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\nSi $X$ est une variable aléatoire positive intégrable, la version *biaisée par la taille* de  $X$ est la variable aléatoire $X^*$ dont la loi $Q$ est absolument continue par rapport à celle de $X$ (notée $P$) et dont la densité (par rapport à celle de $X$)\nest proportionnelle à $X$: \n$$\n\\frac{\\mathrm{d}Q}{\\mathrm{d}P}(x) = \\frac{x}{\\mathbb{E}X} \\, .\n$$\n\na. Caractériser $X^*$ lorsque $X$ est une Bernoulli.\na. Caractériser $X^*$ lorsque $X$ est binomiale.\na. Caractériser $X^*$ lorsque $X$ est Poisson.\na. Caractériser $X^*$ lorsque $X$ est Gamma.\na. Si $X$ est à valeurs entières, exprimer la fonction génératrice de $X^*$ en fonction de celle de $X$.\na. Exprimer la transformée de Laplace de $X^*$ en fonction de celle de $X$.\na. Si $U$ est une transformée de Laplace, dérivable à droite en $0$, $U'/U'(0)$ est-elle la\ntransformée de Laplace d'une loi sur $[0, \\infty)$?\n\n\n### Exercice 8\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {.callout-note}\n\n### Rappel\n\nLa loi normale centrée réduite $\\mathcal{N}(0,1)$ admet pour densité $x\\mapsto \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right)$,\n\n:::\n\n\n- Si $X \\sim \\mathcal{N}(0,1)$, donner une densité de la loi de $Y=\\exp(X)$ (Loi log-normale). Calculer l'espérance et la variance de $Y$.\n- Même question si $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n- Si $X, Y \\sim \\mathcal{N}(0,1)$, avec $X \\perp\\!\\!\\!\\perp Y$, donner une densité de la loi de $Z=Y/X$ (Loi de Student à 1 degré de liberté)\n- Si $X, Y \\sim \\mathcal{N}(0,1)$, avec $X \\perp\\!\\!\\!\\perp Y$, donner une densité de la loi de $W = Y/ \\sqrt{X^2}$. \n- Si $X \\sim \\mathcal{N}(0,1)$ et $\\epsilon$ vaut $\\pm 1$ avec probabilité $1/2$  (variable de Rademacher) avec   $X \\perp\\!\\!\\!\\perp \\epsilon$, donner une densité de la loi de $Y = \\epsilon X$. $Y$ et $X$ sont-elles indépendantes ?\n\n\n### Exercice 9\n\n\n::: {.cell}\n\n:::\n\n\n\n\nPrincipe de réflexion\n\nDans cet exercice, $X_1, X_2, \\ldots$ sont des variables de Rademacher indépendantes ($P\\{X_i = \\pm 1\\} = \\frac{1}{2}$), $S_n =\\sum_{i=1}^n X_i, S_0=0$ et  $M_n = \\max_{k \\leq n} S_n$.\n\nMontrer que, pour $a> 0$,  \n\n$$P\\left\\{ M_n > a \\right\\}\\leq 2 P\\left\\{ S_n > a \\right\\}$$\n\n\n\n::: {.callout-note}\n\n### Statistique des rangs/Statistiques d'ordre\n\n\nLes statistiques d'ordre $X_{1:n}\\leq X_{2:n}\\leq X_{n:n}$ d'un $n$-échantillon  $X_1,\\ldots,X_n$\nd'observations indépendantes identiquement distribuées sont formées par le réarrangement croissant (convention) de l'échantillon. \n\nQuand $n$  est clair d'après le contexte on peut les noter $X_{(1)} \\leq \\ldots \\leq X_{(n)}$. \n\n:::\n\n### Exercice 10\n\n\n::: {.cell}\n\n:::\n\n\n\na. Vérifier que la loi jointe des statistiques d'ordre est absolument continue par rapport \nà la loi de l'échantillon.\na. On suppose que $X$ est une variable aléatoire réelle, absolument continue, de densité continue. Montrer que l'échantillon est presque sûrement formé de valeurs deux à deux distinctes. \na. Donner la densité de la loi jointe des statistiques d'ordre.\na. Si la loi des $X_i$  définie par sa fonction de répartition $F$, admet une densité $f$, quelle est la densité de la loi de $X_{k:n}$  pour $1\\leq k\\leq n$ ?  \na.  Montrer que conditionnellement à $X_{k:n}=x$, la suite \n\n    $$(X_{i:n}-X_{k:n})_{i=k+1,\\ldots, n}$$  \n\n    est distribuée comme les statistiques d'ordre d'un $n-k$ échantillon de la loi d'excès au dessus de $x$  (fonction de survie $\\overline{F}(x+\\cdot)/\\overline{F}(x))$ avec la convention $\\overline{F}=1-F$). \na. Si $X_1,\\ldots,X_n$ est un échantillon i.i.d. de la loi exponentielle d'espérance $1$ (densité $\\mathbb{I}_{x>0} \\mathrm{e}^{-x}$), et $X_{n:n}\\geq X_{n-1:n}\\geq  \\ldots \\geq X_{1:n} $ les statistiques d'ordre associées, montrer que:\n\n  i. avec la convention $X_{0:n}=0$, les écarts $(X_{i:n}-X_{i-1:n})_{1\\leq i\\leq n}$ (\\emph{spacings}) forment une\n  collection de variables aléatoires indépendantes ;\n  i. $X_{i:n}-X_{i-1:n}$ est distribuée selon une loi exponentielle\n  d'espérance $\\tfrac{1}{i}$ .\n\na. Maintenant, $X_1,\\ldots,X_n$ est un échantillon i.i.d. de la loi exponentielle d'espérance $1$ (densité $\\mathbb{I}_{x>0} \\mathrm{e}^{-x}$), et $X_{n:n}\\geq X_{n-1:n}\\geq  \\ldots \\geq X_{1:n}$ les statistiques d'ordre associées, et $(k_n)_n$ est une suite croissante d'entiers qui tend vers l'infini,  telle que $k_n/n$ tende vers une limite finie (éventuellement nulle).  Montrer que\n\n    $$\\frac{X_{k_n:n} -\\mathbb{E} X_{k_n:n} }{\\sqrt{\\operatorname{var}(X_{k_n:n} )}}$$ \n    \n    converge en loi vers une Gaussienne centrée réduite. \n\n\n\n\n\n",
    "supporting": [
      "td4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}