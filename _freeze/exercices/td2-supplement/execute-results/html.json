{
  "hash": "426cc45acb066bbf97508b3c0f8ab9b3",
  "result": {
    "engine": "knitr",
    "markdown": "---\n#title: \"Exercices : semaine III\"\n# subtitle: \"M1 ISIFAR MA1AY010\"\n\n# date: \"2025-09-19\"\n\nformat:\n  pdf:\n    output-file: td2-supplement.pdf\n    class: exam\n    include-in-header:\n      - text: \"\\\\lhead{{\\\\sf  Probabilités \\\\\\\\ TD 2 supplement}}\"\n  html:\n    output-file: td2-supplement.html\n\nengine: knitr\n---\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {.callout-note}\n\n### TD II : Espérances et lois conditionnelles (supplément)\n\n  22 Septembre 2025-26 Septembre 2025\n\n- Master I Isifar\n\n- **Probabilités** \n\n:::\n\n\n### Exercice 1  (Questionnaire)\n\n\n::: {.cell}\n\n:::\n\n\n\nSoient $(\\Omega; \\mathcal{A}; P)$ un espace de probabilité, $X$ et $Y$ des v.a.r., $T$ une v.a. à valeurs\ndans $\\mathbb{R}^d$. \n\nQue peut-on dire, sous réserve d'hypothèses d'intégrabilité adéquates, des espérances conditionnelles suivantes :\n\n\n1. $\\mathbb{E}(f(T)\\mid T)$ avec $f : \\mathbb{R}^d \\to \\mathbb{R}$ borélienne,\n1. $\\mathbb{E}(X\\mid T)$ avec $X$ $\\ \\sigma(T)$-mesurable, \n2. $\\mathbb{E}(XY \\mid T)$ avec $X \\ \\sigma(T)$-mesurable, \n3. $\\mathbb{E}(f(X)\\mid T)$ avec $f : \\mathbb{R}^d \\to \\mathbb{R}$ borélienne, $X$ et $T$ indépendantes, \n4. $\\mathbb{E}(\\mathbb{E}(X \\mid T))$, \n5. $\\mathbb{E}[S_{10} |S_{8}]$ lorsque $S_n = \\sum_{i=1}^n X_i$ et les $(X_i)_{i \\ge 1}$ sont i.i.d., \n6. $\\mathbb{E}[S_{31}\\mid X_1]$ lorsque $S_n = \\sum_{i=1}^n X_i$ et les $(X_i)_{i \\ge 1}$ sont i.i.d., \n7. $\\mathbb{E}[\\Pi_{4} \\mid \\Pi_2]$ lorsque  $\\Pi_n = \\prod_{i=1}^n X_i$ et les $(X_i)_{i \\ge 1}$ sont i.i.d., \n8. $\\mathbb{E}[\\phi(X,Y) \\mid Y]$ lorsque $X$ et $Y$ sont indépendantes, \n9. $\\mathbb{E}[f(S_2+X_8) \\mid S_2]$, lorsque $S_n = \\sum_{i=1}^n X_i$ et les $(X_i)_{i \\ge 1}$ sont i.i.d. \n\n\n::: {.content-visible when-profile=\"solution\"}\n \n\n\n1.[(i)] $f(T)$ est $\\sigma(T)$-mesurable donc \n$$ \\mathbb{E}[f(T) \\mid T] = f(T)$$\n1.[(ii)] si $X$ est $\\sigma(T)$-mesurable \n$$ \\mathbb{E}[X \\mid T] = X.$$ \n1.[(iii)] Si $X$ est $\\sigma(T)$-mesurable notons déjà que $X \\mathbb{E}[Y \\mid T]$ l'est également.\n\nFIxons $A'\\in \\sigma(T)$.\n \n Traitons d'abord le cas $X = \\mathbb{I}_A$, pour  $A \\in \\sigma(T)$. Par définition de $\\mathbb{E}[Y \\mid T]$ on a, \n$$mathbb{E}[ X Y \\mathbb{I}_{A'}] & = & \\mathbb{E}[\\mathbb{I}_{A} Y \\mathbb{I}_{A'}] \\\\ \n& = & \\mathbb{E}[\\mathbb{I}_A \\mathbb{E}[Y \\mid T] \\mathbb{I}_{A'}] $$ \net donc dans ce cas $\\mathbb{E}[XY \\mid T] = X \\mathbb{E}[Y \\mid T]$. \n\nSi $X = \\sum_{i=1}^N \\alpha_i \\mathbb{I}_{A_i}$, avec $A_i \\in \\sigma(T), 1 \\le i \\le N$, on a donc par linéarité de l'espérance \n$$ \\mathbb{E}[ X Y \\mathbb{I}_{A'}]  = \\sum_{i=1}^N \\alpha_i \\mathbb{E}[\\mathbb{I}_{A_i} \\mathbb{E}[Y \\mid T] \\mathbb{I}_{A'}] = \\mathbb{E}\\left[ X \\mathbb{E}[Y \\mid T] \\mathbb{I}_{A'}\\right] $$ \n\nSi $X$ est une v.a.r positive, $\\sigma(T)$-mesurable, il existe une suite de v.a. simples \n$$ X_n = \\sum_{k=0}^{n 2^n -1} \\frac{k}{2^n} \\mathbb{I}_{\\{\\frac{k}{2^n} \\le X < \\frac{k+1}{2^n} \\}} + n \\mathbb{I}_{\\{X \\ge n\\}}$$ \ni.e. de la forme $\\sum_{i=1}^N \\alpha_i \\mathbb{I}_{A_i}$ avec $A_i \\in \\sigma(T), 1 \\le i \\le N$ qui converge p.s. vers $X$.  \nD'après ce qui précède,\n$$   \\mathbb{E}[ X_n Y \\mathbb{I}_{A'}]  = \\mathbb{E}\\left[ X_n \\mathbb{E}[Y \\mid T] \\mathbb{I}_{A'}\\right].$$\nPar convergence dominée ($|X_n| \\le |X|$) on peut passer à la limite lorsque $n \\to \\infty$ dans l'égalité précédente pour assurer \n   $$   \\mathbb{E}[ X Y \\mathbb{I}_{A'}]  = \\mathbb{E}\\left[ X \\mathbb{E}[Y \\mid T] \\mathbb{I}_{A'}\\right].$$\n\nEnfin si $X$ est une v.a.r, $X = X^+-X_-$, avec $X_+ = \\max(X,0)$ qui est clairement $\\sigma(T)$-mesurable, tout comme $X_-$. On peut donc appliquer ce qui précède et conclure \n$$   \\mathbb{E}[ X Y \\mathbb{I}_{A'}]  = \\mathbb{E}\\left[ X \\mathbb{E}[Y \\mid T] \\mathbb{I}_{A'}\\right].$$\nComme le raisonnement est valable pour tout $A' \\in \\sigma(T)$, on conclut que \n$$ \\mathbb{E}[XY \\mid T] = X \\mathbb{E}[Y \\mid T].$$ \n\n1.[(iv)] Si $X$ et $T$ sont indépendantes, i.e. $\\sigma(X)$ et $\\sigma(T)$ indépendantes, alors $f(X)$ étant $\\sigma(X)$-mesurable, on a également que $f(X)$ et $T$ sont indépendantes. \nOn déduit que si $A \\in \\sigma(T)$. \n$$ \\mathbb{E}[f(X) \\mathbb{I}_A] = \\mathbb{E}[f(X)]  \\mathbb{P}(A) = \\mathbb{E}[\\mathbb{I}_A \\mathbb{E}[f(X)]]. $$ \nEvidemment $\\mathbb{E}[f(X)]$ est $\\sigma(T)$-mesurable, et on conclut que $\\mathbb{E}[f(X) \\mid T] = \\mathbb{E}[f(X)]$. \n\n1.[(v)] Soit $\\Omega \\in \\sigma(T)$. Par définition de l'espérance conditionnelle \n$$ \\mathbb{E}[\\mathbb{E}[X \\mid T]] = \\mathbb{E}[\\mathbb{E}[X \\mid T] \\mathbb{I}_{\\Omega}] = \\mathbb{E}[X \\mathbb{I}_{\\Omega}] = \\mathbb{E}[X].$$  \n\n1.[(vi)] $\\mathbb{E}[S_{10} \\mid S_8] = \\mathbb{E}[S_8 + X_9 + X_{10} \\mid S_8] = S_8 + \\mathbb{E}[X_9] + \\mathbb{E}[X_{10}] = S_8 + 2 \\mathbb{E}[X_1]$, \n\noù, pour la deuxième égalité ci-dessus on a utilisé la linéarité de l'espérance, (i) pour $\\mathbb{E}[S_8 \\mid S_8]=S_8$, puis (iv) avec  l'indépendance de $X_9, X_{10},S_8$ car les $(X_i, i \\ge 1)$ sont indépendantes. \nPour la troisième égalité on a utilisé que les $(X_i, i \\ge 1)$ sont i.d \n\n1.[(vii)] De manière similaire au point précédent \n$$ \\mathbb{E}[S_{31} \\mid X_1] = X_1 + 30 \\mathbb{E}[X_1].$$\n\n1.[(viii)] En utilisant (iii), puis l'indépendance de $X_3, X_4$ et $\\Pi_2$ on obtient\n$$ \\mathbb{E}[\\Pi_4 \\mid \\Pi_2] = \\Pi_2 \\mathbb{E}[X_3X_4 \\mid \\Pi_2] = \\Pi_2 \\mathbb{E}[X_3]\\mathbb{E}[X_4] = \\Pi_2 \\mathbb{E}[X_1]^2,$$\npour la dernière égalité, on a utlisé que les $(X_i, i \\ge 1)$ sont i.d.\n\n1.[(ix)] Soit, pour $y \\in \\mathbb{R}$, $\\psi(y) = \\mathbb{E}[\\phi(X,y)] = \\int_{\\mathbb{R}} \\phi(x,y) d \\mathbb{P}_X(x)$ de sorte que $\\psi(Y)$ est clairement $\\sigma(Y)$-mesurable. \nOn a pour $A \\in \\sigma(Y)$, qu'il existe $B$ tel que $A = Y^{-1}(B)$, i.e. $\\mathbb{I}_A(\\omega) = \\mathbb{I}_B(Y(\\omega))$ et donc, par Fubini \n$$mathbb{E}[\\phi(X,Y) \\mathbb{I}_A] & = & \\int_{\\mathbb{R}^2} \\phi(x,y) \\mathbb{I}_B(y) d \\mathbb{P}_X \\otimes d \\mathbb{P}_Y(x,y) \\\\\n& = & \\int_{\\mathbb{R}} \\mathbb{I}_B(y) \\left(\\int_{\\mathbb{R}} \\phi(x,y) d \\mathbb{P}_X(x) \\right) d \\mathbb{P}_Y(y) \\\\ \n& = &  \\int_{\\mathbb{R}} \\mathbb{I}_B(y)  \\psi(y) dy = \\mathbb{E}[\\psi(Y) \\mathbb{I}_B(Y)] = \\mathbb{E}[\\psi(Y) \\mathbb{I}_A] $$\n \n1.[(x)] D'après la question précédente \n$ \\mathbb{E}[f(S_2+X_8) \\mid S_2] = \\psi(S_2),$\navec $ \\psi(s) = \\mathbb{E}[f(s+X_8)]$. \n \n:::\n\n\n\n### Exercice 2\n\n\n::: {.cell}\n\n:::\n\n\n\nOn considère un processus de Galton-Watson de loi de branchement \n$$ \\mathbb{P}(\\xi=0)= \\mathbb{P}(\\xi=2)=1/2.$$ issu à la génération $0$ d'un unique individu ancestral. On note $Z_n$ la taille de la population à la génération $n$.\n  \nExprimer $\\mathbb{E}[(Z_{2}-1)^2 \\mid Z_1].$\n\n::: {.content-visible when-profile=\"solution\"}\n \nOn a $Z_2 = \\sum_{i=1}^{Z_1} \\xi_{1,i}$, avec les $(\\xi_{1,i}, i \\ge 1)$ indépendants de $Z_1$ et i.i.d. \n\nPour tout $f : \\mathbb{R}_+ \\to \\mathbb{R}_+$  on a donc (EF5) : \n$$ \\mathbb{E}[f(Z_2) \\mid Z_1] = \\psi(Z_1), \\mbox{ où } \\psi(n) = \\mathbb{E}\\left[f\\left(\\sum_{i=1}^n \\xi_{1,i}\\right)\\right]$$ \nIci, on a  \n$$psi(n) & = & \\mathbb{E}\\left[\\left(\\sum_{i=1}^n \\xi_{i,1} - 1\\right)^2\\right] \\\\ \n& = & \\mathbb{E}\\left[\\sum_{i,j=1}^n \\xi_{1,i} \\xi_{1,j}\\right] - 2 \\sum_{i=1}^n \\mathbb{E}[\\xi_{1,i}] + 1 \\\\\n& = & 2n + (n^2 -n) -2n +1 = n^2 -n +1, $$\n en utilisant que $\\mathbb{E}[\\xi_{1,i}^2] = 2$, et $\\mathbb{E}[\\xi_{1,i} \\xi_{1,j}]=1$ si $i \\ne j$.  Finalement \n$$ \\mathbb{E}[(Z_2-1)^2 \\mid Z_1] = Z_1^2-Z_1+1.$$ \n \n\n:::\n\n",
    "supporting": [
      "td2-supplement_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}