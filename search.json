[
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3",
    "section": "",
    "text": "Important\n\n\n\nLa semaine III (22-26 septembre 2025) est consacr√©e aux calculs de moments, et au conditionnement.",
    "crumbs": [
      "Agenda",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-3.html#pr√©parervoirrevoir",
    "href": "weeks/week-3.html#pr√©parervoirrevoir",
    "title": "Week 3",
    "section": "Pr√©parer/Voir/Revoir",
    "text": "Pr√©parer/Voir/Revoir\n\n\nEsp√©rances, moments, Espaces \\(L^p\\) (2025-09-22)\nConditionnement (2025-09-23 et 2025-09-25)\n\n\n\n\nVoir Notes, Esp√©rances, Moments, Espaces \\(L^p\\), ‚Ä¶\nVoir Notes, Conditionnement",
    "crumbs": [
      "Agenda",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-3.html#exercices",
    "href": "weeks/week-3.html#exercices",
    "title": "Week 3",
    "section": "Exercices",
    "text": "Exercices\n\nFeuille TD II\nFeuille TD II suppl√©ment\nQuestionnaire I\n\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Agenda",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Semaine 1",
    "section": "",
    "text": "Important\n\n\n\nLa semaine I (8-12 septembre 2025) est consacr√©e aux r√©visions de Licence. On (re)-pr√©sentera beaucoup de d√©finitions, quelques outils essentiels, et on tentera d‚Äôutiliser ces d√©finitions et outils sur la liste d‚Äôexercices des feuilles de TD.",
    "crumbs": [
      "Agenda",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-1.html#pr√©parerrevoir",
    "href": "weeks/week-1.html#pr√©parerrevoir",
    "title": "Semaine 1",
    "section": "Pr√©parer/Revoir",
    "text": "Pr√©parer/Revoir\n\nEspace probabilisable\n\nTribu/\\(\\sigma\\)-alg√®bre\nTribu bor√©lienne\nTribu de Lebesgue\nLemme des classes monotones\n\nLoi de probabilit√©, mesure positive, \\(\\sigma\\)-additivit√©\nFonctions mesurables et variables al√©atoires\nEsp√©rance, variance, moments\nTh√©or√®mes de convergence (monotone, Fatou, domin√©e)\nInd√©pendance (√âvenements, Tribus)",
    "crumbs": [
      "Agenda",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-1.html#exercices",
    "href": "weeks/week-1.html#exercices",
    "title": "Semaine 1",
    "section": "Exercices",
    "text": "Exercices\nFeuille TD I\nCorrig√©s :\n\n1 (transformation affine),\n2 (minima, maxima),\n10 (transform√©es de Laplace),\n11 (densit√© de la loi du carr√©),\n17 (somme de Poisson ind√©pendantes, conditionnement discret),\n18 (sommes al√©atoires de variables ind√©pendantes).",
    "crumbs": [
      "Agenda",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-1.html#exercices-suppl√©mentaires",
    "href": "weeks/week-1.html#exercices-suppl√©mentaires",
    "title": "Semaine 1",
    "section": "Exercices suppl√©mentaires",
    "text": "Exercices suppl√©mentaires\nFeuille TD I suppl√©ments\n\n\nRetour √† l‚Äôagenda ‚èé",
    "crumbs": [
      "Agenda",
      "Week 1"
    ]
  },
  {
    "objectID": "exercices/td2-supplement.html",
    "href": "exercices/td2-supplement.html",
    "title": "MA1AY010 Probabilit√©s",
    "section": "",
    "text": "NoteTD II : Esp√©rances et lois conditionnelles (suppl√©ment)\n\n\n\n22 Septembre 2025-26 Septembre 2025\n\nMaster I Isifar\nProbabilit√©s\n\n\n\n\nExercice 1 (Questionnaire)\nSoient \\((\\Omega; \\mathcal{A}; P)\\) un espace de probabilit√©, \\(X\\) et \\(Y\\) des v.a.r., \\(T\\) une v.a. √† valeurs dans \\(\\mathbb{R}^d\\).\nQue peut-on dire, sous r√©serve d‚Äôhypoth√®ses d‚Äôint√©grabilit√© ad√©quates, des esp√©rances conditionnelles suivantes :\n\n\\(\\mathbb{E}(f(T)\\mid T)\\) avec \\(f : \\mathbb{R}^d \\to \\mathbb{R}\\) bor√©lienne,\n\\(\\mathbb{E}(X\\mid T)\\) avec \\(X\\) \\(\\ \\sigma(T)\\)-mesurable,\n\\(\\mathbb{E}(XY \\mid T)\\) avec \\(X \\ \\sigma(T)\\)-mesurable,\n\\(\\mathbb{E}(f(X)\\mid T)\\) avec \\(f : \\mathbb{R}^d \\to \\mathbb{R}\\) bor√©lienne, \\(X\\) et \\(T\\) ind√©pendantes,\n\\(\\mathbb{E}(\\mathbb{E}(X \\mid T))\\),\n\\(\\mathbb{E}[S_{10} |S_{8}]\\) lorsque \\(S_n = \\sum_{i=1}^n X_i\\) et les \\((X_i)_{i \\ge 1}\\) sont i.i.d.,\n\\(\\mathbb{E}[S_{31}\\mid X_1]\\) lorsque \\(S_n = \\sum_{i=1}^n X_i\\) et les \\((X_i)_{i \\ge 1}\\) sont i.i.d.,\n\\(\\mathbb{E}[\\Pi_{4} \\mid \\Pi_2]\\) lorsque \\(\\Pi_n = \\prod_{i=1}^n X_i\\) et les \\((X_i)_{i \\ge 1}\\) sont i.i.d.,\n\\(\\mathbb{E}[\\phi(X,Y) \\mid Y]\\) lorsque \\(X\\) et \\(Y\\) sont ind√©pendantes,\n\\(\\mathbb{E}[f(S_2+X_8) \\mid S_2]\\), lorsque \\(S_n = \\sum_{i=1}^n X_i\\) et les \\((X_i)_{i \\ge 1}\\) sont i.i.d.\n\n\n\nExercice 2\nOn consid√®re un processus de Galton-Watson de loi de branchement \\[ \\mathbb{P}(\\xi=0)= \\mathbb{P}(\\xi=2)=1/2.\\] issu √† la g√©n√©ration \\(0\\) d‚Äôun unique individu ancestral. On note \\(Z_n\\) la taille de la population √† la g√©n√©ration \\(n\\).\nExprimer \\(\\mathbb{E}[(Z_{2}-1)^2 \\mid Z_1].\\)"
  },
  {
    "objectID": "exercices/td1-supplement.html",
    "href": "exercices/td1-supplement.html",
    "title": "MA1AY010 Probabilit√©s",
    "section": "",
    "text": "NoteTD I : R√©visions de Licence (exercices suppl√©mentaires)\n\n\n\n\n8 Septembre 2025-12 Septembre 2025\nMaster I Isifar\nProbabilit√©s"
  },
  {
    "objectID": "exercices/td1-supplement.html#pour-aller-plus-loin",
    "href": "exercices/td1-supplement.html#pour-aller-plus-loin",
    "title": "MA1AY010 Probabilit√©s",
    "section": "Pour aller plus loin",
    "text": "Pour aller plus loin\n\nExercice 1 (un (contre)-exemple √† garder en t√™te)\nOn note \\(C\\) l‚Äôensemble de Cantor, qui est obtenu, r√©cursivement, en enlevant \\(I_1^{(1)} : = (1/3,2/3)\\) √† l‚Äôintervalle \\([0,1]\\), puis en enlevant les tiers interm√©diaires \\(I_2^{(1)} = (1/9,2/9), I_2^{(2)}= (7/9,8/9)\\) des deux intervalles restants, et ainsi de suite, de sorte qu‚Äô√† l‚Äôetape \\(n\\) on enl√®ve \\(2^{n-1}\\) intervalles tous de taille \\(1/3^n\\), not√©s \\(I_n^{(j)},j=1...2^{n-1}\\).\nOn d√©finit la fonction croissante :\n\\[F(x) := \\begin{cases}  0 & \\text{ si } x \\le 0 \\\\    1 & \\text{ si } x \\ge 1 \\\\ \\frac{2j-1}{2^n} \\text{ si } x \\in I_n^{(j)}. \\end{cases}\\]\n\nLa fonction \\(F\\) est-elle continue?\nDans quel ensemble la variable \\(X\\), de fonction de r√©partition \\(F\\) ‚Äîd√©finie ci-dessus‚Äî prend elle ses valeurs? Que vaut \\(\\mathbb{E}[X]\\)? Que vaut \\(\\mathbb{P}(|X-\\mathbb{E}[X]|&lt;1/8)\\)? Pour \\(x \\in C\\), que vaut \\(\\mathbb{P}(X=x)\\)?\nJustifier que la variable \\(X\\) est uniforme sur \\(C\\). Admet-elle une densit√© sur \\([0,1]\\)?\n\nQuelle est la loi de \\(Y=F(X)\\)?\nPourrait-on ainsi d√©finir une variable al√©atoire uniforme sur \\(\\mathbb{Q}\\cap [0,1]\\)?\nSoient \\(\\{X_j, j \\in \\mathbb{N}^* \\}\\) une famille de variables i.i.d., distribu√©es suivant la loi de Bernoulli de parma√®tre \\(1/2\\). On d√©finit \\(X=2 \\sum_{j \\ge 1} \\frac{X_j}{3^j}\\). Quelle est la loi de \\(X\\)?\nCalculer \\(\\Phi_X\\) et montrer qu‚Äôelle est constante sur \\(\\{3^k \\pi, k \\in \\mathbb{N}^* \\}\\).\n\n\n\nExercice 2\nDans ce qui suit \\(||.||\\) d√©signe la norme euclidienne.\nPour \\(\\varepsilon \\in (0,1)\\), \\(n \\in \\mathbb{N}\\)\non note \\(A_{n, \\varepsilon} := \\{ x \\in \\mathbb{R}^n : (1-\\varepsilon)(n/3)^{1/2} \\le ||x|| \\le (1+\\varepsilon)(n/3)^{1/2}\\}\\), et \\(C_n=[-1,1]^n\\).\nMontrer que pour tout \\(\\varepsilon \\in (0,1)\\), la mesure de Lebesgue de \\(C_n \\cap A_{n, \\varepsilon}^c\\) est n√©gligeable, pour \\(n \\to \\infty\\), devant celle de \\(C_n\\).\nIndication : On notera qu‚Äôun point g√©n√©rique dans \\(C_n\\) a pour coordonn√©es \\((X_1,...,X_n)\\), avec \\(\\{X_i, i \\ge 1\\}\\) une famille de variables al√©atoires i.i.d, uniformes sur \\([-1,1]\\).\nNote : Ceci signifie que pour \\(\\varepsilon\\) aussi petit qu‚Äôon souhaite le prendre, lorsque \\(n\\) est grand, la majeure partie du volume de l‚Äôhypercube \\(C_n\\) se trouve dans la couronne \\(A_{n,\\varepsilon}\\) (!)\n\n\nExercice 3\nSoit \\(X \\sim \\Gamma(1,s)\\). On d√©finit \\(Y \\sim \\mathrm{Poisson}(X)\\), (c‚Äôest-√†-dire que conditionnellement √† \\(X=x\\), \\(Y \\sim \\mathrm{Poisson}(x)\\)).\n\nCalculer \\(\\Phi_Y\\).\nMontrer que lorsque \\(s \\to \\infty\\), \\[\\frac{Y-E[Y]}{\\sqrt{\\mathrm{var}(Y)}} \\overset{(\\mathrm{loi})}{\\longrightarrow} Z,\\] o√π \\(Z \\sim \\mathcal{N}(0,1)\\). Y a-t-il un lien avec le th√©or√®me central limite?\n\n\n\nExercice 4\n(Une remarque importante sur la convergence en loi.)\nSoit, pour \\(n \\ge 1\\), \\(X_n\\) un variable al√©atoire dont la fonction de r√©partition est d√©finie par \\[ F_n(x) = x - \\frac{\\sin(2n \\pi x)}{2n\\pi}, \\ 0 \\le x \\le 1.\\]\n\nMontrer que \\(X_n\\) converge en loi vers une variable \\(X\\) (dont on d√©crira la loi).\n\nV√©rifier que \\(X_n\\) et \\(X\\) sont des variables √† densit√©. On note \\(f_n := F_n'\\) la densit√© de \\(X_n\\), \\(f\\) celle de \\(X\\). A-t-on \\(f_n \\underset{n \\to \\infty}{\\rightarrow} f\\) simplement?\n\n\n\nExercice 5\n(Le probl√®me des anniversaires)\nOn cherche a approximer la probabilit√© que parmi \\(N\\) personnes, au moins deux (resp. trois) aient leur anniversaire le m√™me jour.\n\nPour \\(1 \\le i &lt;j \\le N\\), on note \\(E_{ij}\\) l‚Äô√©v√©nement que les personnes \\(i,j\\) aient le m√™me anniversaire. Quelle est la probabilit√© de \\(E_{ij}\\)? Dans la suite de l‚Äôexercice on omet de consid√©rer le cas des \\(29\\) f√©vrier. Que vaut alors \\(P(E_{ij})\\)? Montrer que les √©v√©nements \\(E_{12}, E_{23}, E_{13}\\) sont ind√©pendants deux √† deux, mais pas mutuellement ind√©pendants. Exprimer la probabilit√© qu‚Äôil y ait au moins deux personnes qui aient leur anniversaire le m√™me jour.\nLe but de cette question n‚Äôest pas d‚Äôobtenir un r√©sultat exact, mais de faire une approximation assez bonne de la probabilit√© que parmi \\(N\\) personnes, il y en ait au moins deux qui partagent le m√™me anniversaire. On admettra donc que dans la suite on fait l‚Äôapproximation que les \\(\\{E_{ij}, 1 \\le i &lt; j \\le N\\}\\) sont mutuellement ind√©pendants. Quelle est alors la loi du nombre de couples ayant le m√™me anniversaire? Approximer le r√©sultat pour \\(N=30, N=60\\).\n\nPar une m√©thode similaire, approximer la probabilit√© que parmi \\(60\\) personnes, il y en ait au moins trois qui ont leur anniversaire le m√™me jour. Finalement, approximer la probabilit√© de cet √©v√©nement lorsque \\(N=90\\).\n\n\n\nExercice 6\n(Quelques variantes du mod√®le de branchement al√©atoire)\nOn consid√®re le mod√®le de branchement al√©atoire qui est un mod√®le pour l‚Äô√©volution d‚Äôune population haplo√Øde.\nOn part initialement de \\(Z_0\\) anc√™tres, et on note \\(Z_n\\) le nombre total d‚Äôindividus de la g√©n√©ration \\(n\\).\nOn fait l‚Äôhypoth√®se (pas tr√®s r√©aliste) que tous les individus ont exactement le m√™me temps de vie (disons \\(1\\)), et que de plus deux g√©n√©rations distinctes ne cohabitent pas. Ainsi chacun des anc√™tre meurt au temps \\(1\\), et donne naissance √† un nombre al√©atoire d‚Äôindividus, de fa√ßon ind√©pendante de ses contemporains. Tous les individus qui sont n√©s au temps \\(1\\) forment la g√©n√©ration \\(1\\). La g√©n√©ration \\(1\\) meurt au temps \\(2\\) en donnant naissance √† la g√©n√©ration \\(2\\), etc‚Ä¶\nFormellement, on se donne une loi de branchement \\(\\nu\\) sur les entiers positifs, telle que \\(\\nu(1)&lt; 1\\) et \\(\\sum_{k \\ge 0} k \\nu(k) = \\mu \\in [0,\\infty)\\) On introduit alors une famille \\((X,X_{i,k}, i \\ge 0, k\\ge 1)\\) de variables al√©atoires i.i.d, toutes de loi \\(\\mu\\). Si jamais la g√©n√©ration \\(i\\) poss√®de un \\(k\\)-i√®me individu, \\(X_{i,k}\\) d√©signe le nombre de ses descendants.\n\nPour \\(n \\ge 1\\), exprimer \\(Z_n\\) en fonction de \\(Z_{n-1}\\) et des \\((X_{n-1,k}, k \\ge 1)\\).\nOn note \\(G_{X}(t) = E[t^{X}]\\), \\(G_{Z_n}(t) = E[t^{Z_n}]\\) (qui ne sont autres, modulo un simple changement de variable, que les fonctions g√©n√©ratrice des moments de \\(X\\), \\(Z_n\\)). Exprimer \\(G_{Z_n}\\) en fonction de \\(G_X, G_{Z_0}\\).\nOn note \\(\\zeta\\) le probabilit√© d‚Äôextinction. A quelle condition sur \\(\\mu\\) a-t-on \\(\\zeta=1\\) p.s.?\nIndication : On pourra consid√©rer la suite \\(\\zeta_n = \\mathbb{P}(Z_n=0)\\)\nUne premi√®re martingale, Calculer \\(\\mathbb{E}[Z_{n-1}|Z_n]\\). On pose \\(M_{n}=Z_n/\\mu^n\\). Calculer \\(\\mathbb{E}[M_{n+1}|M_n]\\).\n\nPour plus de d√©tails, on pourra voir l‚Äôintroduction du livre de D.WILLIAMS, Probability with martingales, Cambridge University Press, 1991.\n\nOn consid√®re (dans cette question uniquement) un processus de branchement avec immigration. On garde la m√™me dynamique : √† sa mort, un individu donne naissance √† un nombre al'atoire de descendants suivant la loi \\(\\mu\\). De plus, chaque g√©n√©ration voit maintenant arriver un nombre al√©atoire d‚Äôimmigrants, indistinguables des individus d√©j√† pr√©sents.\nFormellement, on se donne une loi \\(\\nu\\) sur \\(\\mathbb{N}\\) et on introduit \\(Y,Y_1,...Y_n\\) des variables \\(i.i.d.\\) de loi \\(\\nu\\). La g√©n√©ration \\(n\\) re√ßoit \\(Y_n\\) individus au temps \\(n\\). On note \\(G_Y(t)= E[t^{Y}]\\). Trouver une relation entre \\(G_{Z_n}, G_Y\\) et \\(G_{Z_0}\\).\nEnfin, on consid√®re un processus de branchement dont les individus n‚Äôont pas tous un temps de vie √©gal √† \\(1\\). Pour simplifier un peu, on va seulement consid√©rer la descendance d‚Äôun unique anc√™tre, i.e.¬†on pose \\(Z_0=1\\). \\ Formellement, on se donne une loi \\(P_{T}\\) sur \\(\\mathbb{R}_+\\), dont la densit√© est not√©e \\(f_T\\). On d√©finit famille de variables al√©atoires \\((T_{i}, i \\in \\mathbb{N})\\) i.i.d, de loi \\(P_T\\). On peut num√©roter les individus en les classant suivant leur date de naissance. On d√©finit alors \\(T_i\\) comme le temps de vie du \\(i\\)-i√®me individu.\nPour \\(t \\ge 0\\), on note \\(Z_t\\) le nombre total d‚Äôindividus qui sont en vie au temps \\(t\\). On note enfin \\(G_t(s) = E[s^{Z_t}]\\).\n\n\nMontrer que \\(G_t(s) = \\int_0^{\\infty} E[s^{Z_t} |T_0 =u] f_T(u) du\\)\n\nEn d√©duire \\[ G_t(s) = \\int_0^t G_X(G_{t-u}(s))f_T(u) du + \\int_t^{\\infty} sf_T(u) du.\\]\n\nDans le cas o√π \\(f_T(s)= \\lambda \\exp(-\\lambda s)\\), montrer alors que \\[\\frac{\\partial t}{\\partial t} G_t(s) = \\lambda \\left[ G_X(G_t(s)) - G_t(s)\\right]  \\]"
  },
  {
    "objectID": "exercices-listings.html",
    "href": "exercices-listings.html",
    "title": "TDs",
    "section": "",
    "text": "Note\n\n\n\nLes s√©ances d‚Äôexercice sont organis√©es autour des feuilles de TD. Sentez vous libres d‚Äôattaquer les exercices √† l‚Äôavance.\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Titre\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Tags\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitre\n\n\n\nTags\n\n\n\n\n\n\n\n\nSep 8, 2025\n\n\nTD I : Rappels de Licence\n\n\nVariables al√©atoires r√©elles\n\n\n\n\n\n\nSep 11, 2025\n\n\nTD I suppl√©ment : Rappels de Licence\n\n\nVariables al√©atoires r√©elles, Branchement\n\n\n\n\n\n\nSep 22, 2025\n\n\nTD II : Conditionnement\n\n\nConditionnement, Branchement\n\n\n\n\n\n\nSep 22, 2025\n\n\nTD II : Conditionnement (suppl√©ment)\n\n\nConditionnement, Branchement\n\n\n\n\n\n\nSep 22, 2025\n\n\nQuestionnaire I\n\n\n¬†\n\n\n\n\n\n\nSep 22, 2025\n\n\nTD III : Branchement\n\n\nConditionnement, Branchement\n\n\n\n\n\n\nSep 29, 2025\n\n\nTD IV : Conditionnement\n\n\nConditionnement\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\nTipSuggestion",
    "crumbs": [
      "TDs"
    ]
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Cliquer ici pour t√©l√©charger une copie PDF du syllabus.",
    "crumbs": [
      "Informations",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#informations",
    "href": "course-syllabus.html#informations",
    "title": "Syllabus",
    "section": "Informations",
    "text": "Informations\n\n\n\n\n\n\n\n\n\n\nJour\nHoraire\nSalle\n\n\n\n\nCours/Exercices\nLundi\n13:30 - 16:30\nSophie Germain 1015\n\n\nExercices\nMardi\n8:30 - 10:30\nHalle aux Farines 227C\n\n\nCours/Exercices\nJeudi\n13:30 - 16:30\nSophie Germain 1015",
    "crumbs": [
      "Informations",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#objectifs",
    "href": "course-syllabus.html#objectifs",
    "title": "Syllabus",
    "section": "Objectifs",
    "text": "Objectifs\nA la fin du premier semestre, vous saurez‚Ä¶\n\nD√©finir, caract√©riser une loi de probabilit√© sur un espace simple.\n√âtablir et utiliser les diff√©rents types de convergence de variables al√©atoires.\nManipuler les esp√©rances conditionnelles.\nManipuler les vecteurs gaussiens (en dimension finie).",
    "crumbs": [
      "Informations",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#bibliographie",
    "href": "course-syllabus.html#bibliographie",
    "title": "Syllabus",
    "section": "Bibliographie",
    "text": "Bibliographie\nBerger, Q., Caravenna, F., & Dai Pra, P. (2021). Probabilit√† (Vol. 9). Springer.\n\nEn italien Via ENT Paris Cit√©\nEn fran√ßais Via ENT Paris Cit√©",
    "crumbs": [
      "Informations",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#cours-et-exercices",
    "href": "course-syllabus.html#cours-et-exercices",
    "title": "Syllabus",
    "section": "Cours et exercices",
    "text": "Cours et exercices\n\nNotes de cours (~ Poly)\nExercices",
    "crumbs": [
      "Informations",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#validation",
    "href": "course-syllabus.html#validation",
    "title": "Syllabus",
    "section": "Validation",
    "text": "Validation\n\nContr√¥le continu\n4 √©preuves (Examen terminal inclus)\n\n\nExamens\nL‚Äôexamen terminal de session I dure trois heures, il porte sur l‚Äôensemble du cours",
    "crumbs": [
      "Informations",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#int√©grit√©",
    "href": "course-syllabus.html#int√©grit√©",
    "title": "Syllabus",
    "section": "Int√©grit√©",
    "text": "Int√©grit√©\nTL;DR: Ne trichez pas!",
    "crumbs": [
      "Informations",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#sauvez-les-dates",
    "href": "course-syllabus.html#sauvez-les-dates",
    "title": "Syllabus",
    "section": "Sauvez les dates!",
    "text": "Sauvez les dates!\n\nContr√¥le Continu 1 Mardi 7 octobre 2025 (Programme : semaines I √† III)\nContr√¥le Continu 2 Jeudi 16 octobre 2025 (Programme : semaines I √† V)\nContr√¥le Continu 3 Novembre\nExamen entre le Lundi 8 et le Vendredi 19 d√©cembre\nExamen session II en juin 2026\n\nCliquer ici for l‚Äôemploi du temps.",
    "crumbs": [
      "Informations",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Quelques liens",
    "section": "",
    "text": "Entrepot GitHub du cours\nüîó sur GitHub\n\n\nEntrepot GitHub des Notes de cours\nüîó sur GitHub\n\n\nPortail Moodle du cours\nüîó sur Moodle",
    "crumbs": [
      "Informations",
      "Liens"
    ]
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Pas n√©cessairement.",
    "crumbs": [
      "Informations",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#les-corrig√©s-des-exercices-sont-ils-disponibles-en-ligne",
    "href": "course-faq.html#les-corrig√©s-des-exercices-sont-ils-disponibles-en-ligne",
    "title": "FAQ",
    "section": "",
    "text": "Pas n√©cessairement.",
    "crumbs": [
      "Informations",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#comment-travailler-avec-les-cahiers-de-simulation",
    "href": "course-faq.html#comment-travailler-avec-les-cahiers-de-simulation",
    "title": "FAQ",
    "section": "Comment travailler avec les cahiers de simulation ?",
    "text": "Comment travailler avec les cahiers de simulation ?\n\nEn R\n\nT√©l√©charger et installer R 4.x.y: https://cran.r-project.org/\nT√©l√©charger et installer RStudio: https://dailies.rstudio.com/\nInstaller Quarto CLI: https://quarto.org/docs/getting-started/installation.html\nInstaller Git: https://happygitwithr.com/install-git.html\nInstaller tout package utile avec install.packages(\"___\") (voir aussi le package pak)\n\n\n\nEn Python",
    "crumbs": [
      "Informations",
      "FAQ"
    ]
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "MA1AY010 : Enseignants",
    "section": "",
    "text": "S. Boucheron est professeur dans l‚Äô√âquipe de Statistique du Laboratoire de Probabilit√©s, Statistiques et Mod√©lisation (Universit√© Paris Cit√©, Sorbonne Universit√©, CNRS).\n\n\n\n\n\n\n\nConsultations\nBureau\n\n\n\n\nLundi 11:00 am - 12:00 pm\nSophie Germain 5013\n\n\n\nS. Abbes est professeur √† l‚ÄôIRIF (Universit√© Paris Cit√©, CNRS).",
    "crumbs": [
      "Informations",
      "Enseignants"
    ]
  },
  {
    "objectID": "course-team.html#instructeurs",
    "href": "course-team.html#instructeurs",
    "title": "MA1AY010 : Enseignants",
    "section": "",
    "text": "S. Boucheron est professeur dans l‚Äô√âquipe de Statistique du Laboratoire de Probabilit√©s, Statistiques et Mod√©lisation (Universit√© Paris Cit√©, Sorbonne Universit√©, CNRS).\n\n\n\n\n\n\n\nConsultations\nBureau\n\n\n\n\nLundi 11:00 am - 12:00 pm\nSophie Germain 5013\n\n\n\nS. Abbes est professeur √† l‚ÄôIRIF (Universit√© Paris Cit√©, CNRS).",
    "crumbs": [
      "Informations",
      "Enseignants"
    ]
  },
  {
    "objectID": "exercices/quizz_a.html",
    "href": "exercices/quizz_a.html",
    "title": "MA1AY010 Probabilit√©s",
    "section": "",
    "text": "NoteQuestionnaire I\n\n\n\n\n8 Septembre 2025-12 Septembre 2025\nMaster I Isifar\nProbabilit√©s\n\n\n\n\nQuestion 1\n\nEst-il vrai qu‚Äôune fonction croissante sur \\(\\mathbb{R}\\) est toujours mesurable ?\nSi \\(X,Y\\) sont ind√©pendantes, de lois √† densit√© sur \\(\\mathbb{R}\\), est-il vrai que \\(\\mathbb{P} \\{ X= Y \\}=0\\)?\n\n\n\nQuestion 2\nSoit \\(X\\) une variable al√©atoire r√©elle, dont la loi admet une densit√© \\(f\\) par rapport √† la mesure de Lebesgue. Soit \\(a\\) un r√©el positif et \\(b\\) un r√©el quelconque.\n\nLa loi de la variable al√©atoire \\(aX +b\\) admet-elle une densit√© ?\nSi oui, exprimer cette densit√© en fonction de \\(f, a, b\\).\n\n\n\nQuestion 3\nSur un espace de probabilit√© \\((\\Omega, \\mathcal{F}, P)\\), on dispose d‚Äôune famille infinie de variables al√©atoires ind√©pendantes \\(X_1, X_2, \\ldots, X_n, \\dots\\) toutes distribu√©es selon la loi exponentielle standard (densit√© \\(\\mathrm{e}^{-x}\\) sur \\([0, \\infty)\\)).\nOn d√©finit \\(Y_n = \\sum_{i=1}^n \\left( X_i/i - \\frac{1}{i}\\right)\\) pour tout \\(n\\).\n\nCalculer l‚Äôesp√©rance et la variance de \\(Y_n\\).\nLa suite \\((Y_n)_n\\) converge-t-elle dans \\(\\mathcal{L}_2\\) ?\nSi oui, pouvez-vous caract√©riser la loi de la limite?\n\n\n\nQuestion 4 (In√©galit√© d‚Äôassociation)\nSoit \\(X\\) une variable al√©atoire r√©elle sur un espace de probabilit√© \\((\\Omega, \\mathcal{F}, P)\\) et \\(f,g\\) deux fonctions croissantes positives sur \\(\\mathbb{R}\\).\nMontrer que \\[\n\\mathbb{E} \\left[ f(X) g(X)\\right] \\geq \\mathbb{E}\\left[ f(X)\\right]  \\times \\mathbb{E} \\left[ g(X) \\right] \\, .\n\\]\n\n\nQuestion 5\nSoit \\(X_1, \\ldots, X_n\\) une suite de variables al√©atoires i.i.d. selon une loi exponentielle. On note \\((X_{i,n})_{i\\leq n}\\) le r√©arrangement croissant de \\(X_1, \\ldots, X_n\\), (les statisques d‚Äôordre)\n\nQuelle est la loi de \\(X_{1,n}\\), le minimum ?\nQuelle est la loi de \\(X_{2,n} - X_{1, n}\\) ?\nQuelle est la densit√© jointe de la loi de \\((X_{i,n})_{i\\leq n}\\) ?\nQuelle est la densit√© jointe de la loi de \\((X_{i,n} - X_{i-1,n})_{i\\leq n}\\) avec la convention \\(X_{0,n}=0\\)?\n\n\n\nQuestion 6\nSoit \\(X\\) une variable al√©atoire distribu√©e selon une loi binomiale de param√®tres \\(n\\) et \\(p \\in (0,1)\\). Montrer que \\[\n\\frac{1}{\\mathbb{E}X+1} &lt; \\mathbb{E}\\frac{1}{X+1} \\leq \\frac{1}{\\mathbb{E}X + p} \\, .\n\\] Montrer que si \\(X\\) est distribu√©e selon une loi de Poisson \\[\n\\mathbb{E}\\frac{1}{X+1} = \\frac{1 - \\mathrm{e}^{-\\mathbb{E}X}}{\\mathbb{E}X} \\, .\n\\] On note \\(E\\) l‚Äô√©v√©nement \\(\\{ X &gt;0 \\}\\) montrer que \\[\n\\mathbb{E}_{P (\\cdot|E)}\\left[ \\frac{1}{X}\\right] \\geq \\mathbb{E}\\frac{1}{X+1} \\, .\n\\]\n\n\nQuestion 7\nLe jeu oppose un pr√©sentateur √† un candidat (le joueur). Ce joueur est plac√© devant trois portes ferm√©es. Derri√®re l‚Äôune d‚Äôelles se trouve une voiture et derri√®re chacune des deux autres se trouve une ch√®vre. Il doit tout d‚Äôabord d√©signer une porte. Puis le pr√©sentateur doit ouvrir une porte qui n‚Äôest ni celle choisie par le candidat, ni celle cachant la voiture (le pr√©sentateur sait quelle est la bonne porte d√®s le d√©but). Le candidat a alors le droit d‚Äôouvrir la porte qu‚Äôil a choisie initialement, ou d‚Äôouvrir la troisi√®me porte.\nOn suppose que l‚Äôorganisateur du jeu place la voiture uniform√©ment au hasard derri√®re l‚Äôune des trois portes avant la partie.\nLes questions qui se posent au candidat sont :\n\nQue doit-il faire ?\nQuelles sont ses chances de gagner la voiture en agissant au mieux ?"
  },
  {
    "objectID": "exercices/td1.html",
    "href": "exercices/td1.html",
    "title": "Variables al√©atoires r√©elles",
    "section": "",
    "text": "NoteTD I : R√©visions de Licence\n\n\n\n\n8 Septembre 2025-12 Septembre 2025\nMaster I Isifar\nProbabilit√©s"
  },
  {
    "objectID": "exercices/td1.html#fonctions-de-r√©partition",
    "href": "exercices/td1.html#fonctions-de-r√©partition",
    "title": "Variables al√©atoires r√©elles",
    "section": "Fonctions de r√©partition",
    "text": "Fonctions de r√©partition\n\nExercice 1 (transformation affine)\nSoit \\(X\\) une variable al√©atoire r√©elle, \\(F_X\\) sa fonction de r√©partition, \\(a, b\\) deux r√©els fix√©s, et \\(Y := aX+b\\)\n\nOn suppose dans cette question que \\(a=1\\). Comment d√©duire \\(F_Y\\) de \\(F_X\\)?\nSi (la loi de) \\(X\\) admet une densit√©, en est-il de m√™me de \\(Y\\)? Si oui, exprimer dans ce cas \\(f_Y\\) √† l‚Äôaide de \\(f_X\\).\nOn suppose dans cette question que \\(b=0\\) et \\(a&gt;0\\). Comment d√©duire \\(F_Y\\) de \\(F_X\\)?\nSi (la loi de ) \\(X\\) admet une densit√©, √† quelle condition sur \\(a\\) en est-il de m√™me de (la loi de) \\(Y\\)? Exprimer dans ce cas \\(f_Y\\) √† l‚Äôaide de \\(f_X\\).\nR√©pondre aux m√™mes questions lorsque \\(b=0\\) et \\(a=-1\\)?\nR√©pondre enfin aux m√™mes questions lorsque \\(a\\) et \\(b\\) sont quelconques.\n\n\n\nExercice 2 (Minimum, maximum de variables ind√©pendantes)\nSoient \\(X_i, i \\ge 1\\), des variables ind√©pendantes. Pour \\(k \\ge 2\\), on note \\(Y_k = \\min (X_1,...,X_k)\\), \\(Z_k = \\max(X_1,...,X_k).\\)\n\nDans cette question on s‚Äôint√©resse √† \\(k=2\\).\nComment d√©duire \\(F_{Y_2}\\) de \\(F_{X_1}, F_{X_2}\\)? M√™me question pour \\(F_{Z_2}\\).\nG√©n√©raliser √† \\(k\\) quelconque.\nQuelle est la loi de \\(Z_k\\) lorsque les \\(\\{X_i, i \\ge 1\\}\\) sont i.i.d., \\(\\sim \\mathrm{Unif}[0,1]\\)?\nQuelle est la loi de \\(Y_k\\) lorsque les \\(\\{X_i, i \\ge 1\\}\\) sont des variables exponentielles ind√©pendantes, avec \\(X_i \\sim \\text{Exp}(\\lambda_i)\\) (o√π pour tout \\(i\\), \\(\\lambda_i &gt;0\\))?\n\n\n\nExercice 3\nOn suppose que \\(X \\sim \\mathcal{N}(0,1)\\). Que valent\n\\[\\mathbb{P}(X \\le 1), \\quad \\mathbb{P}(-1.23 \\le X \\le 0.43), \\quad \\mathbb{P}(X&gt;0.32)?\\]\n\n\nExercice 4\nOn suppose que l‚Äô√©cart √† la taille moyenne \\(T=15.5\\) des individus d‚Äôune population suit une loi normale centr√©e r√©duite.\nDans quel intervalle centr√© en \\(T\\) se situent les tailles de \\(99\\%\\) des individus de la population?\n\n\nExercice 5\nEtant donn√©e X une variable al√©atoire gaussienne de param√®tres \\(\\mu\\) et \\(\\sigma^2\\), donner la probabilit√© que \\(|X - \\mu|\\) d√©passe \\(k\\sigma\\) pour \\(k = 1, 2, 3\\).\nSuggestion: On commencera par montrer que \\(\\sigma^{-1}(X-\\mu)\\) suit une loi normale centr√©e r√©duite.\nReprendre les questions de l‚Äôexercice pr√©c√©dent lorsque \\(\\mu=2, \\sigma=2\\).\nReprendre les questions de l‚Äôexercice pr√©c√©dent lorsque \\(\\mu=0, \\sigma=1/2\\)."
  },
  {
    "objectID": "exercices/td1.html#densit√©s",
    "href": "exercices/td1.html#densit√©s",
    "title": "Variables al√©atoires r√©elles",
    "section": "Densit√©s",
    "text": "Densit√©s\n\nExercice 6\nDans les cas suivants, trouver la valeur de \\(C\\) pour que \\(f\\) soit une densit√© de probabilit√©.\n\n\\(f(x) = C \\frac{1}{\\sqrt{x (1-x)}}, 0 &lt;x &lt;1,\\)\n\\(f(x) = C \\exp(-x-\\exp(-x)), x \\in \\mathbb{R},\\)\n\\(f(x) = C \\frac{1}{1+x^2}\\).\n\n\n\nExercice 7\n(M√©lange)\nOn suppose que \\(X\\) et \\(Y\\) sont deux variables de densit√©s respectives \\(f_X, f_Y\\), et que \\(\\alpha \\in [0,1]\\). Montrer que \\(g : = \\alpha f_X + (1-\\alpha) f_Y\\) est √©galement une densit√© de probabilit√©.\nTrouver une variable al√©atoire dont \\(g\\) est la densit√©.\n\n\nExercice 8\nSoit \\(X\\) de densit√© \\(f\\), et \\((\\alpha, \\beta) \\in \\overline{\\mathbb{R}}^2\\) sont suppos√©s tels que \\[\\mathbb{P}(\\alpha &lt; X &lt; \\beta) =1\\] On suppose que \\(g\\) est un \\(C^{1}\\)-diff√©omorphisme croissant de \\((\\alpha, \\beta)\\) sur \\((g(\\alpha),g(\\beta))\\).\n\nMontrer que \\(g(X)\\) a pour densit√© \\(\\frac{f(g^{-1}(x))}{g'(g^{-1}(x))} \\mathbf{1}_{\\{x \\in (g(\\alpha), g(\\beta))\\}}\\).\nQuelle est la densit√© de la variable \\(aX+b\\), o√π \\(a&gt;0\\) et \\(b\\in \\mathbb{R}\\) sont fix√©s?\n\nSoit \\(Y \\sim \\mathcal{N}(0,1)\\). Quelle est la densit√© de \\(Z = \\exp(Y)\\)?"
  },
  {
    "objectID": "exercices/td1.html#lois-usuelles-calculs-de-loi",
    "href": "exercices/td1.html#lois-usuelles-calculs-de-loi",
    "title": "Variables al√©atoires r√©elles",
    "section": "Lois usuelles, calculs de loi",
    "text": "Lois usuelles, calculs de loi\n\nExercice 9\n(Fonctions de r√©partition et fonctions caract√©ristiques de lois usuelles)\n\n\n\n\n\n\nAttention : dans le cas d‚Äôune variable continue, quand on calcule \\(\\Phi_X\\) on %doit int√©grer sur \\(\\mathbb{R}\\) une fonction complexe. Trois m√©thodes sont envisageables.\nParfois on peut int√©grer s√©par√©ment partie r√©elle et partie imaginaire.\nParfois il est utile de se servir de la formule de Cauchy. En particulier, cette formule assure que si \\(f\\) est une fonction holomorphe, si \\(\\mathcal{C}\\) est un contour ferm√© ‚Äúraisonnable‚Äù (en particulier tout cercle ou polygone r√©gulier), et enfin si \\(\\overset{\\circ}{\\mathcal{C}}\\) d√©signe l‚Äôensemble des points se trouvant √† l‚Äôint√©rieur de ce contour, alors\n\\[\\forall a \\in \\overset{\\circ}{\\mathcal{C}}, \\quad f(a) = \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}}  \\frac{f(z)}{z-a} \\mathrm{d}z.\\]\nAttention : cette formule montre bien que l‚Äôon ne peut pas traiter l‚Äôint√©grale d‚Äôune fonction complexe en faisant ‚Äúcomme si‚Äù \\(i\\) √©tait r√©√©l (!) La m√©thode des r√©sidus est en outre une cons√©quence directe de la formule de Cauchy.\nEnfin, on peut utiliser le prolongement analytique (voir l‚Äôexemple de la fonction \\(\\Gamma\\)).\n\n\n\n\nExprimer le plus simplement \\(F_X\\) dans les cas suivants (on pourra se contenter de tracer l‚Äôallure du graphe de la fonction de r√©partition lorsque celle-ci ne poss√®de pas d‚Äôexpression simple).\n\n\\(n \\in \\mathbb{N}^*, p \\in [0,1], X \\sim \\text{Bin}(n,p)\\),\n\\(\\lambda&gt;0, X \\sim \\text{Poisson}(\\lambda)\\),\n\\(a&gt;0, X\\sim \\text{Unif}[-a,a]\\),\n\\(\\lambda&gt;0, X \\sim \\mathbf{exp}(\\lambda)\\),\n\\(\\lambda&gt;0, s \\in \\mathbb{N}^*\\), \\(X \\sim \\Gamma(\\lambda, s)\\) (on rappelle que la densit√© \\(f_X\\) de \\(X \\sim \\Gamma(\\lambda,s)\\) est telle que \\(f_X(x) =\\frac{1}{\\Gamma(s)} \\lambda^s x^{s-1}\\exp(-\\lambda x) \\mathbf{1}_{[0,\\infty[}(x), x \\in \\mathbb{R}\\)),\n\\(X \\sim \\mathcal{N}(0,1)\\),\n\\(\\mu \\in \\mathbb{R}, \\sigma&gt;0, X \\sim \\mathcal{N}(\\mu,\\sigma^2)\\).\n\n\\(a&gt;0, X \\sim \\mathrm{Cauchy}(a)\\) (on rappelle que la densit√© \\(f_X\\) de la loi de Cauchy de param√®tre \\(a\\) est telle que \\(f_X(x) = \\frac{a}{\\pi(x^2+a^2)}, x\\in \\mathbb{R}\\)).\n\n(*) \\(X \\sim \\mathrm{stable}(1/2)\\) (cette loi a pour densit√© \\(\\sqrt{2\\pi x^{-3}} \\exp(-1/2x)\\mathbf{1}_{[0,\\infty[}(x).\\))\n\nLesquelles parmi ces variables poss√®dent une densit√©?\n\nExprimer le plus simplement \\(\\Phi_X\\) pour les \\(7\\) premi√®res variables de la premi√®re question ci-dessus. En d√©duire, ou trouver par un calcul direct, \\(E[X],\\) et \\(\\mathrm{Var}[X]\\).\n\n\n\nExercice 10\nPour des valeurs de \\(t\\) que l‚Äôon pr√©cisera, calculer la transform√©e de Laplace \\(L(t) := \\mathbb{E}[\\exp(-t X)]\\) et la fonction g√©n√©ratrice des moments \\(G(u) := \\mathbb{E}[u^X]\\) de la variable \\(X\\) dans les cas suivants.\n\n\\(X \\sim \\mathrm{Ber}(p)\\), o√π \\(p \\in [0,1]\\),\n\\(X \\sim \\mathrm{Bin}(n,p)\\), o√π \\(n \\in \\mathbb{N}^*, p \\in [0,1]\\),\n\\(X \\sim \\mathrm{Geom}(p)\\), o√π \\(p \\in [0,1]\\),\n\\(X \\sim \\mathrm{Poisson}(\\lambda)\\), o√π \\(\\lambda&gt;0\\),\n\n\\(X=Y_1+...+Y_n\\), o√π les \\(Y_i, 1 \\le i \\le n\\) sont des variables ind√©pendantes, et \\(Y_i \\sim \\mathrm{Poisson}(\\lambda_i)\\), avec \\(\\lambda_i &gt;0\\).\n\n\n\nExercice 11\nSoit \\(X\\) une v.a.r. de densit√© \\(f\\). Quelle est la densit√© de \\(X^2\\)? Qu‚Äôobtient-on dans le cas o√π \\(X \\sim \\mathcal{N}(0,1)\\)?\n\n\nExercice 12\nSoit \\(X \\sim \\exp(1)\\). Calculer la densit√© des variables suivantes :\n\n\\(Y = aX+b\\), o√π \\(a&gt;0\\) et \\(b \\in \\mathbb{R}\\). Qu‚Äôobserve-t-on dans le cas o√π \\(b=0\\)?\n\n\\(Z = X^2\\).\n\\(U = \\exp(-X)\\).\n\n\n\nExercice 13\nTrouver la loi de \\(\\arcsin(X)\\) lorsque\n\n\\(X \\sim \\mathrm{Unif}[0,1]\\),\n\\(X \\sim \\mathrm{Unif}[-1,1]\\).\n\n\n\nExercice 14\nOn souhaite peindre un mur (infini!) en utilisant un arroseur automatique qui effectue des demi-r√©volutions successives. Pour simplifier le mod√®le, on repr√©sentera le mur par une droite verticale \\(\\Delta\\), et l‚Äôarroseur par une source ponctuelle \\(O\\) situ√©e √† \\(1\\) m√®tre du mur, et √©mettant en tout instant \\(t\\) de fa√ßon parfaitement rectiligne dans la direction \\(\\overset{\\rightarrow}{u}(t)\\). On note \\(M\\) la projection orthogonale de \\(O\\) sur \\(\\Delta\\) et \\(\\theta(t)\\) l‚Äôangle entre \\(O \\overset{\\rightarrow}{u}(t)\\) et \\(\\overset{\\rightarrow}{OM}\\). L‚Äôintersection de \\(O\\overset{\\rightarrow}{u}\\) avec \\(\\Delta\\) est not√©e \\(H(\\theta)\\).\nOn suppose en outre que lors d‚Äôune demi-r√©volution, \\(\\theta(t)\\) parcourt exactement l‚Äôintervalle \\((-\\pi/2,\\pi/2)\\).\nOn fait l‚Äôhypoth√®se que la demi-r√©volution s‚Äôeffectue √† vitesse angulaire constante, et on se demande quelle sera la r√©partition de l‚Äô√©paisseur de la couche de peinture le long de \\(\\Delta\\) apr√®s un nombre entier de demi-r√©volutions.\n\nJustifier qu‚Äôune particule de peinture choisie uniform√©ment au hasard parmi toutes les particules est envoy√©e suivant un angle \\(\\theta \\sim \\mathrm{Unif}(-\\pi/2,\\pi/2)\\). Une telle particule se pose alors en \\(H(\\theta)\\), On note \\(h(\\theta)\\) l‚Äôordonn√©e de \\(H(\\theta)\\) (c‚Äôest √©galement la distance alg√©brique entre \\(O\\) et \\(H\\)).\nExprimer \\(h(\\theta)\\) en fonction de \\(\\theta\\). Quelle est la loi de \\(h(\\theta)\\)? Que pouvez-vous en d√©duire sur la distribution de l‚Äô√©paisseur de la couche de peinture le long du mur?\nA posteriori, quelle critique peut-on formuler sur le mod√®le?\n\n\n\nExercice 15\nSoit \\(X \\sim \\mathrm{Cauchy}\\) (de param√®tre \\(1\\)).\nQuelle est la loi de\n\n\\(Y:=\\frac{1}{X}\\)?\n\\(Z:= \\frac{1}{1+X^2}\\)?\n\n\n\nExercice 16\nSoit \\(Z \\sim \\mathcal{N}(0,1)\\). Montrer que pour tout \\(x&gt;0\\),\n\\[\\left(x^{-1}-x^{-3}\\right) \\exp(-x^2/2) \\le \\sqrt{2\\pi} \\mathbb{P}(Z&gt;x) \\le x^{-1} \\exp(-x^2/2).\\]\nIndication : on pourra penser √† utiliser le changement de variable \\(y=x+z\\) pour obtenir l‚Äôin√©galit√© de droite, et on commencera par calculer la d√©riv√©e de \\(\\left(x^{-1}-x^{-3}\\right) \\exp(-x^2/2)\\) pour obtenir celle de gauche.\n\n\nExercice 17 (calcul d‚Äôune loi conditionnelle discr√®te)\nSoient \\(X_1,...,X_n\\) des variables de Poisson, ind√©pendantes, de param√®tres respectifs \\(\\lambda_1,...,\\lambda_n\\).\n\nD√©terminer la loi de \\(Y:=\\sum_{k=1}^n X_k\\).\nPour \\(r \\in \\mathbb{N}\\), que vaut la loi conditionnelle de \\((X_1,...,X_n)\\) sachant \\(Y=r\\)?"
  },
  {
    "objectID": "exercices/td1.html#exemples-divers",
    "href": "exercices/td1.html#exemples-divers",
    "title": "Variables al√©atoires r√©elles",
    "section": "Exemples divers",
    "text": "Exemples divers\n\nExercice 18\nOn suppose que le nombre \\(X\\) d‚Äôoeufs pondus par un insecte suit une loi de Poisson de param√®tre \\(\\lambda&gt;0\\) et que la probabilit√© qu‚Äôun oeuf meurt sans √©clore est, ind√©pendamment des autres oeufs, √©gale √† \\(1-p\\), o√π \\(p \\in ]0,1[\\).\n\nD√©montrer que le nombre \\(Y\\) d‚Äôoeufs qui arrivent √† √©closion suit une loi de Poisson de param√®tre \\(\\lambda p\\).\nQuelle est la loi jointe de \\((Y,Z)\\), o√π \\(Z= X-Y\\) est le nombre d‚Äôoeufs morts avant √©closion?\n\n\n\nExercice 19\n(Somme d‚Äôexponentielles et \\(\\chi^2\\))\nSoit \\(\\lambda&gt;0\\) et \\((Y_i)_{1 \\le i \\le n}\\) des variables i.i.d, \\(\\sim \\exp(\\lambda)\\).\n\nCalculer \\(\\mathbb{E}[\\exp(-tY_1)]\\) pour \\(t \\ge 0\\).\n\nCalculer \\(\\mathbb{E}\\left[\\exp(-t\\sum_{i=1}^n) Y_i \\right]\\) pour \\(t \\ge 0\\).\nMontrer que la densit√© de la variable \\(X= \\sum_{i=1}^n Y_i\\) est proportionnelle √† \\(x^{n-1} \\exp(-\\lambda x) \\mathbf{1}_{x \\ge 0}\\). En d√©duire la valeur de cette densit√©.\nSoient \\(X_n, n \\ge 1\\) des variables i.i.d, \\(\\sim \\mathcal{N}(0,1)\\). On pose \\(\\chi^2(n):=\\sum_{i=1}^n X_i^2\\), \\(Z:=X_1X_2 +X_3X_4\\). \\ Calculer \\(\\Phi_{\\chi^2(n)}, \\Phi_Z\\). Pouvez-vous deviner la distribution de \\(Z\\) (on pourra utiliser un r√©sultat d‚Äôun exercice pr√©c√©dent)?\n\n\n\nExercice 20\nSoit \\(Z = (X, Y )\\), une variable al√©atoire √† valeurs dans \\(\\mathbb{R}^2\\). On suppose que \\(Z\\) admet une densit√© \\(f\\) d√©finie par\n\\[f(x, y) = \\frac{4}{\\pi \\sigma^2} \\exp\\left(-\\frac{x^2+y^2}{\\sigma^2}\\right) \\mathbf{1}_{\\{x \\ge |y|\\}},\\]\no√π \\(\\sigma&gt;0\\).\n\nV√©rifier que \\(f\\) est bien une densit√© de probabilit√©.\nCalculer les lois de \\(X\\) et de \\(Y\\) . Les variables al√©atoires \\(X\\) et \\(Y\\) sont-elles ind√©pendantes ?\nCalculer la loi de \\((X - Y, X + Y )\\) et montrer que \\(X - Y\\) et \\(X + Y\\) sont ind√©pendantes.\n\n\n\nExercice 21\n\nSoit \\(X_1,...,X_n\\) des variables i.i.d, \\(\\sim \\mathcal{N}(0,1)\\), et \\(Z=\\sum_{i=1}^n \\alpha_i X_i\\) (o√π les \\(\\alpha_i, i=1,...,n\\) sont de r√©√©ls fix√©s). Quelle est la loi de \\(Z\\)?\nSoit \\((X_1,...,X_n) \\sim \\mathcal{N}(0,A)\\). Quelle est la loi de \\(Z=\\sum_{i=1}^n \\alpha_i X_i\\)?\nSoit \\((X_1,...,X_n) \\sim \\mathcal{N}(0,A)\\). Quelle est la loi de \\((Z_1,Z_2)\\), o√π, pour des r√©√©ls \\(\\alpha_{i,1}, \\alpha_{i,2}, i=1,...,n\\) fix√©s, \\[  Z_1=\\sum_{i=1}^n \\alpha_{i,1} X_i,  Z_2=\\sum_{i=1}^n \\alpha_{i,2} X_i.\\]\nG√©n√©raliser la question pr√©c√©dente en exprimant la loi de \\[ (Z_1,...,Z_n) =  (X_1,...,X_n) P,\\] o√π \\(P\\) est une matrice \\(n \\times n\\).\nSoient \\(X,Y\\) deux variables ind√©pendantes, \\(\\sim \\mathrm{Unif}[0,1]\\). Quelle est la loi de \\(S=X+Y\\)?\nSoient \\(X, Y\\) des variables ind√©pendantes de loi respectives \\(\\Gamma(a,c), \\Gamma(b,c)\\), o√π \\(a,b,c&gt;0\\). On pose \\(S=X+Y,\nT= \\frac{X}{X+Y}\\) Quelle est la loi du couple \\((S,T)\\)?\nSoient \\(X,Y\\) deux variables ind√©pendantes, \\(\\sim \\mathrm{Unif}[0,1]\\). On pose \\(U = \\sqrt{-2\\log(X)} \\cdot \\cos(2\\pi Y), V = \\sqrt{-2\\log(X)} \\cdot \\sin(2\\pi Y)\\). Quelle est la loi du couple \\((X,Y)\\)?\nSoient \\(X,Y\\) deux variables ind√©pendantes, \\(\\sim \\mathcal{N}(0,1)\\). On pose \\(T = \\frac{Y}{X}\\). Quelle est la loi de \\(T\\)?\nSoient \\((X,Y)\\) un couple de variables ind√©pendantes, \\(\\sim \\mathcal{N}(0,1)\\). On pose \\(U=X, V= X^2 + Y^2\\). Quelle est la loi de \\((U,V)\\)?\nSoit \\(X\\) de densit√© \\(\\exp(-x) \\mathbf{1}_{\\mathbb{R}_+}(x)\\). On pose \\(U = [X]\\) et \\(V= X-[X]\\), la partie enti√®re, resp. la partie d√©cimale de \\(X\\). Quelle est la loi de \\((U,V)\\)?\n\n\n\nExercice 22\nSoient \\(X_1, X_2\\) deux variables ind√©pendantes et identiquement distribu√©es suivant la loi \\(\\mathrm{Unif}\\{1,2,3\\}\\).\nOn note \\(U = \\min\\{X_1,X_2\\}\\), \\(V= \\max\\{X_1,X_2\\}\\) et enfin \\(S= U+V\\).\n\nD√©terminer la loi jointe de \\((U, V)\\) et \\((V, S)\\).\nEn d√©duire les lois de \\(U, V\\), et \\(S\\). Calculer les lois de \\(UV\\) et \\(VS\\).\nCalculer les covariances et les coefficients de corr√©lation de \\((U, V)\\) et \\((V, S)\\)."
  },
  {
    "objectID": "exercices/td1.html#le-cadre-gaussien",
    "href": "exercices/td1.html#le-cadre-gaussien",
    "title": "Variables al√©atoires r√©elles",
    "section": "Le cadre gaussien",
    "text": "Le cadre gaussien\n\nExercice 23\nOn consid√®re deux variables ind√©pendantes \\(Y \\sim \\mathcal{N}(0,1)\\) et\n\\[\\varepsilon= \\begin{cases} & 1 \\mbox{ avec probabilit√© } p \\\\ & -1 \\mbox{ avec probabilit√© } 1-p, \\end{cases}\\]\no√π \\(p \\in (0,1)\\).\n\nQuelle est la loi de \\(Z= \\varepsilon Y\\)\nQuelle est la loi de \\(Y+Z\\)?\nLe vecteur \\((Y,Z)\\) est-il un vecteur gaussien?\n\n\n\nExercice 24\nSoit \\((X,Y,Z)\\) le vecteur al√©atoire gaussien d‚Äôesp√©rance \\((1,1,0)\\) et de matrice de covariance\n\\[K = \\begin{pmatrix} 2 & 1 & 1 \\\\ 1 & 2 & 2 \\\\ 1 & 2 & 2  \\end{pmatrix}.\\]\n\nEcrire la fonction caract√©ristique de \\((X,Y,Z)\\).\n\nTrouver la loi de \\(2X+Y+Z\\), de \\(4X-2Y+Z\\), enfin de \\(Y-Z\\).\nLe vecteur \\((X,Y)\\) admet-il une densit√© dans \\(\\mathbb{R}^2\\). Si oui, laquelle?\nPour \\(a \\in \\mathbb{R}\\) on d√©finit \\(u_a : \\mathbb{R}^3 \\to \\mathbb{R}^3\\) de matrice\n\\[A = \\begin{pmatrix} 1/\\sqrt{2} & 0 & 0 \\\\ a & -2a & 0 \\\\ 0 & 1 & -1\\end{pmatrix}.\\]\nD√©terminer la loi de \\(u_a(X-1,Y-1,Z)\\) en fonction de \\(a\\).\nPour quelle valeur de \\(a\\) les deux premi√®res coordonn√©es de \\(u_a(X-1,Y-1,Z)\\) suivent-ils une loi normale centr√©e r√©duite sur \\(\\mathbb{R}^2\\)?\n\n\n\nExercice 25\nSoit \\(\\rho\\in ]-1,1[\\) et \\((X,Y)\\) un vecteur gaussien centr√© de matrice de covariances \\(M = \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix}\\). On notera \\(\\sigma = \\sqrt{1-\\rho^2}\\).\n\nCalculer det(\\(M\\)), \\(M^{-1}\\), puis exprimer la densit√© \\(f_{(X,Y)}\\) du vecteur \\((X,Y)\\).\nMontrer que\n\\[g_x(y) := \\frac{f_{(X,Y)}(x,y)}{f_X(x)} = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( - \\frac{1}{2(1-\\rho^2)} \\left(y-\\rho x\\right)^2\\right).\\]\nMontrer que pour tout \\(x \\in \\mathbb{R}\\), \\(y \\to g_x(y)\\) d√©finit une densit√©.\nSi on note \\(Y_x\\) une variable de densit√© \\(g_x\\), que pouvez-vous dire sur la loi de \\(Y_x\\)?\n\nTrouver \\(\\alpha\\), \\(\\beta\\) deux r√©els tels que \\((X, \\alpha X + \\beta Y)\\) suit la loi normale centr√©e r√©duite.\n\nRemarquer que l‚Äôon peut √©crire \\(Y= -\\frac{\\alpha}{\\beta} X +\\frac{1}{\\beta}(\\alpha X + \\beta Y)\\). Sauriez-vous dire pourquoi cette √©criture est int√©ressante?\n\n\nExercice 26\nMontrer que le vecteur al√©atoire de dimension \\(3\\) de moyenne \\(m = (7,0,1)\\) et de matrice de covariances\n\\[K = \\begin{pmatrix} 10 & -1 & 4 \\\\ -1 & 1 & -1 \\\\ 4 & -1 & 2 \\end{pmatrix}\\]\nappartient presque s√ªrement √† un hyperplan affine de \\(\\mathbb{R}^3\\) que l‚Äôon d√©terminera."
  },
  {
    "objectID": "exercices/td2.html",
    "href": "exercices/td2.html",
    "title": "MA1AY010 Probabilit√©s",
    "section": "",
    "text": "NoteTD II : Esp√©rances et lois conditionnelles\n\n\n\n22 Septembre 2025-26 Septembre 2025\n\nMaster I Isifar\nProbabilit√©s\n\n\n\n\nExercice 1\n\n\n\n\n\n\nNoteCours\n\n\n\nEsp√©rance conditionnelle par rapport √† une tribu engendr√©e par une partition d√©nombrable.\n\n\n\nSoit \\((A_n, n \\in \\mathbb{N}^*)\\) une partition de \\(\\Omega\\) et \\(\\mathcal{F}= \\sigma(A_n, n \\ge 1)\\) la tribu engendr√©e par les \\(A_n, n \\ge 1\\). Rappelons qu‚Äôune v.a.r. \\(Y\\) est \\(\\mathcal{F}\\)-mesurable si et seulement si il existe une suite de r√©ls \\((a_n)\\) telle que \\(Y= \\sum_{n \\ge 1} a_n \\mathbf{1}_{A_n}\\). Exprimer \\(\\mathbb{E}[X \\mid \\mathcal{F}]\\).\nSoient \\(X,Y\\) deux variables i.i.d. \\(\\sim\\) Ber\\((p)\\). On consid√®re \\(\\mathcal{G} = \\sigma(\\{X+Y=0\\})\\). Calculer \\(\\mathbb{E}[X \\mid \\mathcal{G}], \\mathbb{E}[Y\\mid \\mathcal{G}]\\). Les variables obtenues sont-elles toujours ind√©pendantes?\n\n\n\nExercice 2\n\n\n\n\n\n\nNoteCours\n\n\n\nConditionnement continu\n\n\nSoient \\((X,Y)\\) un couple de v.a. r√©elles int√©grables de densit√© jointe \\(f\\), \\(g : \\mathbb{R}^2 \\to \\mathbb{R}\\) bor√©lienne telle que \\(g(X,Y) \\in \\mathbb{L}^1\\).\nRappeler l‚Äôexpression de \\(\\phi, \\psi\\) telles que \\[\\mathbb{E}[g(X,Y)\\mid Y] = \\phi(Y), \\quad \\mathbb{E}[g(X,Y)|X] = \\psi(X).\\]\n\nOn consid√®re \\((X,Y)\\) de densit√© jointe \\(f(x,y)= \\frac{1}{x} \\mathbf{1}_{\\{0 \\le y \\le x \\le 1\\}}.\\) Quelle est la loi de \\(X\\)? Calculer la distribution conditionnelle \\(f_{Y \\mid X}\\) de \\(Y\\) sachant \\(X\\). Calculer \\(\\mathbb{P}(X^2 +Y^2 \\le 1 |X)\\), puis en d√©duire \\(\\mathbb{P}(X^2+Y^2 \\le 1)\\).\nPour simplifier l‚Äôexpression obtenue on pourra utiliser que \\(x \\to \\sqrt{1-x^2} - \\tanh^{-1}(\\sqrt{1-x^2}) = \\sqrt{1-x^2}-\\frac{1}{2} \\ln(1+\\sqrt{1-x^2}) + \\frac{1}{2} \\ln(1-\\sqrt{1-x^2})\\) est une primitive de \\(x \\to \\frac{\\sqrt{1-x^2}}{x}\\).\nDans le cas g√©n√©ral, montrer que \\(\\mathbb{E}[\\mathbb{E}[Y|X]] = \\mathbb{E}[Y]\\). Que vaut \\(\\mathbb{E}[Y]\\) dans l‚Äôexemple de la question pr√©c√©dente?\nMontrer, dans le cas g√©n√©ral, que \\[ \\mathbb{E}[\\mathbb{E}[Y|X] g(X)] = \\mathbb{E}[Yg(X)],\\] pour toute fonction \\(g\\) telle que les deux esp√©rances sont d√©finies. Que vaut \\(\\mathbb{E}[Y g(X) \\mid X]\\)?\n\n\n\nExercice 3\n\n\n\n\n\n\nNotePartiel pass√©\n\n\n\n\n\n\nSoient \\(0 \\le r \\le p \\le 1\\) tels que \\(1-2p+r \\ge 0\\).\nSoient \\(X_1, X_2\\) tels que\n\\[\\begin{eqnarray*}\n&&  \\mathbb{P}(X_1=1, X_2=1)=r, \\quad   \\mathbb{P}(X_1=0, X_2=1)=p-r, \\\\\n&& \\mathbb{P}(X_1=1, X_2=0)=p-r, \\quad  \\mathbb{P}(X_1=0, X_2=0)=1-2p+r.\n\\end{eqnarray*}\\]\n\nQuelle est la loi de \\(X_1\\)? celle de \\(X_2\\)?\nCalculer \\(Y = \\mathbb{E}[X_1\\mid X_2]\\) et v√©rifier que \\[Y= \\begin{cases} & \\frac{p-r}{1-p} \\mbox{ avec probabilit√© } 1-p\\\\\n& \\frac{r}{p} \\mbox{ avec probabilit√© } p.\\end{cases}\\]\nRappelons que par d√©finition \\(\\mathrm{Var}[X_1 \\mid X_2] = \\mathbb{E}[X_1^2\\mid X_2] - \\mathbb{E}[X_1\\mid X_2]^2\\). Montrer que \\[\\mathrm{Var}[X_1 \\mid X_2] = \\left( \\frac{p-r}{1-p} - \\left(\\frac{p-r}{1-p}\\right)^2\n\\right) \\mathbf{1}_{\\{X_2=0\\}} + \\left( \\frac{r}{p} - \\left(\\frac{r}{p}\\right)^2 \\right)\n\\mathbf{1}_{\\{X_2=1\\}}.\\]\nQue vaut \\(\\mathrm{Var}(\\mathbb{E}[X_1\\mid X_2])\\)? \\(\\mathbb{E}[\\mathrm{Var}[X_1\\mid X_2]]\\)? V√©rifier qu‚Äôon a bien \\[\\mathrm{Var}(X_1) = \\mathrm{Var}(\\mathbb{E}[X_1\\mid X_2]) + \\mathbb{E}[\\mathrm{Var}[X_1\\mid X_2]].\\]\n\n\n\nExercice 4\nSoit \\((X_n)\\) une suite de v.a. .i.i.d int√©grables, et \\(S_n = \\sum_{i=1}^n X_i\\).\n\nQue valent \\(\\mathbb{E}[X_1\\mid X_2], \\mathbb{E}[S_n \\mid X_1], \\mathbb{E}[S_n \\mid S_{n-1}]?\\)\nMontrer que si les paires de variables \\((X,Z)\\), \\((Y,Z)\\) ont la m√™me loi jointe, alors pour toute fonction r√©elle positive (ou satisfaisant une condition d‚Äôint√©grabilit√©), \\(\\mathbb{E}[f(X)\\mid Z] = \\mathbb{E}[f(Y)\\mid Z]\\). En d√©duire \\(\\mathbb{E}[X_1 \\mid S_n]\\).\n\n\n\nExercice 5\n\n\n\n\n\n\nNote(Examen pass√©)\n\n\n\n\n\n\nSoit \\((X_n, n \\ge 0)\\) une suite de variables i.i.d, avec \\(X_1 \\sim \\text{Ber}(1/2)\\). On pose \\(S_n = \\sum_{i=1}^n (X_i -1/2)\\), \\(\\mathcal{F}_n= \\sigma(X_1,...,X_n)\\).\nCalculer \\(\\mathbb{E}[S_n \\mid \\mathcal{F}_5]\\) en fonction de \\(n\\). Quelle est la loi de cette variable al√©atoire?\n\n\nExercice 6\n\n\n\n\n\n\nNotePartiel pass√©\n\n\n\n\n\n\nSoient \\(\\{\\mathbf{e}_i, i \\in \\mathbb{N} \\}\\) des variables i.i.d exponentielles de param√®tre \\(1\\). Pour \\(n \\in \\mathbb{N}^*\\) on note \\(S_n := \\sum_{i=1}^n \\mathbf{e}_i\\).\n\nOn note \\(f_n\\) la fonction de densit√© de la variable \\(S_n\\). Montrer que pour tout \\(t \\ge 0\\) \\[ f_n(t) = \\frac{t^{n-1}}{(n-1)!} \\exp(-t).\\]\nPour \\(t &gt;0, n \\in \\mathbb{N}^*\\), que vaut \\(\\mathbb{P}(S_n \\le t)\\)?\nOn fixe \\(t&gt;0\\) et on suppose \\(X_t \\sim \\mathrm{Poisson}(t)\\). Que vaut \\(\\mathbb{P}(X_t \\ge n)\\), pour \\(n \\in \\mathbb{N}^*\\)?\nSur la demi-droite \\(\\mathbb{R}_+\\) on place les points \\(S_1, S_2, S_3,...\\). On note \\(N_t\\) le nombre de ces points qui tombent dans l‚Äôintervalle \\([0,t]\\). Exprimer l‚Äô√©v√©nement \\(\\{N_t \\ge n\\} = \\{S_n \\le t\\}\\). D√©terminer la loi de \\(N_t\\) √† l‚Äôaide des questions pr√©c'dentes.\n\nMontrer que, conditionnellement √† \\(\\{N_t=1\\}\\), la loi de \\(\\mathbf{e}_1\\) est uniforme sur \\([0,t]\\).\nConditionnellement √† \\(\\{N_t=2\\}\\), quelle est la loi du vecteur \\((\\mathbf{e}_1; \\mathbf{e}_2)\\)?\n\n\n\nExercice 7\n\n\n\n\n\n\nNoteCC2 2023\n\n\n\n\n\n\nOn consid√®re \\[ X \\sim \\mathcal{N} \\left( \\begin{pmatrix} -1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 2 & 1 & -1 & -1 \\\\ 1 & 2 & -1 & 0 \\\\ -1 & -1 & 3 & -1 \\\\ -1 & 0 & -1 & 5 \\end{pmatrix}\\right).\\]\n\nCalculer \\(\\mathbb{E}[X_3 \\mid X_4]\\), et d√©terminer la loi conditionnelle de \\(X_3\\) sachant \\(X_4\\).\n\nOn pose \\(A = \\begin{pmatrix} 2  & 1 \\\\ 1 & 2 \\end{pmatrix}\\), \\(B= \\begin{pmatrix} -1 & -1 \\\\ -1 & 0 \\end{pmatrix}\\). Calculer \\(BA^{-1}\\), puis v√©rifier que \\[B A^{-1} B^T = \\begin{pmatrix} \\frac{2}{3} & \\frac{1}{3} \\vspace{0.1cm} \\\\ \\frac{1}{3} & \\frac{2}{3}\\end{pmatrix}.\\]\nD√©terminer \\(\\mathbb{E}\\left[\\begin{pmatrix} X_3 \\\\ X_4 \\end{pmatrix} \\ \\bigg| \\ \\begin{pmatrix} X_1 \\\\ X_2 \\end{pmatrix}\\right]\\). et la loi conditionnelle de \\(\\begin{pmatrix} X_3 \\\\ X_4 \\end{pmatrix}\\) sachant \\(\\begin{pmatrix} X_1 \\\\ X_2 \\end{pmatrix}\\).\n\n\n\nExercice 8\n\n\n\n\n\n\n(Partiel pass√©)\n\n\n\nSoit \\((X_1,X_2,X_3) \\sim \\mathcal{N}(\\mu, M)\\) o√π \\[\\mu = \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix}, \\quad M = \\begin{pmatrix} 2 & 1 & 0 \\\\ 1 & 2 & 1 \\\\ 0 & 1 & 2 \\end{pmatrix}.\\]\n\nQuelle est la loi du couple \\((X_1,X_2)\\)?\nD√©terminer \\(\\alpha\\) un r√©el tel que $Y = X_1 + X_2 $ est ind√©pendante de \\(X_1\\). Que vaut \\(\\mathbb{E}[Y]\\)? \\(\\text{Var}(Y)\\)?\nEn d√©duire \\(\\mathbb{E}[X_2 \\mid X_1]\\). Quelle est la loi conditionnelle de \\(X_2\\) sachant \\(X_1\\)?\nD√©terminer un r√©el \\(\\beta\\) tels que \\(Z=\\beta X_1 + X_3\\) est ind√©pendante de \\(X_1\\). En d√©duire \\[ \\mathbb{E}[X_3 \\mid X_1], \\quad \\mathbb{E}[X_3^2 \\mid X_1].\\]\nCalculer \\(\\mathbb{E}\\left[X_1^2X_2 + X_3^2 X_1 \\mid X_1\\right]\\).\n\n\n\nExercice 9\n\n\n\n\n\n\nNoteExamen pass√©\n\n\n\n\n\n\nSoit \\((X_1,X_2,X_3) \\sim \\mathcal{N}(\\mu,M)\\), o√π \\[ \\mu = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\qquad M=  \\begin{pmatrix} 1 & 1/2 & 2 \\\\ 1/2 & 1 & 1 \\\\ 2 & 1 & 3 \\end{pmatrix}.\\] Calculer \\(\\mathbb{E}[X_1+2X_2 \\mid X_3].\\) Quelle est la loi conditionnelle de \\(X_1+2X_2\\) sachant \\(X_3\\)?\n\n\nExercice 10\n\n\n\n\n\n\nNote(CC2 2023)\n\n\n\n\n\n\nOn suppose dans cet exercice que \\((X,Y)\\) est un couple de variables al√©atoires tel que pour toute \\(\\phi : \\mathbb{R}^2\\to \\mathbb{R}_+\\) bor√©lienne, \\[ \\mathbb{E}[\\phi(X,Y)] = \\sum_{n \\ge 1} \\frac{2}{3^{n}\\sqrt{2\\pi n}}  \\int_{\\mathbb{R}} \\phi(n,y) \\exp\\left(-\\frac{y^2}{2n}\\right) dy.\\]\n\nMontrer que \\(X \\sim \\mathrm{Geom}(2/3)\\).\nV√©rifier que pour une fonction \\(f : \\mathbb{R} \\to \\mathbb{C}\\) telle que \\(f(Y) \\in \\mathbb{L}^1\\), on a\n\\[ \\mathbb{E}[f(Y) \\mid X] = \\sum_{n \\ge 1} \\left(\\int_{\\mathbb{R}} \\frac{1}{\\sqrt{ 2\\pi n}} f(y) \\exp\\left(-\\frac{y^2}{2n} \\right) dy \\right) \\mathbb{I}_{\\{X=n\\}}\\] %1. En d√©duire que pour tout \\(k \\in \\mathbb{N}\\), %\\[\\mathbb{E}[Y^k \\mid X] = \\frac{k!}{X^{2k}}\\]\nCalculer \\(\\mathbb{E}[\\exp(itY) \\mid X]\\), \\(t \\in \\mathbb{R}\\), quelle est la loi conditionnelle de \\(Y\\) sachant \\(X\\) ?\nD√©duire que si \\(t\\in \\mathbb{R}\\) \\[ \\mathbb{E}[\\exp(itY)] = \\frac{2 \\exp\\left(-\\frac{t^2}{2}\\right)}{3-\\exp\\left(-\\frac{t^2}{2}\\right)}.\\]\n\n\n\nExercice 11\n\n\n\n\n\n\nNotePartiel pass√©\n\n\n\n\n\n\n\nPartie I\nOn consid√®re le couple \\((X,Z)\\) de densit√© jointe \\[ f(x,z) := (z-x)\\exp(-z) \\mathbf{1}_{\\{z \\ge x \\ge 0\\}}.\\]\n\nCalculer la loi de \\(X\\), puis celle de \\(Z\\).\nEn d√©duire que \\[ f_{X \\mid Z}(x \\mid z) = \\frac{2(z-x)}{z^2} \\mathbf{1}_{\\{0 \\le x \\le z, z &gt;0\\}}.\\]\nCalculer \\(\\mathbb{E}[X \\mid Z]\\), puis \\(\\mathrm{Var}[X\\mid Z]\\).\nCalculer \\(f_{Z \\mid X}(z \\mid x)\\), puis d√©montrer que \\(\\mathbb{E}[Z \\mid X] = X + 2\\).\nQuelle est la loi du couple \\((X, Z-X)\\)? En d√©duire la loi de \\(Z-X\\).\n\n\n\nPartie II\n\nSoit \\(z &gt;0\\). On suppose que \\(U_1^z \\sim \\mathrm{Unif}[0,z]\\), \\(U_2^z \\sim\n\\mathrm{Unif}[0,z]\\) et que \\(U_1^z\\) est ind√©pendante de \\(U_2^z\\). Calculer la densit√© de \\(\\min(U_1^z, U_2^z)\\).\nOn suppose √† pr√©sent que {}, \\(U_1^Z \\sim \\mathrm{Unif}[0,Z]\\), \\(U_2^Z \\sim \\mathrm{Unif}[0,Z]\\) et que \\(U_1^Z\\) est (toujours conditionnellement √† \\(Z\\)) ind√©pendante de \\(U_2^Z\\). Montrer que, conditionnellement √† \\(Z\\), \\(\\mathrm{min}(U_1^Z, U_2^Z)\\) a la m√™me loi que X.\nSoient \\(X_1,X_2,X_3\\) trois variables ind√©pendantes, toutes trois distribu√©es suivant la distribution exponentielle de param√®tre \\(1\\). On note \\(S= X_1+X_2+X_3\\). D√©terminer la loi de \\((X_1,S)\\). \\ Que vaut \\(\\mathbb{E}[X_1\\mid S]\\)? \\(\\mathbb{E}[S \\mid X_1]\\)?\\ Montrer finalement que conditionnellement √† \\(S\\), le couple \\((X_1,X_1+X_2)\\) a la m√™me loi que \\(\\left(\\mathrm{min}(U_1^S, U_2^S), \\mathrm{max}(U_1^S, U_2^S)\\right)\\).\n\n\n\n\nExercice 12\n\n\n\n\n\n\nNotePartiel pass√©\n\n\n\n\n\n\nPour \\((x,y) \\in \\mathbb{R}^2\\) on d√©finit\n\\[f(x,y) := \\frac{4y}{x^3} \\mathbf{1}_{\\{0&lt;x&lt;1, 0&lt;y &lt;x^2\\}}.\\]\nV√©rifier que \\(f\\) est bien une densit√© de probabilit√©, puis calculer les densit√©s marginales \\(f_X\\), \\(f_Y\\).\nCalculer \\(f_{Y\\mid X}(y \\mid x)\\) et en d√©duire que \\[\\mathbb{E}[Y \\mid X] = \\frac{2}{3} X^2.\\]\nMontrer que \\[ f_{X \\mid Y}(x\\mid y) = \\frac{2y}{1-y} \\frac{1}{x^3} \\mathbf{1}_{\\{0&lt;x&lt;1, 0&lt;y &lt;x^2\\}},\\] puis calculer \\(\\mathbb{E}[X \\mid Y]\\).\n\n\nExercice 13\n\n\n\n\n\n\nNoteCC2 2023\n\n\n\n\n\n\nDans cet exercice on suppose que \\[ \\begin{pmatrix} X \\\\ Y\\end{pmatrix} \\sim \\mathcal{N} \\left( \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 2 & 1 \\\\ 1 & 1 \\end{pmatrix} \\right),\\]\net on pose \\(U= X^2\\).\n\nV√©rifier que \\(U \\sim \\mathrm{Gamma}(1/2,1/4)\\).\nMontrer que \\((X,Y)\\) poss√®de une densit√© jointe \\(g\\) que l‚Äôon d√©terminera.\n\nMontrer que \\((U,Y)\\) poss√®de la densit√© jointe \\[ f(u,y) = \\frac{1}{{ 4} \\pi \\sqrt{u}} \\left( \\exp\\left(- \\frac{u}{2} - y^2 + y \\sqrt{u} \\right) + \\exp\\left(-\\frac{u}{2}- y^2 - y\\sqrt{u} \\right) \\right) \\mathbb{I}_{\\{u &gt;0\\}}. \\]\nCalculer \\(f_{Y \\mid U}(y \\mid u)\\). En d√©duire \\(\\mathbb{E}[Y \\mid U], \\mathbb{E}[Y^2 \\mid U]\\) et \\(\\mathrm{Var}(Y \\mid U)\\). V√©rifier qu‚Äôon a bien \\[\\mathrm{Var}[Y] = \\mathbb{E}[\\mathrm{Var}[Y \\mid U]] + \\mathrm{Var}[\\mathbb{E}[Y \\mid U]]\\, .\\]\nOn suppose que conditionnellement √† \\(U\\), \\(\\xi\\) et \\(Z\\) sont ind√©pendantes avec \\(\\xi \\sim \\mathrm{Ber}(1/2)\\) et \\(Z \\sim \\mathcal{N}\\left(\\frac{\\sqrt{U}}{2},\\frac{1}{2}\\right)\\). Montrer que conditionnellement √† \\(U\\), \\((2\\xi-1) Z\\) a m√™me loi que \\(Y\\). V√©rifier alors les calculs de la question pr√©c√©dente.\n\n\n\n\n\n\n\nTipIndications\n\n\n\n\nrappelle que pour \\(a&gt;0, \\lambda &gt;0\\), la densit√© d‚Äôune variable \\(G \\sim \\mathrm{Gamma}(a,\\lambda)\\) est donn√©e par \\[ f_G(x) = \\frac{\\lambda^a x^{a-1}}{\\Gamma(a)} \\exp(-\\lambda x) \\mathbb{I}_{\\{x &gt;0 \\}}\\]\n\nOn fera attention √† distinguer les domaines \\(D_1 = \\mathbb{R}_-^*\\times \\mathbb{R}\\) et \\(D_2 = \\mathbb{R}_+^* \\times \\mathbb{R}\\) pour pouvoir consid√©rer les \\(\\mathcal{C}^1\\)-diff√©omorphismes \\(\\displaystyle{\\Psi_1 : \\begin{cases} \\!\\!&\\!\\! D_1 \\to \\mathbb{R}_+^* \\times \\mathbb{R} \\\\ \\!\\!&\\!\\! (x,y) \\to (x^2,y) \\end{cases}, \\ \\ \\Psi_2 :  \\begin{cases} \\!\\!&\\!\\! D_2 \\to \\mathbb{R}_+^* \\times \\mathbb{R} \\\\ \\!\\!&\\!\\! (x,y) \\to (x^2,y)\\end{cases}}\\).\n\nPour \\(\\alpha \\in \\mathbb{R}\\), les deux premiers moments de la variable \\(\\zeta \\sim \\mathcal{N}\\left(\\alpha \\frac{\\sqrt{u}}{2}, \\frac{1}{2}\\right)\\) sont \\[\\begin{align*}\n\\mathbb{E}[\\zeta]\n& = \\int_{\\mathbb{R}} \\frac{1}{\\sqrt{\\pi}} y \\exp\\left(-  \\left(y - \\alpha \\frac{\\sqrt{u}}{2}\\right)^2 \\right) dy \\\\\n& = \\alpha \\frac{\\sqrt{u}}{2},  \\\\\n\\mathbb{E}[\\zeta^2]\n& = \\mathbb{E}[\\zeta]^2+ \\mathrm{Var}[\\zeta] = \\int_{\\mathbb{R}} \\frac{1}{\\sqrt{\\pi}} y^2 \\exp\\left(-  \\left(y - \\alpha \\frac{\\sqrt{u}}{2}\\right)^2 \\right) dy \\\\\n& = \\alpha^2 \\frac{u}{4} + \\frac{1}{2}\n\\end{align*}\\]\n\n\n\n\n\nExercice 14\n\n\n\n\n\n\nNoteRattrapage pass√©\n\n\n\n\n\n\nSoit \\(X=(X_1,X_2,X_3) \\sim \\mathcal{N}(0,M)\\), o√π\n\\[M := \\begin{pmatrix} 2& 2 &-2  \\\\ 2& 5 & 1 \\\\ -2 & 1 & 5 \\end{pmatrix},\\]\n\nMontrer que \\(\\det(M)=0\\). Le vecteur \\(X\\) poss√®de-t-il une densit√© dans \\(\\mathbb{R}^3\\)?\nTrouver \\(a \\in \\mathbb{R}\\) tel que \\(X_1\\) et \\(Y=X_2-a X_1\\) soient ind√©pendantes. Calculer \\(\\mathrm{Var}(Y)\\) et en d√©duire la loi de \\((X_1,Y)\\).\nTrouver la loi conditionnelle de \\(X_2\\) sachant \\(X_1\\).\n\n\n\nExercice 15\nOn consid√®re \\(X_0 =0\\), et \\((X_n)_{n \\ge 1}\\) une suite de variables al√©atoires r√©elles ind√©pendantes, identiquement distribu√©es suivant la loi normale centr√©e r√©duite.\nOn introduit les variables\n\\[Y_i = \\frac{X_i-X_{i-1}}{i}, i \\ge 1.\\]\nPour \\(n \\ge 1\\), montrer que le vecteur \\((Y_1,...,Y_n)\\) est gaussien, puis calculer le vecteur moyenne et la matrice de covariances de \\((Y_1,...,Y_n)\\).\nCalculer, pour \\(n \\ge 1\\), \\(\\mathbb{E}[Y_{n+1}\\mid Y_n]\\).\n\n\nExercice 16\nSoient \\((X,Y)\\) dont la loi jointe a pour densit√© \\(f(x,y) = x(y-x) \\exp(-y), 0 \\le x \\le y &lt;\\infty\\). On introduit la notation \\(f_{X|Y}(x|y) := f(x,y)/f_Y(y)\\) lorsque le quotient est \\(&gt;0\\), \\(0\\) sinon.\n\nExprimer \\(f_{X|Y}(x|y)\\), puis \\(f_{Y|X}(y|x)\\).\nEn d√©duire les expressions de \\(\\mathbb{E}[X|Y], \\mathbb{E}[Y|X]\\).\n\n\n\nExercice 17\nSoient \\(Y,Z\\) deux v.a.r. ind√©pendantes \\(\\sim \\mathrm{exp}(\\lambda)\\) o√π \\(\\lambda&gt;0\\). On pose \\(X= Y+Z\\). Quelle est la loi conditionnelle de \\(Y\\) sachant \\(X\\)? Que vaut \\(\\mathbb{E}[Y|X]\\)? En d√©duire l‚Äôexpression de \\(\\mathbb{E}[Y|X]\\)\n\n\nExercice 18\nSoient \\(X\\) et \\(Y\\) deux variables al√©atoires ind√©pendantes, toutes deux normales centr√©es r√©duites. On d√©finit pour \\(\\sigma_1 &gt;0, \\sigma_2&gt;0, |\\rho|\\le 1\\), \\[U = \\sigma_1 X, \\quad V= \\sigma_2 \\rho X + \\sigma_2 \\sqrt{1- \\rho^2} Y.\\]\n\nQuelle est la loi de \\((U,V)\\)?\nQue vaut \\(\\mathbb{E}[UV]\\)?\nQue vaut \\(\\mathbb{E}[U \\mid V]? \\mathbb{E}[V \\mid U]? \\mathrm{Var}[U \\mid V]? \\mathrm{Var}[V \\mid U]?\\)\n\n\n\nExercice 19\nSoit \\(Z = (X, Y )\\) un vecteur al√©atoire gaussien √† valeurs dans \\(\\mathbb{R}^2\\). On suppose que \\(E(X) = E(Y ) = 0\\), \\(\\mathrm{Var}(X) = \\mathrm{Var}(Y ) = 1\\) et que \\(\\mathrm{Cov}(X; Y ) = \\rho\\) avec \\(|\\rho|^2 \\ne 1\\). On pose \\(U = X -\\rho Y , V = \\sqrt{1-\\rho^2} Y\\).\n\nQuelles sont les lois de \\(U\\) et \\(V\\) ? Les v.a. \\(U\\) et \\(V\\) sont-elles ind√©pendantes ?\nCalculer \\(\\mathbb{E}(U^2V^2), \\mathbb{E}(U V^3), \\mathbb{E}(V^4)\\). En d√©duire \\(\\mathbb{E}(X^2Y^2)\\).\nRetrouver ce dernier r√©sultat par conditionnement.\n\n\n\nExercice 20\nSoient \\(U, V, W\\) trois v.a.r. gaussiennes centr√©es r√©duites. On pose \\[Z =\\frac{U + VW}{\\sqrt{1+W^2}}.\\]\n\nQuelle est la loi conditionnelle de \\(Z\\) sachant \\(W\\)?\nEn d√©duire que \\(Z\\) et \\(W\\) sont ind√©pendantes et donner la loi de \\(Z\\).\n\n\n\nExercice 21\nSoient \\(X_1\\) et \\(X_2\\) des v.a. ind√©pendantes, de lois exponentielles de param√®tres respectifs \\(\\lambda_1\\) et \\(\\lambda_2\\).\n\nCalculer \\(\\mathbb{E}[\\max(X_1,X_2) \\mid X_1]\\).\nCalculer \\(\\mathbb{E}[\\max(X_1;X_2)]\\).\n\n\n\nExercice 22\nOn pose \\(h(x) = \\frac{1}{\\Gamma(a+1)} \\exp(-x)x^{a-1}\\) (\\(a &gt; 0\\) fix√©) et \\(D = \\{0 &lt; y &lt; x\\}\\). Soit \\(f(x, y) = h(x)\\mathbf{1}_D(x, y)\\):\n\nMontrer que \\(f\\) est une densit√© de probabilit√© sur \\(\\mathbb{R}^2\\). On consid√®re dans la suite un couple \\((X, Y)\\) de v.a.r. de densit√© \\(f\\).\nLes v.a. \\(X\\) et \\(Y/X\\) sont-elles ind√©pendantes?\nQuelle est la loi conditionnelle de \\(Y\\) sachant \\(X\\) ?\nSoit \\(U\\) une v.a.r. ind√©pendante du couple \\((X, Y)\\) telle que \\(\\mathbb{P}(U = 1) = p\\) et \\(\\mathbb{P}(U = 0) = 1 - p\\). On pose \\(Z = UX + (1 - U)Y\\). Quelle est l‚Äôesp√©rance conditionnelle de \\(Z\\) sachant \\(X\\)?\n\n\n\nExercice 23\nSoit \\((X_n, n \\in \\mathbb{N})\\) une suite de v.a.r.i.i.d. de densit√© \\(f\\) et fonction de r√©partition \\(F\\). Soient \\(N := \\min\\{ n \\ge 1 : X_n &gt;X_0\\}\\) et\n\\(M := \\min \\{n \\ge 1 : X_0 \\ge X_1 \\ge ... \\ge X_{n-1} &lt;X_n \\}.\\)\n\nTrouver \\(\\mathbb{P}(N=n)\\), puis montrer que la fonction de r√©partition de \\(X_N\\) est \\(F +(1-F) \\log(1-F)\\) (on pourra conditionner par les √©v√©nements \\(\\{N=n\\}, n \\in \\mathbb{N}\\)).\nExprimer \\(\\mathbb{P}(M=m), m \\ge 1\\).\nOn suppose dans cette question que \\(f = \\mathbf{1}_{[0,1]}\\). Pour \\(x \\in (0,1)\\) on introduit \\(R^x := \\min\\{ n \\ge 1 : X_1+...+X_n &gt;x \\}\\). Montrer que \\(\\mathbb{E}[\\mathbf{1}_{\\{R^x&gt;n\\}} \\mid X_n] = \\Phi(X_n)\\) o√π \\(\\Phi(u) = \\mathbb{I}_{\\{u&lt;x\\}}  \\mathbb{P}(R^{x-u} &gt; n-1)\\). En d√©duire \\(H_n(x):= \\mathbb{P}(R^x&gt;n)\\).\n\n\n\nExercice 24\nSoient \\(X\\) et \\(Y\\) deux v.a.r. ind√©pendantes de loi uniforme sur \\([0, 1]\\).\n\nQuelle est l‚Äôesp√©rance conditionnelle de \\((Y - X)_+\\) sachant \\(X\\)?\nQuelle est la loi conditionnelle de \\((Y - X)_+\\) sachant \\(X\\)?\n\n\n\nExercice 25\nSoient \\(X_1, X_2, X_3\\) trois v. a. r. gaussiennes centr√©es r√©duites ind√©pendantes. On pose \\(U = 2X_1 - X_2 - X_3, V = X_1 + X_2 + X_3, W = 3X_1 + X_2 - 4X_3\\).\n\nQuelles sont les lois de \\(U, V\\) et \\(W\\)? Quels sont les couples de v.a. ind√©pendantes parmi les couples \\((U, V), (U,W), (V,W)\\)?\nMontrer qu‚Äôil existe \\(a \\in \\mathbb{R}\\) tel que \\(W = aU + Z\\) avec \\(U\\) et \\(Z\\) ind√©pendantes. En d√©duire \\(\\mathbb{E}(W \\mid U)\\).\n\n\n\nExercice 26\nSoient \\(X\\) et \\(Y\\) deux v. a. r. gaussiennes centr√©es r√©duites ind√©pendantes. On pose \\(Z = X + Y\\) , \\(W = X - Y\\).\n\nMontrer que \\(Z\\) et \\(W\\) sont ind√©pendantes. Quelle est la loi de \\(W\\)?\nEn d√©duire l‚Äôesp√©rance conditionnelle et la loi conditionnelle de \\(X\\) sachant \\(Z\\).\nCalculer \\(\\mathbb{E}(XY \\mid Z)\\) et \\(\\mathbb{E}(XYZ \\mid Z)\\)."
  },
  {
    "objectID": "exercices/td4.html",
    "href": "exercices/td4.html",
    "title": "MA1AY010 Probabilit√©s",
    "section": "",
    "text": "NoteTD IV : Esp√©rance conditionnelle/Catact√©risations\n\n\n\n\n29 Septembre 2025-2 octobre 2025\nMaster I ISIFAR\nProbabilit√©s\n\n\n\n\n\n\n\n\n\nNoteConventions\n\n\n\nDans les 3 exercices qui suivent, \\(X_1, \\ldots, X_n, ...\\) constituent une famille ind√©pendante de variables al√©atoires identiquement distribu√©es √† valeur dans \\(\\{-1,1\\}\\).\nL‚Äôunivers des possibles est \\(\\Omega = \\{-1,1\\}^{\\mathbb{N}}\\). Les \\(X_i\\) sont les projections canoniques.\nOn note \\(\\mathcal{F}_n\\) la tribu engendr√©e par les \\(n\\) premi√®res coordonn√©es :\n\\[\n\\mathcal{F}_n =  \\sigma(X_1, \\ldots, X_n) \\,\n\\]\nL‚Äôunivers est muni de la tribu des cylindres \\(\\mathcal{F} = \\sigma\\left(\\bigcup_n \\mathcal{F}_n\\right)\\).\nOn note \\(\\Delta\\) une constante √† valeur dans \\((0,1)\\) (la d√©rive de la marche al√©atoire).\nOn note \\(\\mathbb{P}\\) la loi produit infini, telle que pour tout \\(x \\in \\{-1, 1\\}^n\\)\n\\[\n\\mathbb{P}\\left\\{\\bigwedge_{i=1}^n X_i = x_i\\right\\} = \\prod_{i=1}^n \\frac{1}{2}\\left(1 + x_i \\Delta\\right)\n\\]\nOn √©tudie la marche al√©toire sur \\(\\mathbb{Z}\\) de d√©rive \\(\\Delta\\).\nOn note \\(S_n = \\sum_{i=1}^n X_i\\).\nL‚Äôindice \\(n\\) repr√©sente le temps, \\(S_n\\) la position √† l‚Äôinstant \\(n\\).\n\n\n\nExercice 1 (marches al√©atoires biais√©es i)\n\nQuelle est la loi de \\(S_n\\) ?\n\\(S_n\\) est-elle \\(\\mathcal{F}_n, \\mathcal{F}_{n-1}, \\mathcal{F}_{n+1}\\) mesurable ?\nQuelle est l‚Äôesp√©rance de \\(S_n\\) ?\nQuelle est la variance de \\(S_n\\) ?\n\n\n\n\n\n\n\nNoteOn admettra l‚Äôin√©galit√© de Hoeffding:\n\n\n\nSi \\(Y_1, \\ldots, Y_n\\) sont des variables al√©atoires ind√©pendantes telles que \\(a_i \\leq Y_i \\leq b_i\\) (les \\(Y_i\\) sont born√©es), alors \\[\nP \\left\\{  Z - \\mathbb{E} Z \\geq t  \\right\\} \\leq \\mathrm{e}^{- 2 \\frac{t^2}{\\sum_{i=1}^n (b_i-a_i)^2}}\n\\] avec \\(Z = \\sum_{i=1}^n Y_i\\).\n\n\n\n\nExercice 2 (marches al√©atoires biais√©es ii)\nPour \\(0 \\leq \\tau \\leq  n \\Delta\\),\n\nMajorer \\(\\mathbb{P}\\{ S_n \\leq \\tau \\}\\) √† l‚Äôaide de l‚Äôin√©galit√© de Chebyshev\nMajorer \\(\\mathbb{P}\\{ S_n \\leq \\tau \\}\\) √† l‚Äôaide de l‚Äôin√©galit√© de Hoeffding\nL‚Äôensemble \\[\nE = \\left\\{ \\omega :  \\forall n,  S_n(\\omega) &lt; \\tau \\right\\}\n\\] appartient-il √† la tribu \\(\\mathcal{F}_m\\) pour un \\(m\\) donn√© ? est-il un √©v√©nement de \\(\\mathcal{F}\\) ?\nSi \\(E\\) est un √©v√©nement, quelle est sa probabilit√© ?\n\n\n\n\n\n\n\nNoteConvention\n\n\n\nOn suppose \\(\\tau \\in \\mathbb{N} ‚àñ  \\{0\\}\\).\nOn note \\(T = \\inf \\left\\{ n : S_n \\geq \\tau \\right\\}\\). Si \\(\\forall n, \\quad S_n(\\omega)&lt; \\tau\\), alors \\(T(\\omega) = \\infty\\).\nOn note \\(S_T\\), la fonction d√©finie par \\[\nS_T(\\omega) = \\sum_{n=1}^\\infty \\mathbb{I}_{T(\\omega)=n} S_n(\\omega)\\qquad \\text{si } T(\\omega) &lt; \\infty\n\\] et \\(S_T(\\omega) =0\\) si \\(T(\\omega) =\\infty\\).\n\n\n\n\nExercice 3 (marches al√©atoires biais√©es iii)\n\nPourquoi peut-on consid√©rer que \\(T\\) est une variable al√©atoire (√† valeur dans \\(\\mathbb{N} \\cup \\{\\infty\\}\\)) ?\nQuelle est la probabilit√© que \\(T = \\infty\\) ?\nL‚Äô√©v√©nement \\(\\{ T \\leq n \\}\\) est-il \\(\\mathcal{F}_{n-1}, \\mathcal{F}_n, \\mathcal{F}_{n+1}\\) mesurable ?\nPourquoi peut-on consid√©rer que \\(S_T\\) est une variable al√©atoire ?\nQuelle est l‚Äôesp√©rance de \\(S_T\\) ?\nMontrer que \\(\\mathbb{E} S_T = \\Delta \\mathbb{E} T\\) En d√©duire \\(\\mathbb{E} T\\).\n\n\n\nExercice 4\nLes variables \\(X_1, X_2, \\ldots, X_n, \\ldots\\) sont des variables de Bernoulli de probabilit√© de succ√®s \\(p \\in (0,1)\\), ind√©pendantes. On d√©finit \\(T_1 = \\min \\{i : X_i=1\\}\\) (temps du premier succ√®s), \\(T_1 = \\min \\{i : i &gt; T_1, X_i=1\\}\\) (temps du premier succ√®s apr√®s \\(T_1\\)), et r√©cursivement \\(T_{n+1} = \\min \\{ i : i &gt; T_n, X_i =1\\}\\) (temps du \\(n+1\\)eme succ√®s).\nOn admet l‚Äôexistence d‚Äôun espace de probabilit√© \\((\\Omega, \\mathcal{F}, P)\\) o√π \\(\\Omega = \\{0,1\\}^{\\mathbb{N}}\\), \\(\\mathcal{F}\\) est une tribu pour laquelle les \\(X_i\\) sont mesurables, et \\(P\\) tel que \\(X_1, \\ldots, X_n, \\ldots\\) est une famille ind√©pendante.\n\n\\(T_1\\) et plus g√©n√©ralement \\(T_n\\) sont-elles des variables al√©atoires?\nCalculer \\(P \\{ T_1 &gt; k  \\}\\) pour \\(k \\in \\mathbb{N}\\).\nCalculer \\(P \\{ T_1 = k  \\}\\) pour \\(k \\in \\mathbb{N}\\)\nCalculer \\(\\mathbb{E}T_1\\).\nCalculer \\(P \\{ T_1 = k  \\wedge T_2 = k+j\\}\\) pour \\(k, j \\in \\mathbb{N}\\)\nCalculer \\(P \\{ T_2 = k  \\}\\) pour \\(k \\in \\mathbb{N}\\)\nCalculer \\(\\mathbb{E}T_2\\)\nCalculer \\(\\mathbb{E} T_n\\)\n\n\n\nExercice 5\nOn dispose de \\(n\\) urnes num√©rot√©es de \\(1\\) √† \\(n\\) et de \\(n\\) boules. Les boules sont r√©parties de mani√®re uniforme dans les urnes (chaque boule se comporte de mani√®re ind√©pendante des autres et a probabilit√© \\(1/n\\) de tomber dans chaque urne). On note \\(U_i\\) la variable al√©atoire d√©signant le nombre de boules qui tombent dans l‚Äôurne \\(i\\). Soit \\(\\alpha &gt;1\\) un r√©el.\n\nD√©terminer la loi de \\(U_i\\).\nMontrer que l‚Äôon a : \\[\\mathbb{P}( \\max_{1 \\leq i \\leq n} U_i &gt; \\alpha \\log n) \\leq n \\mathbb{P}( U_1 &gt; \\alpha \\log n).\\]\nCalculer \\(\\mathbb{E}(\\exp(U_1))\\).\nMontrer que pour tout \\(\\beta &gt; -n\\), on a \\((1+\\beta/n)^n \\leq \\exp(\\beta)\\).\nMontrer que \\(\\mathbb{P}(U_1 &gt; \\alpha \\log n) \\leq \\frac{\\exp(\\exp(\\alpha)-1)}{n^\\alpha}\\).\nEn d√©duire que si \\(\\alpha &gt;1\\), on a \\[\\mathbb{P}( \\max_{1 \\leq i \\leq n} U_i &gt; \\alpha \\log n) \\rightarrow_{n \\rightarrow \\infty} 0.\\]\n\n\n\nExercice 6 (Restitution Organis√©e de Connaissances)\n\nSoient \\(A, B, C\\) trois √©v√©nements dans un espace probabilis√©. A-t-on toujours: \\(A \\perp\\!\\!\\!\\perp B \\text{ et } B \\perp\\!\\!\\!\\perp C \\Rightarrow A \\perp\\!\\!\\!\\perp C\\)?\nSoient \\(P\\) et \\(Q\\) deux lois de probabilit√©s sur \\((\\Omega, \\mathcal{F})\\), on d√©finit l‚Äôensemble \\(\\mathcal{M} = \\big\\{ A : A \\in \\mathcal{F}, P(A)=Q(A)\\}\\). R√©pondre par vrai/faux/je ne sais pas aux questions suivantes:\n\n\\(\\mathcal{M}\\) est-il toujours une classe monotone ?\n\\(\\mathcal{M}\\) est-il toujours une \\(\\sigma\\)-alg√®bre ?\n\\(\\mathcal{M}\\) est-il toujours une \\(\\pi\\)-classe ?\n\nSoient \\(G\\) et \\(F\\) sont deux fonctions g√©n√©ratrices de probabilit√©. R√©pondre par vrai/faux aux questions suivantes:\n\nEst-il vrai que \\(G \\times F\\) est toujours une fonction g√©n√©ratrice ?\nEst-il vrai que \\(G + F\\) est toujours une fonction g√©n√©ratrice de probabilit√© ?\nEst-il vrai que \\(\\lambda G + (1-\\lambda) F\\) avec \\(\\lambda \\in [0,1]\\) est toujours une fonction g√©n√©ratrice de probabilit√© ?\n\nSi \\(\\widehat{F}\\) est la fonction caract√©ristique de la loi de \\(X\\), et si \\(\\epsilon \\perp\\!\\!\\!\\perp X\\), avec \\(P\\{\\epsilon=1\\}= P\\{\\epsilon=-1\\}=1/2\\), quelle est la fonction caract√©ristique de la loi de \\(\\epsilon X\\)?\n\n\n\nExercice 7\nSi \\(X\\) est une variable al√©atoire positive int√©grable, la version biais√©e par la taille de \\(X\\) est la variable al√©atoire \\(X^*\\) dont la loi \\(Q\\) est absolument continue par rapport √† celle de \\(X\\) (not√©e \\(P\\)) et dont la densit√© (par rapport √† celle de \\(X\\)) est proportionnelle √† \\(X\\): \\[\n\\frac{\\mathrm{d}Q}{\\mathrm{d}P}(x) = \\frac{x}{\\mathbb{E}X} \\, .\n\\]\n\nCaract√©riser \\(X^*\\) lorsque \\(X\\) est une Bernoulli.\nCaract√©riser \\(X^*\\) lorsque \\(X\\) est binomiale.\nCaract√©riser \\(X^*\\) lorsque \\(X\\) est Poisson.\nCaract√©riser \\(X^*\\) lorsque \\(X\\) est Gamma.\nSi \\(X\\) est √† valeurs enti√®res, exprimer la fonction g√©n√©ratrice de \\(X^*\\) en fonction de celle de \\(X\\).\nExprimer la transform√©e de Laplace de \\(X^*\\) en fonction de celle de \\(X\\).\nSi \\(U\\) est une transform√©e de Laplace, d√©rivable √† droite en \\(0\\), \\(U'/U'(0)\\) est-elle la transform√©e de Laplace d‚Äôune loi sur \\([0, \\infty)\\)?\n\n\n\nExercice 8\n\n\n\n\n\n\nNoteRappel\n\n\n\nLa loi normale centr√©e r√©duite \\(\\mathcal{N}(0,1)\\) admet pour densit√© \\(x\\mapsto \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right)\\),\n\n\n\nSi \\(X \\sim \\mathcal{N}(0,1)\\), donner une densit√© de la loi de \\(Y=\\exp(X)\\) (Loi log-normale). Calculer l‚Äôesp√©rance et la variance de \\(Y\\).\nM√™me question si \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\).\nSi \\(X, Y \\sim \\mathcal{N}(0,1)\\), avec \\(X \\perp\\!\\!\\!\\perp Y\\), donner une densit√© de la loi de \\(Z=Y/X\\) (Loi de Student √† 1 degr√© de libert√©)\nSi \\(X, Y \\sim \\mathcal{N}(0,1)\\), avec \\(X \\perp\\!\\!\\!\\perp Y\\), donner une densit√© de la loi de \\(W = Y/ \\sqrt{X^2}\\).\nSi \\(X \\sim \\mathcal{N}(0,1)\\) et \\(\\epsilon\\) vaut \\(\\pm 1\\) avec probabilit√© \\(1/2\\) (variable de Rademacher) avec \\(X \\perp\\!\\!\\!\\perp \\epsilon\\), donner une densit√© de la loi de \\(Y = \\epsilon X\\). \\(Y\\) et \\(X\\) sont-elles ind√©pendantes ?\n\n\n\nExercice 9\nPrincipe de r√©flexion\nDans cet exercice, \\(X_1, X_2, \\ldots\\) sont des variables de Rademacher ind√©pendantes (\\(P\\{X_i = \\pm 1\\} = \\frac{1}{2}\\)), \\(S_n =\\sum_{i=1}^n X_i, S_0=0\\) et \\(M_n = \\max_{k \\leq n} S_n\\).\nMontrer que, pour \\(a&gt; 0\\),\n\\[P\\left\\{ M_n &gt; a \\right\\}\\leq 2 P\\left\\{ S_n &gt; a \\right\\}\\]\n\n\n\n\n\n\nNoteStatistique des rangs/Statistiques d‚Äôordre\n\n\n\nLes statistiques d‚Äôordre \\(X_{1:n}\\leq X_{2:n}\\leq X_{n:n}\\) d‚Äôun \\(n\\)-√©chantillon \\(X_1,\\ldots,X_n\\) d‚Äôobservations ind√©pendantes identiquement distribu√©es sont form√©es par le r√©arrangement croissant (convention) de l‚Äô√©chantillon.\nQuand \\(n\\) est clair d‚Äôapr√®s le contexte on peut les noter \\(X_{(1)} \\leq \\ldots \\leq X_{(n)}\\).\n\n\n\n\nExercice 10\n\nV√©rifier que la loi jointe des statistiques d‚Äôordre est absolument continue par rapport √† la loi de l‚Äô√©chantillon.\nOn suppose que \\(X\\) est une variable al√©atoire r√©elle, absolument continue, de densit√© continue. Montrer que l‚Äô√©chantillon est presque s√ªrement form√© de valeurs deux √† deux distinctes.\nDonner la densit√© de la loi jointe des statistiques d‚Äôordre.\nSi la loi des \\(X_i\\) d√©finie par sa fonction de r√©partition \\(F\\), admet une densit√© \\(f\\), quelle est la densit√© de la loi de \\(X_{k:n}\\) pour \\(1\\leq k\\leq n\\) ?\n\nMontrer que conditionnellement √† \\(X_{k:n}=x\\), la suite\n\\[(X_{i:n}-X_{k:n})_{i=k+1,\\ldots, n}\\]\nest distribu√©e comme les statistiques d‚Äôordre d‚Äôun \\(n-k\\) √©chantillon de la loi d‚Äôexc√®s au dessus de \\(x\\) (fonction de survie \\(\\overline{F}(x+\\cdot)/\\overline{F}(x))\\) avec la convention \\(\\overline{F}=1-F\\)).\nSi \\(X_1,\\ldots,X_n\\) est un √©chantillon i.i.d. de la loi exponentielle d‚Äôesp√©rance \\(1\\) (densit√© \\(\\mathbb{I}_{x&gt;0} \\mathrm{e}^{-x}\\)), et $X_{n:n}X_{n-1:n}X_{1:n} $ les statistiques d‚Äôordre associ√©es, montrer que:\navec la convention \\(X_{0:n}=0\\), les √©carts \\((X_{i:n}-X_{i-1:n})_{1\\leq i\\leq n}\\) () forment une collection de variables al√©atoires ind√©pendantes ;\n\\(X_{i:n}-X_{i-1:n}\\) est distribu√©e selon une loi exponentielle d‚Äôesp√©rance \\(\\tfrac{1}{i}\\) .\nMaintenant, \\(X_1,\\ldots,X_n\\) est un √©chantillon i.i.d. de la loi exponentielle d‚Äôesp√©rance \\(1\\) (densit√© \\(\\mathbb{I}_{x&gt;0} \\mathrm{e}^{-x}\\)), et \\(X_{n:n}\\geq X_{n-1:n}\\geq  \\ldots \\geq X_{1:n}\\) les statistiques d‚Äôordre associ√©es, et \\((k_n)_n\\) est une suite croissante d‚Äôentiers qui tend vers l‚Äôinfini, telle que \\(k_n/n\\) tende vers une limite finie (√©ventuellement nulle). Montrer que\n\\[\\frac{X_{k_n:n} -\\mathbb{E} X_{k_n:n} }{\\sqrt{\\operatorname{var}(X_{k_n:n} )}}\\]\nconverge en loi vers une Gaussienne centr√©e r√©duite."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA15Y010 Probabilit√©s et Extr√™mes",
    "section": "",
    "text": "Cette page r√©sume le d√©roulement du semestre\n\n\n\n\n\n\n\n\n\n\n\n\n\nSemaine\nDate\nTh√®me(s)\nPr√©parer\nCours\nExercices\n√âvaluation\n\n\n\n\n1\n8 Sep 2025\nR√©visions Licence\n\n\nTD 1\n\n\n\n\n9 Sep\nR√©visions Licence\n\n\nTD 1\n\n\n\n\n11 Sep\nR√©visions Licence: th√©oremes de convergence (int√©gration)\n\n\nTD 1\n\n\n\n2\n15 Sep\nR√©visions Licence: Espaces roduits\n\n\n\n\n\n\n\n16 Sep\nChangement de variables. Calcul Gamma/Beta\n\n\n\n\n\n\n\n18 Sep\nFonctions g√©n√©ratrices/Conditionnement discret\n\n\n\n\n\n\n3\n22 Sep\nMoments, Espaces \\(L^p\\)\n\n\n\n\n\n\n\n23 Sep\nEsp√©rance conditionnelle\n\n\n\n\n\n\n\n25 Sep\nConditionnement\n\n\nTD 2 TD 2 suppl√©ment\n\n\n\n4\n29 Sep\nCaract√©risations\n\n\nTD4\n\n\n\n\n30 Sep\nCaract√©risations\n\n\nCorrections TD1\n\n\n\n\n2 Oct\nCaract√©risations\n\n\n\n\n\n\n5\n6 Oct\n\n\n\n\n\n\n\n\n7 Oct\nCC 1\n\n\n\n\n\n\n\n9 Oct\n\n\n\n\n\n\n\n6\n13 Oct\n\n\n\n\n\n\n\n\n14 Oct\n\n\n\n\n\n\n\n\n16 Oct\nCC 2",
    "crumbs": [
      "Informations",
      "Agenda"
    ]
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Semaine 2",
    "section": "",
    "text": "Important\n\n\n\nLa semaine II (15-19 septembre 2025) est encore consacr√©e aux r√©visions de Licence.",
    "crumbs": [
      "Agenda",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#pr√©parerrevoir",
    "href": "weeks/week-2.html#pr√©parerrevoir",
    "title": "Semaine 2",
    "section": "Pr√©parer/Revoir",
    "text": "Pr√©parer/Revoir\n\n\nEspaces produits, tribus produits (2025-09-15)\nLois produits (2025-09-15)\nTh√©or√®me de Fubini (2025-09-15)\nCalculs de densit√©s image, formules de changement de variable (2025-09-16)\nEsp√©rances, moments, Espaces \\(L^p\\) (2025-09-16)\nConditionnement discret (2025-09-18)\nProcessus de branchement al√©atoire (2025-09-18)\nEnregistrement du cours du 18 septembre\n\n\n\n\nVoir Notes, Espaces produits, etc\nVoir Notes, calculs de densit√© image\nVoir Notes, Fonctions g√©n√©ratrices\nVoir Notes, Conditionnement discret\nVoir Notes, Esp√©rances, Moments, Espaces \\(L^p\\), ‚Ä¶",
    "crumbs": [
      "Agenda",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#exercices",
    "href": "weeks/week-2.html#exercices",
    "title": "Semaine 2",
    "section": "Exercices",
    "text": "Exercices\nFeuille TD I Feuille TD I suppl√©ments\n\nTD I.18 (sommes al√©atoires de variables ind√©pendantes) (fin).\nSuppl√©ment TD I Exercice 5 (Anniversaires)\nTD I.7\nTD I‚Ä¶.\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Agenda",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "Important\n\n\n\nLa semaine IV (29 septembre- 2 octobre 2025) est consacr√©e aux caract√©risations des lois de probabilit√©s (Transform√©es de Laplace et de Fourier).",
    "crumbs": [
      "Agenda",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week-4.html#pr√©parervoirrevoir",
    "href": "weeks/week-4.html#pr√©parervoirrevoir",
    "title": "Week 4",
    "section": "Pr√©parer/Voir/Revoir",
    "text": "Pr√©parer/Voir/Revoir\n\n\nTransform√©e de Laplace\nTransform√©e de Fourier\n\n\n\n\nVoir Transform√©e de Laplace ‚Ä¶\nVoir Transform√©e de Fourier ‚Ä¶",
    "crumbs": [
      "Agenda",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week-4.html#exercices",
    "href": "weeks/week-4.html#exercices",
    "title": "Week 4",
    "section": "Exercices",
    "text": "Exercices\n\nFeuille TD IV\nCorrections TD I\n\n\nBack to course schedule ‚èé",
    "crumbs": [
      "Agenda",
      "Week 4"
    ]
  },
  {
    "objectID": "corriges/td1.html",
    "href": "corriges/td1.html",
    "title": "Variables al√©atoires r√©elles",
    "section": "",
    "text": "NoteTD I : R√©visions de Licence\n\n\n\n\n8 Septembre 2025-12 Septembre 2025\nMaster I Isifar\nProbabilit√©s"
  },
  {
    "objectID": "corriges/td1.html#fonctions-de-r√©partition",
    "href": "corriges/td1.html#fonctions-de-r√©partition",
    "title": "Variables al√©atoires r√©elles",
    "section": "Fonctions de r√©partition",
    "text": "Fonctions de r√©partition\n\nExercice 1 (transformation affine)\nSoit \\(X\\) une variable al√©atoire r√©elle, \\(F_X\\) sa fonction de r√©partition, \\(a, b\\) deux r√©els fix√©s, et \\(Y := aX+b\\)\n\nOn suppose dans cette question que \\(a=1\\). Comment d√©duire \\(F_Y\\) de \\(F_X\\)?\nSi (la loi de) \\(X\\) admet une densit√©, en est-il de m√™me de \\(Y\\)? Si oui, exprimer dans ce cas \\(f_Y\\) √† l‚Äôaide de \\(f_X\\).\nOn suppose dans cette question que \\(b=0\\) et \\(a&gt;0\\). Comment d√©duire \\(F_Y\\) de \\(F_X\\)?\nSi (la loi de ) \\(X\\) admet une densit√©, √† quelle condition sur \\(a\\) en est-il de m√™me de (la loi de) \\(Y\\)? Exprimer dans ce cas \\(f_Y\\) √† l‚Äôaide de \\(f_X\\).\nR√©pondre aux m√™mes questions lorsque \\(b=0\\) et \\(a=-1\\)?\nR√©pondre enfin aux m√™mes questions lorsque \\(a\\) et \\(b\\) sont quelconques.\n\n\n\n\n\n\n\nNoteSolution\n\n\n\nSoit \\(F_Y\\) la fonction de r√©partition de \\(Y\\).\n\nOn a\n\\[F_Y(x) = \\mathbb{P}(Y \\le x) = \\mathbb{P}(X+b \\le x) = \\mathbb{P}(X \\le x-b) = F_X(x-b)\\]\nAinsi, le graphe de \\(F_Y\\) se d√©duit de celui de \\(F_X\\) en le translatant de \\(b\\) vers la droite. Si \\(X\\) admet une densit√© \\(f_X\\),\n\\[F_Y(x) = \\int_{-\\infty}^{x-b} f_X(u) du = \\int_{-\\infty}^b f_Y(v) dv,\\]\no√π \\(f_Y(v) = f_X(v-b), u \\in \\mathbb{R}\\).\nAinsi, si \\(X\\) admet une densit√© \\(f_X\\), \\(Y\\) admet la densit√© \\(f_Y\\) d√©finie ci-dessus.\nOn a dans ce cas \\[F_Y(x) = \\mathbb{P}(Y \\le x) = \\mathbb{P}(aX \\le x) = \\mathbb{P}(X \\le \\frac{x}{a}) = F_X(\\frac{x}{a}).\\] Ainsi le graphe de \\(F_Y\\) se d√©duit de celui de \\(F_X\\) en dilatant ce dernier par \\(a\\).\nSi \\(X\\) admet une densit√© \\(f_X\\), on a \\[F_Y(x) = \\int_{-\\infty}^{\\frac{x}{a}} f_X(u) du = \\int_{-\\infty}^x \\frac{1}{a} f_X(\\frac{v}{a}) dv = \\int_{-\\infty}^x f_Y(v) dv,\\] o√π \\(f_Y(v) = \\frac{1}{a} f_X(\\frac{v}{a}), v \\in \\mathbb{R}\\). Ainsi, si \\(X\\) admet une densit√© \\(f_X\\), alors \\(Y\\) admet la densit√© \\(f_Y\\) d√©finie ci-dessus.\nDans ce cas \\[F_Y(x) = \\mathbb{P}(-X \\le x) = \\mathbb{P}(X \\ge -x) = 1-F_X((-x)^-).\\] Si \\(X\\) admet une densit√© \\(f_X\\), \\[F_Y(x) = \\int_{-x}^{\\infty} f_X(u) du = \\int_{-\\infty}^x f_X(-v) dv = \\int_{-\\infty}^x f_Y(v)dv,\\] o√π \\(f_Y(v) = f_X(-v), x \\in \\mathbb{R}\\). Ainsi, si \\(X\\) admet une densit√© \\(f_X\\), alors \\(Y\\) admet la densit√© \\(f_Y\\) d√©finie ci-dessus.\nTraitons d‚Äôabord le cas \\(a=0\\). Dans ce cas, quelque soit \\(X\\), on obtient que \\(Y\\) est d√©terministe, \\(\\mathbb{P}(Y=b)=1\\) (en particulier \\(Y\\) n‚Äôa pas de densit√© m√™me si \\(X\\) en poss√®de une.\nLorsque \\(a &gt; 0\\), on obtient par un raisonnement similaire √† 1,2, \\[F_Y(x) = F_X\\left(\\frac{x-b}{a}\\right),\\] et si \\(X\\) poss√®de la densit√© \\(f_X\\), alors \\(Y\\) poss√®de la densit√© \\(f_Y\\) telle que \\(f_Y(v) = \\frac{1}{a} f_X\\left( \\frac{v-b}{a} \\right), v \\in \\mathbb{R}\\).\nEnfin lorsque \\(a&lt;0\\), \\[F_Y(x) = \\mathbb{P}(aX+b \\le x) = \\mathbb{P}(aX \\le x-b) = \\mathbb{P}\\left(X \\ge \\frac{x-b}{a}\\right) = 1-F_X\\left(\\left(\\frac{x-b}{a}\\right)^-\\right),\\] et si \\(X\\) poss√®de la densit√© \\(f_X\\), \\[F_Y(x) = \\int_{\\frac{x-b}{a}}^{+\\infty} f_X(u) du = \\frac{1}{|a|} \\int_{-\\infty}^{x} f_X\\left(\\frac{v-b}{a}\\right) dv,\\] de sorte que \\(Y\\) poss√®de la densit√© \\(f_Y\\) o√π \\(f_Y(v) = \\frac{1}{|a|} f_X\\left(\\frac{v-b}{a}\\right), v \\in \\mathbb{R}\\).\n\n\n\n\n\nExercice 2 (Minimum, maximum de variables ind√©pendantes)\nSoient \\(X_i, i \\ge 1\\), des variables ind√©pendantes. Pour \\(k \\ge 2\\), on note \\(Y_k = \\min (X_1,...,X_k)\\), \\(Z_k = \\max(X_1,...,X_k).\\)\n\nDans cette question on s‚Äôint√©resse √† \\(k=2\\).\nComment d√©duire \\(F_{Y_2}\\) de \\(F_{X_1}, F_{X_2}\\)? M√™me question pour \\(F_{Z_2}\\).\nG√©n√©raliser √† \\(k\\) quelconque.\nQuelle est la loi de \\(Z_k\\) lorsque les \\(\\{X_i, i \\ge 1\\}\\) sont i.i.d., \\(\\sim \\mathrm{Unif}[0,1]\\)?\nQuelle est la loi de \\(Y_k\\) lorsque les \\(\\{X_i, i \\ge 1\\}\\) sont des variables exponentielles ind√©pendantes, avec \\(X_i \\sim \\text{Exp}(\\lambda_i)\\) (o√π pour tout \\(i\\), \\(\\lambda_i &gt;0\\))?\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nOn a pour tout \\(x \\in \\mathbb{R}\\), \\[1-F_{Y_2}(x) = \\mathbb{P}(Y_2 &gt; x) = \\mathbb{P}(\\min(X_1,X_2) &gt;x)) = \\mathbb{P}(X_1 &gt;x, X_2 &gt;x) = \\mathbb{P}(X_1&gt;x) \\mathbb{P}(X_2&gt;x),\\] o√π pour la derni√®re √©galit√© on s‚Äôest servi de l‚Äôind√©pendance de \\(X_1\\) et \\(X_2\\). On d√©duit que pour tout \\(x \\in \\mathbb{R}\\), \\[1-F_{Y_2}(x) = (1-F_{X_1}(x)) (1-F_{X_2}(x)).\\]\n\nDe mani√®re similaire, on obtient pour tout \\(x \\in \\mathbb{R}\\) \\[F_{Z_2}(x) = F_{Y_1}(x) F_{Y_2}(x).\\]\n\nPar un raisonnement similaire, pour tout \\(x \\in \\mathbb{R}\\),\n\\[ 1-f_{Y_k}(x) = \\prod_{i=1}^k (1-F_{X_i}(x))\\]\nPar ailleurs, pour tout \\(x \\in \\mathbb{R}\\), \\[F_{Z_k}(x) = \\mathbb{P}(\\max(X_1,...,X_k) \\le x) = \\mathbb{P}(X_i \\le x, 1 \\le i \\le k) = \\prod_{i=1}^k \\mathbb{P}(X_i \\le x)\\] o√π pour la derni√®re √©galit√© on s‚Äôest servi de l‚Äôind√©pendance des \\((X_i, 1 \\le i \\le k)\\). On d√©duit, pour tout \\(x \\in \\mathbb{R}\\), \\[F_{Z_k}(x) = \\prod_{i=1}^k F_{X_i}(x)\\]\nDans ce cas \\(F_{X_i}(x) = x \\mathbb{I}_{[0,1]}(x) + \\mathbb{I}_{]1,+\\infty[}(x)\\), et donc\n\\[F_{Z_k}(x) = \\begin{cases} 0 & \\text{si } x \\le 0\\\\ x^k & \\text{si } 0 \\le x \\le 1 \\\\  1 & \\mbox{si } x \\ge 1 \\end{cases},\\]\non d√©duit donc que \\(Z_k\\) est une variable de densit√© \\[f_{Z_k}(x) = k x^{k-1} \\mathbf{1}_{[0,1]}(x), x \\in \\mathbb{R}.\\]\nDans ce cas \\(1-F_{X_i}(x) = \\exp(-\\lambda_i x) \\mathbf{1}_{\\{x \\ge 0\\}} + \\mathbf{1}_{\\{x&lt;0\\}}\\), on a donc\n\\[1-F_{Y_k}(x) = \\begin{cases} 1 & \\mbox{si } x \\le 0 \\\\ \\exp\\left(-x \\sum_{i=1}^k \\lambda_i\\right)  & \\text{sinon}\\end{cases}\\]\nde sorte que \\(Y_k \\sim \\exp(\\Lambda)\\), avec \\(\\Lambda = \\sum_{i=1}^k \\lambda_i\\).\n\n\n\n\n\nExercice 3\nOn suppose que \\(X \\sim \\mathcal{N}(0,1)\\). Que valent\n\\[\\mathbb{P}(X \\le 1), \\quad \\mathbb{P}(-1.23 \\le X \\le 0.43), \\quad \\mathbb{P}(X&gt;0.32)?\\]\n\n\n\n\n\n\nNoteSolution\n\n\n\nEn utillisant le logiciel R, la fonction de r√©partition de la loi \\(\\mathcal{N}(0,1)\\) est d√©sign√©e par pnorm(), la fonction r√©ciproque (fonction quantile) est d√©sign√©e par qnorm\n\n\n\n\n\n\n\n\n\n\n\\(\\approx\\)\n\n\n\n\n\\(\\mathbb{P}(X \\le 1)\\)\npnorm(1)\n0.84\n\n\n\\(\\mathbb{P}(-1.23 \\le X \\le 0.43)\\)\npnorm(.43) - pnorm(-1.23)\n0.56\n\n\n\\(\\mathbb{P}(X &gt; .32 1)\\)\n1 - pnorm(.32)\n0.37\n\n\n\n\n\n\n\nExercice 4\nOn suppose que l‚Äô√©cart √† la taille moyenne \\(T=15.5\\) des individus d‚Äôune population suit une loi normale centr√©e r√©duite.\nDans quel intervalle centr√© en \\(T\\) se situent les tailles de \\(99\\%\\) des individus de la population?\n\n\n\n\n\n\nNoteSolution\n\n\n\nD‚Äôapr√®s la table, pour \\(Z \\sim \\mathcal{N}(0,1)\\), on a \\(\\mathbb{P}(Z \\le 2.57) \\approx 0.9949),\\) et \\(\\mathbb{P}(Z \\le 2.58) \\approx 0.9951\\), de sorte que \\(\\mathbb{P}(|Z| \\ge 2.57) \\approx 0.0102\\), et \\(\\mathbb{P}(|Z| \\ge 2.58) \\approx 0.0098\\).\nOn d√©duit que les tailles de \\(99\\%\\) de la population se situent entre \\(15.5 - 2,58 = 12.92\\) et \\(15.5+2.58 = 18.08\\).\n\n\n\n\nExercice 5\nEtant donn√©e X une variable al√©atoire gaussienne de param√®tres \\(\\mu\\) et \\(\\sigma^2\\), donner la probabilit√© que \\(|X - \\mu|\\) d√©passe \\(k\\sigma\\) pour \\(k = 1, 2, 3\\).\nSuggestion: On commencera par montrer que \\(\\sigma^{-1}(X-\\mu)\\) suit une loi normale centr√©e r√©duite.\nReprendre les questions de l‚Äôexercice pr√©c√©dent lorsque \\(\\mu=2, \\sigma=2\\).\nReprendre les questions de l‚Äôexercice pr√©c√©dent lorsque \\(\\mu=0, \\sigma=1/2\\).\n\n\n\n\n\n\nNoteSolution\n\n\n\nPuisque \\((X-\\mu)/\\sigma \\sim \\mathcal{N}(0,1)\\) on a\n\\[\\mathbb{P}(|X- \\mu| \\ge k \\sigma)= \\mathbb{P}(|Z| \\ge k),\\] et donc d‚Äôapr√®s la table, pour \\(k=1\\) ceci vaut\n\\[\\mathbb{P}(|Z| \\ge 1) =  2 (1-\\mathbb{P}(Z \\le 1)) \\approx 2 \\times (1-0.8413) = 2 * 0.1587 = 0.3174\\] pour \\(k=2\\),\n\\[\\mathbb{P}(|Z| \\ge 2) = 2(1-\\mathbb{P}(Z \\le 2) \\approx 2 \\times (1- 0.9772) = 0.0456.\\] enfin pour \\(k=3\\),\n\\[\\mathbb{P}(|Z| \\ge 3) = 2 (1- \\mathbb{P}(Z \\le 3) \\approx 2 \\times (1-0.9987) = 0.0026.\\]\nPour \\(\\mu=2, \\sigma=2\\), on a\n\\[\\mathbb{P}(X \\le 1) = \\mathbb{P}(Z \\le -1/2) \\approx 0.3085,\\]\n\\[ \\mathbb{P}(-1.23 \\le X \\le 0.43) = \\mathbb{P}(-\\frac{3.23}{2} \\le Z \\le -\\frac{1.57}{2}) \\approx 0.9463-0.7823 = 0.1640,\\]\n\\[\\mathbb{P}(X &gt; 0.32) = \\mathbb{P}(Z&gt;-0.84) \\approx 0.7995.\\]\nPour \\(\\mu=0, \\sigma=1/2\\), on trouve \\[\\mathbb{P}(X \\le 1) = \\mathbb{P}(Z \\le 2) \\approx 0.9772\\]\n\\[\\mathbb{P}(-1.23 \\le X \\le 0.43 ) = \\mathbb{P}(-2.46 \\le Z \\le 0.86) \\approx 0.8051 - (1-0.9931) = 0.7982,\\]\n\\[\\mathbb{P}(X&gt;0.32) = \\mathbb{P}(Z &gt; 0.64) \\approx 1-0.7389 = 0.2611\\]"
  },
  {
    "objectID": "corriges/td1.html#densit√©s",
    "href": "corriges/td1.html#densit√©s",
    "title": "Variables al√©atoires r√©elles",
    "section": "Densit√©s",
    "text": "Densit√©s\n\nExercice 6\nDans les cas suivants, trouver la valeur de \\(C\\) pour que \\(f\\) soit une densit√© de probabilit√©.\n\n\\(f(x) = C \\frac{1}{\\sqrt{x (1-x)}}, 0 &lt;x &lt;1,\\)\n\\(f(x) = C \\exp(-x-\\exp(-x)), x \\in \\mathbb{R},\\)\n\\(f(x) = C \\frac{1}{1+x^2}\\).\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nOn a \\[x(1-x) = x-x^2 = \\frac{1}{4} - \\left(x-\\frac{1}{2}\\right)^2\\] et on sait que la primitive de \\(x \\to \\frac{1}{\\sqrt{a^2-x^2}}\\) est \\(x \\to \\arcsin\\left(\\frac{x}{a}\\right)\\). On a donc en effectuant le changement de variable \\(y = x-1/2\\), \\[\\int_{0}^1 \\frac{1}{\\sqrt{x(1-x)}} = \\int_{-1/2}^{1/2} \\frac{dy}{\\sqrt{\\frac{1}{4}-y^2}} = \\left[\\arcsin(2y)\\right]_{-1/2}^{1/2} = \\pi,\\] et il faut donc poser \\(C = \\frac{1}{\\pi}\\) pour que \\(f\\) soit une densit√© de probabilit√© sur \\(]0,1[\\).\n\nSoit \\(h(x) = \\exp(-\\exp(-x)), x \\in \\mathbb{R}\\), on a pour \\(x \\in \\mathbb{R}\\), \\[h'(x) =\\exp(-x) \\exp(-\\exp(-x)) = \\exp(-x-\\exp(-x)),\\] de sorte que \\[ \\int_{-\\infty}^{\\infty} \\exp(-x-\\exp(-x)) = \\left[\\exp(-\\exp(-x))\\right]_{-\\infty}^{\\infty} = 1,\\] et il faut poser \\(C=1\\) pour que \\(f\\) soit une densit√© de probabilit√© sur \\(\\mathbb{R}\\).\n\nOn a \\[\\int_{\\infty}^{\\infty} \\frac{dx}{1+x^2} = \\left[ \\arctan(x) \\right]_{-\\infty}^{\\infty} = \\pi,\\] et il faut donc poser \\(C=\\frac{1}{\\pi}\\) pour que \\(f\\) soit une densit√© de probabilit√© sur \\(\\mathbb{R}\\).\n\n\n\n\n\nExercice 7\n(M√©lange)\nOn suppose que \\(X\\) et \\(Y\\) sont deux variables de densit√©s respectives \\(f_X, f_Y\\), et que \\(\\alpha \\in [0,1]\\). Montrer que \\(g : = \\alpha f_X + (1-\\alpha) f_Y\\) est √©galement une densit√© de probabilit√©.\nTrouver une variable al√©atoire dont \\(g\\) est la densit√©.\n\n\n\n\n\n\nNoteSolution\n\n\n\nLa fonction \\(g\\) reste bien √©videmment bor√©lienne, et puisque \\(\\alpha \\in [0,1]\\), positive, de plus\n\\[\\int_{\\mathbb{R}} g(x) dx = \\alpha \\int_{\\mathbb{R}} f_X(x) dx + (1-\\alpha) \\int_{\\mathbb{R}} f_Y(x) dx = \\alpha + (1-\\alpha) = 1,\\]\non conclut que \\(g\\) est bien une densit√© de probabilit√©.\nSoit \\(\\xi \\sim \\mathrm{Ber}(\\alpha)\\), ind√©pendante de \\((X,Y)\\). Alors \\(Z= \\xi X + (1-\\xi)Y\\) poss√®de la densit√© \\(g\\). En effet, en utilisant l‚Äôind√©pendance de \\(\\xi\\) et \\((X,Y)\\) √† la deuxi√®me ligne ci-dessous,\n\\[\\begin{align*}\n\\mathbb{P}(Z \\le x) & =  \\mathbb{P}(\\xi=1,  X \\le x) + \\mathbb{P}(\\xi=0, Y \\le x) \\\\ & =  \\mathbb{P}(\\xi=1) \\mathbb{P}(X \\le x) + \\mathbb{P}(\\xi=0) \\mathbb{P}(Y \\le x) \\\\ & =  \\alpha F_X(x) + (1-\\alpha) F_Y(x) \\\\ & =  \\int_{-\\infty}^x (\\alpha f_X(x) + (1-\\alpha)f_Y(x)) dx\n\\end{align*}\\]\n\n\n\n\nExercice 8\nSoit \\(X\\) de densit√© \\(f\\), et \\((\\alpha, \\beta) \\in \\overline{\\mathbb{R}}^2\\) sont suppos√©s tels que \\[\\mathbb{P}(\\alpha &lt; X &lt; \\beta) =1\\] On suppose que \\(g\\) est un \\(C^{1}\\)-diff√©omorphisme croissant de \\((\\alpha, \\beta)\\) sur \\((g(\\alpha),g(\\beta))\\).\n\nMontrer que \\(g(X)\\) a pour densit√© \\(\\frac{f(g^{-1}(x))}{g'(g^{-1}(x))} \\mathbf{1}_{\\{x \\in (g(\\alpha), g(\\beta))\\}}\\).\nQuelle est la densit√© de la variable \\(aX+b\\), o√π \\(a&gt;0\\) et \\(b\\in \\mathbb{R}\\) sont fix√©s?\n\nSoit \\(Y \\sim \\mathcal{N}(0,1)\\). Quelle est la densit√© de \\(Z = \\exp(Y)\\)?\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nPosons \\(T= g(X)\\). Pour \\(h : \\mathbb{R} \\to \\mathbb{R}_+\\) mesurable, on a \\[\\mathbb{E}[h(T)]  = \\mathbb{E}[h(g(X))] = \\int_{\\alpha}^{\\beta} h(g(x)) f(x) dx\\]\nEn effectuant le changement de variables \\(t = g(x)\\) il vient \\[ \\mathbb{E}[h(T)]  = \\int_{g(\\alpha)}^{g(\\beta)} \\frac{h(t) f(g^{-1}(t))}{g'(g^{-1}(t))} dt. \\] Comme ceci est valable pour tout fonction \\(h\\) mesurable positive, on conclut que \\(T\\) poss√®de la densit√© souhait√©e sur \\((g(\\alpha),g(\\beta))\\)\nIci \\(g : x \\to ax+b\\), \\(g^{-1} : x \\to \\frac{x-b}{a}\\), \\(g'(x) = a\\) pour tout \\(x\\) et dans ce cas la densit√© recherch√©e s‚Äôexprime donc \\[\\frac{1}{a} f\\left( \\frac{x-b}{a} \\right) \\mathbf{1}_{(a\\alpha+b, a\\beta+b)}(x), \\ x \\in \\mathbb{R}.\\] Quitte √† prendre \\(\\alpha = -\\infty, \\beta = +\\infty\\), on retrouve le r√©sultat de l‚Äôexercice 2.\nIci \\(\\alpha = - \\infty, \\beta=+\\infty\\), \\(f(y) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-y^2/2), y \\in \\mathbb{R}\\), et \\(g: x \\to \\exp(x)\\), \\(g^{-1} : y \\to \\ln(y)\\) et \\(g'(g^{-1}(x)) = x\\). On obtient donc que la densit√© de \\(Z\\) est \\[\\frac{1}{x \\sqrt{2\\pi}} \\exp\\left(-\\frac{\\ln(x)^2}{2}\\right) \\mathbf{1}_{\\{x &gt;0\\}}.\\]"
  },
  {
    "objectID": "corriges/td1.html#lois-usuelles-calculs-de-loi",
    "href": "corriges/td1.html#lois-usuelles-calculs-de-loi",
    "title": "Variables al√©atoires r√©elles",
    "section": "Lois usuelles, calculs de loi",
    "text": "Lois usuelles, calculs de loi\n\nExercice 9\n(Fonctions de r√©partition et fonctions caract√©ristiques de lois usuelles)\n\n\n\n\n\n\nAttention : dans le cas d‚Äôune variable continue, quand on calcule \\(\\Phi_X\\) on %doit int√©grer sur \\(\\mathbb{R}\\) une fonction complexe. Trois m√©thodes sont envisageables.\nParfois on peut int√©grer s√©par√©ment partie r√©elle et partie imaginaire.\nParfois il est utile de se servir de la formule de Cauchy. En particulier, cette formule assure que si \\(f\\) est une fonction holomorphe, si \\(\\mathcal{C}\\) est un contour ferm√© ‚Äúraisonnable‚Äù (en particulier tout cercle ou polygone r√©gulier), et enfin si \\(\\overset{\\circ}{\\mathcal{C}}\\) d√©signe l‚Äôensemble des points se trouvant √† l‚Äôint√©rieur de ce contour, alors\n\\[\\forall a \\in \\overset{\\circ}{\\mathcal{C}}, \\quad f(a) = \\frac{1}{2\\pi i} \\oint_{\\mathcal{C}}  \\frac{f(z)}{z-a} \\mathrm{d}z.\\]\nAttention : cette formule montre bien que l‚Äôon ne peut pas traiter l‚Äôint√©grale d‚Äôune fonction complexe en faisant ‚Äúcomme si‚Äù \\(i\\) √©tait r√©√©l (!) La m√©thode des r√©sidus est en outre une cons√©quence directe de la formule de Cauchy.\nEnfin, on peut utiliser le prolongement analytique (voir l‚Äôexemple de la fonction \\(\\Gamma\\)).\n\n\n\n\nExprimer le plus simplement \\(F_X\\) dans les cas suivants (on pourra se contenter de tracer l‚Äôallure du graphe de la fonction de r√©partition lorsque celle-ci ne poss√®de pas d‚Äôexpression simple).\n\n\\(n \\in \\mathbb{N}^*, p \\in [0,1], X \\sim \\text{Bin}(n,p)\\),\n\\(\\lambda&gt;0, X \\sim \\text{Poisson}(\\lambda)\\),\n\\(a&gt;0, X\\sim \\text{Unif}[-a,a]\\),\n\\(\\lambda&gt;0, X \\sim \\mathbf{exp}(\\lambda)\\),\n\\(\\lambda&gt;0, s \\in \\mathbb{N}^*\\), \\(X \\sim \\Gamma(\\lambda, s)\\) (on rappelle que la densit√© \\(f_X\\) de \\(X \\sim \\Gamma(\\lambda,s)\\) est telle que \\(f_X(x) =\\frac{1}{\\Gamma(s)} \\lambda^s x^{s-1}\\exp(-\\lambda x) \\mathbf{1}_{[0,\\infty[}(x), x \\in \\mathbb{R}\\)),\n\\(X \\sim \\mathcal{N}(0,1)\\),\n\\(\\mu \\in \\mathbb{R}, \\sigma&gt;0, X \\sim \\mathcal{N}(\\mu,\\sigma^2)\\).\n\n\\(a&gt;0, X \\sim \\mathrm{Cauchy}(a)\\) (on rappelle que la densit√© \\(f_X\\) de la loi de Cauchy de param√®tre \\(a\\) est telle que \\(f_X(x) = \\frac{a}{\\pi(x^2+a^2)}, x\\in \\mathbb{R}\\)).\n\n(*) \\(X \\sim \\mathrm{stable}(1/2)\\) (cette loi a pour densit√© \\(\\sqrt{2\\pi x^{-3}} \\exp(-1/2x)\\mathbf{1}_{[0,\\infty[}(x).\\))\n\nLesquelles parmi ces variables poss√®dent une densit√©?\n\nExprimer le plus simplement \\(\\Phi_X\\) pour les \\(7\\) premi√®res variables de la premi√®re question ci-dessus. En d√©duire, ou trouver par un calcul direct, \\(E[X],\\) et \\(\\mathrm{Var}[X]\\).\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nBin√¥miale Il s‚Äôagit d‚Äôune variable discr√®te √† valeurs dans \\([|0,n|]\\), (elle ne poss√®de donc pas de densit√©), et telle que \\[\\mathbb{P}(X=k) = {n \\choose k} p^k (1-p)^{n-k}, \\ 0\\le k \\le n\\] On a\n\\[F_X(x) = \\sum_{k=0}^n \\mathbf{1}_{\\{x \\ge k\\}} {n \\choose k} p^k(1-p)^{n-k}, x \\in \\mathbb{R}.\\] \\(X\\) a m√™me loi que \\(\\sum_{j=1}^n \\xi_j\\) o√π les \\((\\xi_j, 0 \\le j \\le n)\\) i.i.d suivant la loi Ber\\((p)\\), de sorte que \\[\\Phi_X(t) = \\mathbb{E}[\\exp(itX)] = \\Phi_{\\xi_1}(t)^n = (p\\exp(it)+(1-p))^n, \\ t \\in \\mathbb{R}\\] On a enfin, toujours gr^ace √† l‚Äô√©criture de \\(X\\) comme somme de \\(n\\) variables de Bernoulli ind√©pendantes et de m√™me param√®tre \\(p\\), \\[\\mathbb{E}[X] = np , \\qquad \\mathrm{Var}[X] = np(1-p)\\]\nPoisson Il s‚Äôagit d‚Äôune variable discr√®te √† valeurs dans \\(\\mathbb{N}\\) (elle ne poss√®de donc pas de densit√©) et telle que \\[ \\mathbb{P}(X=k) = \\lambda^k \\frac{\\exp(-\\lambda)}{k!}, k \\in \\mathbb{N}.\\] On a \\[ F_X(x) = \\sum_{k \\in \\mathbb{N}} \\mathbf{1}_{\\{x \\ge k\\}} \\exp(-\\lambda)\\frac{\\lambda^k}{k!}, x \\in \\mathbb{R}\\] et \\[ \\Phi_X(t) = \\sum_{ k \\in \\mathbb{N}} \\exp(itk) \\exp(-\\lambda) \\frac{\\lambda^k}{k!} = \\exp(\\lambda \\exp(it) -1), t \\in \\mathbb{R}\\] On a par un calcul direct \\[ \\mathbb{E}[X] = \\mathrm{Var}[X] = \\lambda.\\]\nUniforme continue sym√©trique\nIl s‚Äôagit de la loi de densit√© \\(\\frac{1}{2a} \\mathbf{1}_{[-a,a]}\\). On a pour \\(x \\in \\mathbb{R}\\),\n\\[F_X(x) = \\begin{cases}  0 & \\mbox{si } x \\le -a \\\\\n  \\frac{1}{2a} (x+a) & \\mbox{si } x \\in [-a,a] \\\\\n  1 & \\mbox{si } x \\ge a \\end{cases}\\]\net pour \\(t \\in \\mathbb{R}\\),\n\\[\\Phi_X(t) = \\begin{cases} 1 & \\mbox{si } t =0 \\\\ \\frac{\\sin(ta)}{ta} & \\mbox{si } t \\ne 0.\\end{cases}\\]\nOn a par un calcul direct\n\\[\\mathbb{E}[X] = 0, \\mathrm{Var}[X] = \\frac{a^2}{3}\\]\nExponentielle\nIl s‚Äôagit de la loi de densit√© \\(x \\to \\lambda \\exp(-\\lambda x) \\mathbf{1}_{\\{x \\ge 0\\}}\\). On a pour \\(x \\in \\mathbb{R}\\),\n\\[F_X(x) =  \\begin{cases}  0 & \\mbox{si } x \\le 0 \\\\\n  1-\\exp(-\\lambda x) & \\mbox{si } x \\ge 0 \\end{cases}\\]\net\n\\[\\Phi_X(t) = \\frac{\\lambda}{\\lambda-it}, t\\ in \\mathbb{R}\\]\nOn a enfin par un calcul direct (i.p.p)\n\\[\\mathbb{E}[X] = \\frac{1}{\\lambda}, \\ \\ \\mathrm{Var}[X] = \\frac{1}{\\lambda^2}\\]\nGamma\nLa densit√© est rappel√©e en √©nonc√©. La fonction de r√©partition n‚Äôadmet pas en g√©n√©ral de forme plus simple que \\(\\int_{-\\infty}^x f_X(u)du\\). On a de plus\n\\[\\Phi_X(t) = \\left(\\frac{\\lambda}{\\lambda-it} \\right)^s, t \\in \\mathbb{R}\\]\nQuitte √† calculer la d√©riv√©e premi√®re et seconde en \\(0\\) de \\(\\Phi_X\\) on trouve\n\\[\\mathbb{E}[X] = \\frac{s}{\\lambda}, \\qquad \\mathrm{Var}[X] = \\frac{s}{\\lambda^2}.\\]\nGaussienne centr√©e r√©duite\nIl s‚Äôagit de la loi de densit√© \\(f_X : x \\to \\frac{1}{\\sqrt{2\\pi}} \\exp(-x^2/2)\\), la fonction \\(F_X\\) n‚Äôa pas de forme plus simple que \\(\\int_{-\\infty}^x f_X(u)du\\), et \\[ \\Phi_X(t) = \\exp(-t^2/2), \\ t\\in \\mathbb{R}\\] On a (soit par calcul direct, soit en d√©rivant \\(\\Phi_X\\)) \\[\\mathbb{E}[X] = 0, \\quad \\mathrm{Var}[X] =1\\]\nGaussienne\nSi \\(Z \\sim \\mathcal{N}(0,1)\\), on a \\(X = \\mu + \\sigma Z \\sim \\mathcal{N}(\\mu,\\sigma^2)\\), et \\(X\\) a pour densit√© \\[f_X : x \\to \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2}\\right).\\] la fonction \\(F_X\\) n‚Äôa pas de forme plus simple que \\(\\int_{-\\infty}^x f_X(u)du\\) et \\[\\Phi_X(t) = \\exp\\left(it \\mu - \\frac{\\sigma^2 t^2}{2}\\right), t\\in \\mathbb{R}.\\] Puisque \\(X = \\mu + \\sigma Z\\) on trouve que \\[\\mathbb{E}[X] = \\mu, \\quad \\mathrm{Var}[X]= \\sigma^2.\\]\nCauchy\nLa densit√© est rappel√©e dans l‚Äô√©nonc√©, on a pour \\(x \\in \\mathbb{R}\\), \\[F_X(x) = \\frac{1}{\\pi} \\left(\\frac{\\pi}{2}+ \\arctan\\left(\\frac{x}{a}\\right)\\right),\\] et \\[ \\Phi_X(t) = \\exp(-a|t|), t \\in \\mathbb{R}.\\]\nStable \\((1/2)\\)\nLa loi stable\\((1/2)\\) a la densit√© rappel√©e en √©nonc√© (la fonction \\(F_X\\) n‚Äôa pas de forme plus simple que \\(\\int_{-\\infty}^x f_X(u)du\\)), sa fonction caract√©ristique est donn√©e par \\[\\Phi_X(t) = \\exp(-\\sqrt{|t|}(1+\\mathrm{sgn}(t)i), \\ t\\in \\mathbb{R}.\\]\net on note que \\(x \\to x f_X(x)\\) n‚Äôest pas int√©grable (donc \\(\\mathbb{E}[X]= +\\infty\\), \\(\\mathrm{Var}[X]=+\\infty\\)).\n\n\n\n\n\nExercice 10\nPour des valeurs de \\(t\\) que l‚Äôon pr√©cisera, calculer la transform√©e de Laplace \\(L(t) := \\mathbb{E}[\\exp(-t X)]\\) et la fonction g√©n√©ratrice des moments \\(G(u) := \\mathbb{E}[u^X]\\) de la variable \\(X\\) dans les cas suivants.\n\n\\(X \\sim \\mathrm{Ber}(p)\\), o√π \\(p \\in [0,1]\\),\n\\(X \\sim \\mathrm{Bin}(n,p)\\), o√π \\(n \\in \\mathbb{N}^*, p \\in [0,1]\\),\n\\(X \\sim \\mathrm{Geom}(p)\\), o√π \\(p \\in [0,1]\\),\n\\(X \\sim \\mathrm{Poisson}(\\lambda)\\), o√π \\(\\lambda&gt;0\\),\n\n\\(X=Y_1+...+Y_n\\), o√π les \\(Y_i, 1 \\le i \\le n\\) sont des variables ind√©pendantes, et \\(Y_i \\sim \\mathrm{Poisson}(\\lambda_i)\\), avec \\(\\lambda_i &gt;0\\).\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\\(G(u) = 1-p + pu, u \\in \\mathbb{R}\\), \\(L(t) = (1-p) + p \\exp(-t) = G(\\exp(-t)), t \\in \\mathbb{R}\\).\n\\(G(u) = (1-p + pu)^n, u \\in \\mathbb{R}\\), \\(L(t)= G(\\exp(-t)), t \\in \\mathbb{R}\\)\n\\(G(u) = \\frac{up}{1-u(1-p)}, |u|&lt;\\frac{1}{1-p}\\), et \\(L(t) = G(\\exp(-t)),  t &gt; \\ln(1-p)\\).\n\\(G(u) = \\exp(\\lambda(u-1)), u \\in \\mathbb{R}\\), et \\(L(t) = G(\\exp(-t)), t \\in \\mathbb{R}\\)\n\\(G(u) = \\exp(\\Lambda(u-1)), u \\in \\mathbb{R}\\) o√π \\(\\Lambda = \\sum_{i=1}^n \\lambda_i\\), \\(L(t) = G(\\exp(-t)), t \\in \\mathbb{R}\\)\n\n\n\n\n\nExercice 11\nSoit \\(X\\) une v.a.r. de densit√© \\(f\\). Quelle est la densit√© de \\(X^2\\)? Qu‚Äôobtient-on dans le cas o√π \\(X \\sim \\mathcal{N}(0,1)\\)?\n\n\n\n\n\n\nNoteSolution\n\n\n\nSoit \\(\\phi : \\mathbb{R} \\to \\mathbb{R}\\) bor√©lienne positive. et \\(Y=X^2\\). On a, en effectuant le changement de variables \\(u=x^2\\) √† la quatri√®me ligne ci-dessous,\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(Y^2)] & =  \\mathbb{E}[\\phi(X^2)] \\\\ & =  \\int_{\\mathbb{R}} \\phi(x^2) f(x) dx \\\\ & =  \\int_{\\mathbb{R}_-}\\phi(x^2) f(x) dx + \\int_{\\mathbb{R}_+} \\phi(x^2) f(x) dx \\\\ & =  \\int_{0}^{\\infty} \\phi(u) f(-\\sqrt{u}) \\frac{du}{2\\sqrt{u}} + \\int_0^{\\infty} \\phi(u) f(\\sqrt{u})\\frac{du}{2\\sqrt{u}} \\\\  & =  \\int_0^{\\infty} \\phi(u) \\frac{f(-\\sqrt{u}) + f(\\sqrt{u})}{2\\sqrt{u}} du\n\\end{align*}\\]\nComme l‚Äô√©galit√© ci-dessus est valable pour toute \\(\\phi : \\mathbb{R} \\to \\mathbb{R}\\) bor√©lienne positive, on conclut que \\(Y\\) poss√®de la densit√©\n\\[u\\to f_Y(u)  = \\frac{f(-\\sqrt{u}) + f(\\sqrt{u})}{2\\sqrt{u}} \\mathbf{1}_{\\{u&gt;0\\}}.\\]\nDans le cas o√π \\(X \\sim \\mathcal{N}(0,1)\\), on obtient\n\\[f_Y(u) = \\frac{1}{\\sqrt{2\\pi}} \\frac{\\exp\\left(-\\frac{u}{2}\\right)}{\\sqrt{u}} \\mathbf{1}_{\\{u &gt; 0\\}},\\]\nde sorte que \\(Y \\sim \\Gamma(1/2,1/2)\\).\n\n\n\n\nExercice 12\nSoit \\(X \\sim \\exp(1)\\). Calculer la densit√© des variables suivantes :\n\n\\(Y = aX+b\\), o√π \\(a&gt;0\\) et \\(b \\in \\mathbb{R}\\). Qu‚Äôobserve-t-on dans le cas o√π \\(b=0\\)?\n\n\\(Z = X^2\\).\n\\(U = \\exp(-X)\\).\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nOn a d‚Äôapr√®s l‚Äôexercice 2\n\\[f_Y(u) = \\frac{1}{a} \\exp\\left(- \\frac{u-b}{a}\\right)\\mathbf{1}_{\\{u \\ge 0\\}}, u \\in \\mathbb{R} \\]\nLorsque \\(b =0\\), on constate que \\(Y \\sim \\exp\\left(\\frac{1}{a}\\right)\\)\nD‚Äôapr√®s l‚Äôexercice pr√©c√©dent\n\\[f_Z(u) = \\frac{\\exp(- \\sqrt{u})}{\\sqrt{u}} \\mathbf{1}_{\\{u&gt;0\\}}, u \\in \\mathbb{R}.\\]\nSoit \\(\\phi : \\mathbb{R} \\to \\mathbb{R}_+\\) bor√©lienne, on a, en effectuant le changement de variables \\(u=\\exp(-x)\\) √† la troisi√®me ligne ci-dessous\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(U)]\n& = \\mathbb{E}[\\phi(\\exp(-X)] \\\\\n& =  \\int_0^{\\infty} \\phi(\\exp(-x)) \\exp(-x) dx \\\\\n& =  \\int_{0}^1 \\phi(u) du,\n\\end{align*}\\]\net, comme cette √©galit√© est valable pour tout \\(\\phi : \\mathbb{R} \\to \\mathbb{R}_+\\) bor√©lienne, on conclut que \\(U \\sim \\mathrm{Unif}[0,1]\\).\n\n\n\n\n\nExercice 13\nTrouver la loi de \\(\\arcsin(X)\\) lorsque\n\n\\(X \\sim \\mathrm{Unif}[0,1]\\),\n\\(X \\sim \\mathrm{Unif}[-1,1]\\).\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nSoit \\(\\phi : \\mathbb{R} \\to \\mathbb{R}_+\\) bor√©lienne, on a, en effectuant le changement de variables \\(u=\\arcsin(x)\\) √† la deuxi√®me ligne ci-dessous\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(\\arcsin(X))]\n& =  \\int_0^1 \\phi(\\arcsin(x)) dx  \\\\\n& =  \\int_0^{\\pi/2} \\phi(u) \\cos(u) du.\n\\end{align*}\\]\n\nOn conclut que \\(Y=\\arcsin(X)\\) poss√®de la densit√© \\(u \\to f_Y(u) = \\cos(u) \\mathbf{1}_{[0,\\pi/2]}(u)\\).\n\nSoit \\(\\phi : \\mathbb{R} \\to \\mathbb{R}_+\\) bor√©lienne, on a, en effectuant le changement de variables \\(u=\\arcsin(x)\\) √† la deuxi√®me ligne ci-dessous\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(\\arcsin(X))]\n& =  \\frac{1}{2} \\int_{-1}^1 \\phi(\\arcsin(x)) dx  \\\\\n& =  \\frac{1}{2} \\int_{-\\pi/2}^{\\pi/2} \\phi(u) \\cos(u) du.    \n\\end{align*}\\]\nOn conclut que \\(Y=\\arcsin(X)\\) poss√®de la densit√© \\(u \\to f_Y(u) = \\frac{\\cos(u)}{2} \\mathbf{1}_{[-\\pi/2,\\pi/2]}(u)\\).\n\n\n\n\n\nExercice 14\nOn souhaite peindre un mur (infini!) en utilisant un arroseur automatique qui effectue des demi-r√©volutions successives. Pour simplifier le mod√®le, on repr√©sentera le mur par une droite verticale \\(\\Delta\\), et l‚Äôarroseur par une source ponctuelle \\(O\\) situ√©e √† \\(1\\) m√®tre du mur, et √©mettant en tout instant \\(t\\) de fa√ßon parfaitement rectiligne dans la direction \\(\\overset{\\rightarrow}{u}(t)\\). On note \\(M\\) la projection orthogonale de \\(O\\) sur \\(\\Delta\\) et \\(\\theta(t)\\) l‚Äôangle entre \\(O \\overset{\\rightarrow}{u}(t)\\) et \\(\\overset{\\rightarrow}{OM}\\). L‚Äôintersection de \\(O\\overset{\\rightarrow}{u}\\) avec \\(\\Delta\\) est not√©e \\(H(\\theta)\\).\nOn suppose en outre que lors d‚Äôune demi-r√©volution, \\(\\theta(t)\\) parcourt exactement l‚Äôintervalle \\((-\\pi/2,\\pi/2)\\).\nOn fait l‚Äôhypoth√®se que la demi-r√©volution s‚Äôeffectue √† vitesse angulaire constante, et on se demande quelle sera la r√©partition de l‚Äô√©paisseur de la couche de peinture le long de \\(\\Delta\\) apr√®s un nombre entier de demi-r√©volutions.\n\nJustifier qu‚Äôune particule de peinture choisie uniform√©ment au hasard parmi toutes les particules est envoy√©e suivant un angle \\(\\theta \\sim \\mathrm{Unif}(-\\pi/2,\\pi/2)\\). Une telle particule se pose alors en \\(H(\\theta)\\), On note \\(h(\\theta)\\) l‚Äôordonn√©e de \\(H(\\theta)\\) (c‚Äôest √©galement la distance alg√©brique entre \\(O\\) et \\(H\\)).\nExprimer \\(h(\\theta)\\) en fonction de \\(\\theta\\). Quelle est la loi de \\(h(\\theta)\\)? Que pouvez-vous en d√©duire sur la distribution de l‚Äô√©paisseur de la couche de peinture le long du mur?\nA posteriori, quelle critique peut-on formuler sur le mod√®le?\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nLa vitesse angulaire √©tant constante, et le nombre de r√©volutions √©tant entier, aucune direction dans \\(]-\\pi/2,\\pi/2[\\) n‚Äôest privil√©gi√©e. Plus pr√©cis√©ment, si \\(-\\pi/2 &lt; \\theta_0 &lt; \\theta_0 + \\theta_1 &lt; \\pi/2\\), le nombre de particules envoy√©es lors des \\(n\\) r√©volutions dans un secteur angulaire \\((\\theta_0, \\theta_0+\\theta_1)\\) ne d√©pend pas de \\(\\theta_0\\) et est proportionnel √† \\(\\theta_1\\).\nAinsi, lorsqu‚Äôon choisit une des particules de peinture envoy√©es uniform√©ment au hasard, la probabilit√© qu‚Äôelle ait √©t√© envoy√©e dans ce secteur angulaire est proportionnelle √† \\(\\theta_1\\),, elle vaut donc \\(\\frac{2}{\\pi} \\theta_1\\) (en effet la probabilit√© est \\(1\\) pour \\(\\theta_0=-\\pi/2, \\theta_1=\\pi\\). Toujours pour \\(-\\pi/2&lt; \\theta_0&lt; \\theta_0 +\\theta_1&lt;\\pi/2\\), \\(\\frac{1}{\\pi} \\theta_1=\\int_{\\theta_0}^{\\theta_0+\\theta_1} \\frac{1}{\\pi} dx\\), et comme ceci est valable pour tous \\(-\\pi/2&lt; \\theta_0&lt; \\theta_0 +\\theta_1&lt;\\pi/2\\), cela caract√©rise la loi de l‚Äôangle, et on d√©duit que celui-ci suit bien une loi \\(\\mathrm{Unif}]-\\pi/2,\\pi/2[\\).\nOn a \\(h(\\theta) = \\tan(\\theta)\\), et donc si on pose \\(X = h(\\theta)\\) et si \\(\\phi : \\mathbb{R} \\to \\mathbb{R}_+\\) est bor√©lienne on a (on effectue le changement de variables \\(x=\\tan(\\theta)\\) √† la troisi√®me ligne ci-dessous)\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(X)]\n& = \\mathbb{E}[\\phi(\\tan(\\theta))] \\\\\n& = \\int_{-\\pi/2}^{\\pi/2} \\frac{2}{\\pi} \\phi(\\tan(\\theta)) d\\theta \\\\\n& = \\int_{-\\infty}^{\\infty} \\frac{1}{\\pi} \\frac{\\phi(x)}{1+x^2} dx  \n\\end{align*}\\]\nde sorte que \\(X\\) a pour densit√© \\(f_X: x \\to \\frac{1}{\\pi(1+x^2)}\\).\nOn a \\(\\mathbb{E}[|X|]=+\\infty\\), autrement dit, la distance moyenne √† l‚Äôaxe des abcisses √† laquelle une particule choisie uniform√©ment atterit est ‚Ä¶ infinie.\n\n\n\n\n\nExercice 15\nSoit \\(X \\sim \\mathrm{Cauchy}\\) (de param√®tre \\(1\\)).\nQuelle est la loi de\n\n\\(Y:=\\frac{1}{X}\\)?\n\\(Z:= \\frac{1}{1+X^2}\\)?\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nComme \\(\\mathbb{P}(X=0)=0\\), la variable \\(Y\\) est bien d√©finie.\nSi \\(\\phi : \\mathbb{R} \\to \\mathbb{R}_+\\) est bor√©lienne on a (on effectue le changement de variables \\(y=\\frac{1}{x}\\) √† la toisi√®me ligne ci-dessous)\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(Y)]\n& =  \\mathbb{E}[\\phi(\\frac{1}{X})] \\\\\n& =  \\int_{-\\infty}^{0} \\frac{\\phi(1/x)}{\\pi(1+x^2)} dx  + \\int_{0}^{\\infty} \\frac{\\phi(1/x)}{\\pi(1+x^2)} dx \\\\\n& = \\int_{-\\infty}^0 \\frac{\\phi(y)}{\\pi y^2(1+\\frac{1}{y^2})} dy + \\int_0^{\\infty} \\frac{\\phi(y)}{\\pi y^2(1+\\frac{1}{y^2})} dy \\\\  \n& =  \\int_{-\\infty}^{\\infty}  \\frac{\\phi(y)}{\\pi (1+y^2)} dy\n\\end{align*}\\]\nde sorte que \\(Y \\sim \\mathrm{Cauchy}(1)\\).\nSi \\(\\phi : \\mathbb{R} \\to \\mathbb{R}_+\\) est bor√©lienne on a (on effectue le changement de variables \\(z=\\frac{1}{1+x^2}\\) √† la toisi√®me ligne ci-dessous)\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(Z)]\n& =  \\mathbb{E}[\\phi(\\frac{1}{1+X^2})] \\\\\n& =  \\int_{-\\infty}^{0} \\frac{\\phi(\\frac{1}{1+x^2})}{\\pi(1+x^2)} dx  + \\int_{0}^{\\infty} \\frac{\\phi(\\frac{1}{1+x^2})}{\\pi(1+x^2)} dx \\\\\n& =  2 \\int_{0}^1 \\frac{z \\phi(z)}{\\pi} \\frac{1}{2 z^2\\sqrt{\\frac{1}{z}-1}}  \\\\\n& =  \\int_{0}^{1} \\frac{\\phi(z)}{\\pi\\sqrt{z(1-z)}}\n\\end{align*}\\]\nde sorte que \\(Z \\sim \\mathrm{Beta}(1/2,1/2)\\).\n\n\n\n\n\nExercice 16\nSoit \\(Z \\sim \\mathcal{N}(0,1)\\). Montrer que pour tout \\(x&gt;0\\),\n\\[\\left(x^{-1}-x^{-3}\\right) \\exp(-x^2/2) \\le \\sqrt{2\\pi} \\mathbb{P}(Z&gt;x) \\le x^{-1} \\exp(-x^2/2).\\]\nIndication : on pourra penser √† utiliser le changement de variable \\(y=x+z\\) pour obtenir l‚Äôin√©galit√© de droite, et on commencera par calculer la d√©riv√©e de \\(\\left(x^{-1}-x^{-3}\\right) \\exp(-x^2/2)\\) pour obtenir celle de gauche.\n\n\n\n\n\n\nNoteSolution\n\n\n\nOn a pour \\(x &gt;0\\), en effectuant le changement de variables \\(y=x+z\\) sugg√©r√© dans l‚Äô√©nonc√©\n\\[\\begin{align*}\n\\sqrt{2\\pi} \\mathbb{P}(Z&gt;x) & =  \\int_{x}^{\\infty} \\exp(-y^2/2) dy\n\\\\ & =  \\int_0^{\\infty} \\exp(-x^2/2-xz-z^2/2) \\mathrm{d}z\n\\\\ & =  \\exp(-x^2/2) \\int_{\\mathbb{R}_+} \\exp(-zx - z^2/2) \\mathrm{d}z\n\\\\ & \\le  \\exp(-x^2/2) \\int_{\\mathbb{R}_+} \\exp(-zx) \\mathrm{d}z = x^{-1} \\exp(-x^2/2)\n\\end{align*}\\]\nPar ailleurs, si \\(g : x \\to (x^{-1}-x^{-3})(\\exp(-x^2/2)\\), on a pour \\(x&gt;0\\)\n\\[\\begin{align*}\ng'(x) & =  \\left(-\\frac{1}{x^2}-\\frac{3}{x^4} -x (x^{-1}-x^{-3}) \\right)\\exp(-x^2/2)   \\\\\n& = \\left( -1 -\\frac{3}{x^4} \\right) \\exp(-x^2/2)\n\\end{align*}\\]\nPar ailleurs, si \\(h : x \\to \\sqrt{2\\pi} \\mathbb{P}(Z&gt;x)\\), on a \\(h'(x) = - \\exp(-x^2/2)\\) de sorte que \\(g'(x) &lt;h'(x),\\) pour tout \\(x &gt;0\\).\nComme \\(g(x) \\to -\\infty\\) lorsque \\(x \\searrow 0\\), alors que \\(h(0) = \\sqrt{\\pi/2}\\), on d√©duit, comme souhait√©, que\n\\[g(x)  \\le h(x), \\ \\forall x &gt;0 \\]\n\n\n\n\nExercice 17 (calcul d‚Äôune loi conditionnelle discr√®te)\nSoient \\(X_1,...,X_n\\) des variables de Poisson, ind√©pendantes, de param√®tres respectifs \\(\\lambda_1,...,\\lambda_n\\).\n\nD√©terminer la loi de \\(Y:=\\sum_{k=1}^n X_k\\).\nPour \\(r \\in \\mathbb{N}\\), que vaut la loi conditionnelle de \\((X_1,...,X_n)\\) sachant \\(Y=r\\)?\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nOn a pour tout \\(t \\in \\mathbb{R}\\), en utilisant l‚Äôind√©pendance des \\((X_k, 1 \\le k \\le n)\\) √† la premi√®re ligne ci-dessous,\n\n\\[\\begin{align*}\n\\Phi_Y(t) & =  \\prod_{k=1}^n \\Phi_{X_k}(t) \\\\ & =  \\prod_{k=1}^n \\exp(\\lambda_k (\\exp(it)-1)) \\\\ & =  \n\\exp(\\Lambda (\\exp(it)-1)\n\\end{align*}\\]\no√π \\(\\Lambda = \\sum_{k=1}^n \\lambda_k\\). La fonction caract√©ristique caract√©risant la loi, on d√©duit que \\(Y \\sim \\mathrm{Poisson}(\\Lambda)\\). 1. Soient \\((\\ell_1,\\ell_2, \\dots,\\ell_n) \\in \\mathbb{N}^n\\). Si \\(\\sum_{k=1}^n \\ell_k \\ne r\\) on a bien s√ªr \\(\\{(X_1,...,X_n)= (\\ell_1,... \\ell_n)\\} \\cap \\{Y=r\\} = \\emptyset\\) donc \\[ \\mathbb{P}((X_1,X_2, \\dots ,X_n) = (\\ell_1, \\ell_2, \\dots, \\ell_n)  \\mid Y=r) = 0\\] Si \\((\\ell_1,\\ell_2, \\dots, \\ell_n) \\in \\mathbb{N}^n\\) sont tels que \\(\\sum_{k=1}^n \\ell_k = n\\), on a \\(\\{Y=r\\} \\supset \\{(X_1,X_2, \\dots,X_n)= (\\ell_1, \\ell_2, \\dots, \\ell_n)\\}\\) et donc en utilisant l‚Äôind√©pendance des $(X_k)_{1 k n} $ √† la deuxi√®me ligne ci-dessous\n\\[\\begin{align*}\n\\mathbb{P}((X_1, X_2, \\dots,X_n) = (\\ell_1,\\ell_2, \\dots, \\ell_n) \\mid Y =r) & =  \\frac{\\mathbb{P}(X_1=\\ell_1, X_2= \\ell_2, \\dots, X_n = \\ell_r)}{\\mathbb{P}(Y=r)} \\\\ & =  \n\\frac{\\prod_{k=1}^n \\frac{\\lambda_k^{\\ell_k}\\exp(-\\lambda_k)}{\\ell_k!}}{\\frac{\\exp(-\\Lambda) \\Lambda^r}{r!} }\n\\\\ & =  {r \\choose \\ell_1, \\ell_2, \\dots,\\ell_n} \\prod_{k=1}^n \\left(\\frac{\\lambda_k}{\\Lambda}\\right)^{\\ell_k},\n\\end{align*}\\]\navec \\({r \\choose \\ell_1, \\ell_2, \\dots, \\ell_n} =\\frac{r!}{\\ell_1! \\ell_2! \\dots \\ell_n!}\\) le coefficient multin√¥mial de \\((\\ell_1,...,\\ell_n)\\) parmi \\(r\\).\nOn conclut que la loi conditionnelle de \\((X_1,...,X_n)\\) sachant \\(\\{Y=r\\}\\) est une loi mutin√¥miale de param√®tres \\(\\left(r,\\frac{\\lambda_1}{\\Lambda}, \\frac{\\lambda_2}{\\Lambda}, \\dots, \\frac{\\lambda_n}{\\Lambda}\\right)\\)."
  },
  {
    "objectID": "corriges/td1.html#exemples-divers",
    "href": "corriges/td1.html#exemples-divers",
    "title": "Variables al√©atoires r√©elles",
    "section": "Exemples divers",
    "text": "Exemples divers\n\nExercice 18\nOn suppose que le nombre \\(X\\) d‚Äôoeufs pondus par un insecte suit une loi de Poisson de param√®tre \\(\\lambda&gt;0\\) et que la probabilit√© qu‚Äôun oeuf meurt sans √©clore est, ind√©pendamment des autres oeufs, √©gale √† \\(1-p\\), o√π \\(p \\in ]0,1[\\).\n\nD√©montrer que le nombre \\(Y\\) d‚Äôoeufs qui arrivent √† √©closion suit une loi de Poisson de param√®tre \\(\\lambda p\\).\nQuelle est la loi jointe de \\((Y,Z)\\), o√π \\(Z= X-Y\\) est le nombre d‚Äôoeufs morts avant √©closion?\n\n\n\n\n\n\n\nNoteSolution\n\n\n\nQuitte √† introduire des variables \\((\\xi_i, i \\ge 1)\\) ind√©pendantes de \\(X\\), et i.i.d suivant la loi de Bernoulli de param√®tre \\(p\\) (\\(\\xi_i=1\\) si le \\(i\\)-i√®me oeuf arrive √† √©closion),\n\\[Y = \\sum_{k=1}^X \\xi_i, \\quad Z = \\sum_{k=1}^X (1-\\xi_i),\\]\no√π par convention \\(\\sum_{k=1}^0 \\dots = 0\\).\nOn a donc pour \\((s,t) \\in \\mathbb{R}^2\\), en utilisant l‚Äôind√©pendance de \\(X\\) et des \\((\\xi_i, i \\ge 1)\\) √† la quatri√®me ligne ci-dessous, puis le fait que les \\((\\xi_i, i \\ge 1)\\) sont i.i.d suivant une loi Ber\\((p)\\) √† la suivante :\n\\[\\begin{align*}\n\\Phi_{(Y,Z)}(s,t) & =  \\mathbb{E}[\\exp(isY + itZ)] \\\\\n& =  \\mathbb{E}\\left[\\exp\\left(is \\sum_{k=1}^X \\xi_k + it \\sum_{k=1}^X (1-\\xi_k)\\right)\\right]\n\\\\ & =  \\sum_{j \\in \\mathbb{N}} \\mathbb{E}\\left[\\mathbf{1}_{\\{X= j\\}} \\exp\\left(is \\sum_{k=1}^j \\xi_k + it \\sum_{k=1}^j (1-\\xi_k)\\right)\\right]\n\\\\ & =  \\sum_{j \\in \\mathbb{N}} \\frac{\\lambda^j \\exp(-\\lambda)}{j!} \\mathbb{E}\\left[\\prod_{k=1}^j  \\exp(is \\xi_k + it(1-\\xi_k))\\right]\n\\\\ & =  \\sum_{j \\in \\mathbb{N}} \\frac{\\lambda^j \\exp(-\\lambda)}{j!}  \\bigg(p\\exp(is) + (1-p)\\exp(it)\\bigg)^j\n\\\\ & =  \\exp(-\\lambda + \\lambda p \\exp(is) + \\lambda(1-p)\\exp(it))\n\\\\ & =  \\exp(\\lambda p (\\exp(is)-1)) \\exp(\\lambda(1-p) (\\exp(it)-1))\n\\end{align*}\\]\nOn d√©duit que \\((Y,Z)\\) est un couple de variables de Poisson ind√©pendantes, de param√®tres respectifs \\(\\lambda p, \\lambda(1-p)\\).\n\n\n\n\nExercice 19\n(Somme d‚Äôexponentielles et \\(\\chi^2\\))\nSoit \\(\\lambda&gt;0\\) et \\((Y_i)_{1 \\le i \\le n}\\) des variables i.i.d, \\(\\sim \\exp(\\lambda)\\).\n\nCalculer \\(\\mathbb{E}[\\exp(-tY_1)]\\) pour \\(t \\ge 0\\).\n\nCalculer \\(\\mathbb{E}\\left[\\exp(-t\\sum_{i=1}^n) Y_i \\right]\\) pour \\(t \\ge 0\\).\nMontrer que la densit√© de la variable \\(X= \\sum_{i=1}^n Y_i\\) est proportionnelle √† \\(x^{n-1} \\exp(-\\lambda x) \\mathbf{1}_{x \\ge 0}\\). En d√©duire la valeur de cette densit√©.\nSoient \\(X_n, n \\ge 1\\) des variables i.i.d, \\(\\sim \\mathcal{N}(0,1)\\). On pose \\(\\chi^2(n):=\\sum_{i=1}^n X_i^2\\), \\(Z:=X_1X_2 +X_3X_4\\). \\ Calculer \\(\\Phi_{\\chi^2(n)}, \\Phi_Z\\). Pouvez-vous deviner la distribution de \\(Z\\) (on pourra utiliser un r√©sultat d‚Äôun exercice pr√©c√©dent)?\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\\(\\mathbb{E}[\\exp(-tY_1)] = \\frac{\\lambda}{\\lambda+t}, t \\ge 0\\)\n\\(\\mathbb{E}\\left[\\exp(-t\\sum_{i=1}^n) Y_i \\right] = \\left(\\frac{\\lambda}{\\lambda+t}\\right)^n, \\ t \\ge 0\\).\nOn montre cette assertion par r√©currence sur \\(n \\in \\mathbb{N}^*\\). L‚Äôassertion est √©vidente pour \\(n=1\\) (avec facteur de proportionalit√© \\(c_1:=\\lambda\\)). Supposons la vraie au rang \\(n\\) et posons \\(Z_{n+1} = \\sum_{i=1}^{n+1} Y_i\\). Comme \\(Y_{n+1}\\) est ind√©pendante de \\(Z_n\\) le vecteur \\((Z_n, Y_{n+1})\\) poss√®de la densit√© jointe sur \\(\\mathbb{R}^2\\) : \\[ f_{(Z_n, Y_{n+1})}(z,y) = f_{Z_n}(z) f_{Y_{n+1}}(y) = c_n  \\lambda z^{n-1} \\exp(-\\lambda z - \\lambda y) \\mathbf{1}_{\\{z \\ge 0, y \\ge 0\\}}, (z,y) \\in \\mathbb{R}^2\\] Soit \\(\\phi : \\mathbb{R} \\to \\mathbb{R}\\) bor√©lienne positive\n\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(Z_{n+1})] & =  \\mathbb{E}[\\phi(Z_n + Y_{n+1})]\n\\\\ & =  \\int_{\\mathbb{R}_+^2} \\phi(z+y) f_{Z_n}(z) f_{Y_{n+1}}(y) \\mathrm{d}z dy\n\\\\ & =  \\int_{\\mathbb{R}_+^2} \\phi(z+y)     c_n  \\lambda z^{n-1} \\exp(-\\lambda z - \\lambda y)  \\mathrm{d}z dy\n\\\\ & =  \\int_{u \\in \\mathbb{R}_+, u \\ge v}  \\phi(u) c_n \\lambda v^{n-1} \\exp(-\\lambda u) du dv\n\\end{align*}\\]\no√π √† la derni√®re ligne on a utilis√© le changement de variable \\((u,v) = (z+y,z)\\) de \\(\\mathbb{R}_+^2\\) dans \\(\\{(u,v) \\in \\mathbb{R}_+^2 : v \\le u\\}\\), de jacobien \\(1\\). On a donc\n\\[\\begin{align*}\n  \\mathbb{E}[\\phi(Z_{n+1})] & =   \\int_{u \\in \\mathbb{R}_+} \\lambda c_n \\phi(u)  \\exp(-\\lambda u) \\int_{v =0}^u  v^{n-1} dv  du \\\\\n& =  \\int_{\\mathbb{R}_+} \\phi(u) \\lambda \\frac{c_n}{n} u^n \\exp(-\\lambda u) du\n\\end{align*}\\]\net on obtient la conclusion souhait√©e, avec \\(c_{n+1} = \\frac{\\lambda c_n}{n}\\).\nOn d√©duit par une r√©currence imm√©diate que \\(c_n = \\frac{\\lambda^n}{(n-1)!}, n \\in \\mathbb{N}^*\\).\n\nOn a vu (exercice 12) que \\(X_i^2 \\sim \\mathrm{Gamma}(1/2,1/2)\\), et par un raisonnement similaire √† celui de la question pr√©c√©dente, on obtient que \\(\\chi^2(n) \\sim \\mathrm{Gamma}(n/2,1/2)\\). On peut aussi raisonner directement avec les fonctions caract√©ristiques, pour obtenir que \\[ \\Phi_{\\chi^2(n)}(t) = \\Phi_{X_1^2}(t)^n = \\left(\\frac{1/2}{1/2-it}\\right)^{n/2}.\\] Par ailleurs pour \\(t \\in \\mathbb{R}\\),\n\n\\[\\begin{align*}\n\\Phi_{X_1X_2}(t) & =  \\mathbb{E}[\\exp(i t X_1 X_2)] = \\int_{\\mathbb{R}^2} \\frac{1}{2\\pi} \\exp(it x_1 x_2 - x_1^2/2 - x_2^2/2) dx_1 dx_2 \\\\\n& =  \\int_{\\mathbb{R}} dx_1 \\frac{1}{\\sqrt{2\\pi}} \\exp(-x_1^2 /2) \\int_{\\mathbb{R}} dx_2 \\frac{1}{\\sqrt{2\\pi}} \\exp(it x_1 x_2 - x_2^2/2)\n\\\\ & =  \\int_{\\mathbb{R}} \\frac{1}{\\sqrt{2\\pi}} \\exp(-x_1^2/2) \\Phi_{X_2}(tx_1) dx_1\n\\\\ & =  \\int_{\\mathbb{R}}  \\frac{1}{\\sqrt{2\\pi}} \\exp(-x_1^2/2) \\exp(-t^2 x_1^2 /2) dx_1\n\\\\ & =  \\int_{\\mathbb{R}} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(- \\frac{x_1^2 (1+t^2)}{2} \\right) dx_1\n\\\\ & =  \\frac{1}{\\sqrt{1+t^2}}\n\\end{align*}\\]\net donc les \\((X_i, i \\ge 1)\\) √©tant i.i.d, pour \\(t \\in \\mathbb{R}\\),\n\\[\\Phi_Z(t) = \\Phi_{X_1X_2}(t) \\Phi_{X_3X_4}(t) = \\frac{1}{1+t^2}.\\]\nIl s‚Äôagit de la fonction caract√©ristique d‚Äôune variable ‚Äúexponentielle sym√©trique‚Äù, de densit√© \\(x \\to \\frac{1}{2}\\exp(-|x|)\\) (c‚Äôest d‚Äôailleurs une mani√®re d‚Äôeffectuer le calcul de la fonction caract√©ristique d‚Äôune Cauchy\\((1)\\)). On peut le v√©rifier directement. Soit \\(\\xi \\sim \\mathrm{Ber}(1/2)\\), et \\((X,Y)\\) i.i.d suivant une loi exp\\((1)\\). La variable \\(T=\\xi X -(1-\\xi)Y\\) a une loi exponentielle sym√©trique. De plus pour \\(t \\in \\mathbb{R}\\),\n\\[\\begin{align*}\n\\Phi_T(t) & =  \\mathbb{E}[\\exp(it \\xi X -it(1-\\xi)Y)]  \\\\\n& =  \\frac{1}{2} \\mathbb{E}[\\exp(itX)] + \\frac{1}{2}\\mathbb{E}[\\exp(-itY)] \\\\\n& =  \\frac{1}{2} \\frac{1}{1-it} + \\frac{1}{2} \\frac{1}{1+it}\n\\\\ & =  \\frac{\\frac{1}{2}(1+it) + \\frac{1}{2}(1-it)}{1+t^2} = \\frac{1}{1+t^2}\n\\end{align*}\\]\ncomme souhait√©.\n\n\n\n\nExercice 20\nSoit \\(Z = (X, Y )\\), une variable al√©atoire √† valeurs dans \\(\\mathbb{R}^2\\). On suppose que \\(Z\\) admet une densit√© \\(f\\) d√©finie par\n\\[f(x, y) = \\frac{4}{\\pi \\sigma^2} \\exp\\left(-\\frac{x^2+y^2}{\\sigma^2}\\right) \\mathbf{1}_{\\{x \\ge |y|\\}},\\]\no√π \\(\\sigma&gt;0\\).\n\nV√©rifier que \\(f\\) est bien une densit√© de probabilit√©.\nCalculer les lois de \\(X\\) et de \\(Y\\) . Les variables al√©atoires \\(X\\) et \\(Y\\) sont-elles ind√©pendantes ?\nCalculer la loi de \\((X - Y, X + Y )\\) et montrer que \\(X - Y\\) et \\(X + Y\\) sont ind√©pendantes.\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\n\\(f : \\mathbb{R}^2 \\to \\mathbb{R}_+\\) est continue donc bor√©lienne Par sym√©trie des r√¥les de \\(x\\) et \\(y\\),\n\n\\[\\int_{\\mathbb{R}^2} f(x,y) dx dy = \\int_{\\mathbb{R}^2}\\frac{4}{\\pi \\sigma^2} \\exp\\left(-\\frac{x^2+y^2}{\\sigma^2}\\right) \\mathbf{1}_{\\{y \\ge |x|\\}}.\\]\nPar parit√© de \\(x \\to \\exp(-\\frac{x^2}{2})\\),\n\\[\\int_{\\mathbb{R}^2} f(x,y) dx dy = \\int_{\\mathbb{R}^2}\\frac{4}{\\pi \\sigma^2} \\exp\\left(-\\frac{x^2+y^2}{\\sigma^2}\\right) \\mathbf{1}_{\\{x \\le -|y|\\}}.\\]\nA nouveau par sym√©trie des r√¥les de \\(x\\) et \\(y\\)\n\\[\\int_{\\mathbb{R}^2} f(x,y) dx dy = \\int_{\\mathbb{R}^2}\\frac{4}{\\pi \\sigma^2} \\exp\\left(-\\frac{x^2+y^2}{\\sigma^2}\\right) \\mathbf{1}_{\\{y  \\le -|x|\\}}.\\]\nEnfin, la r√©union des \\(4\\) ensembles \\(\\{(x,y) \\in \\mathbb{R}^2: x \\ge |y|\\}, \\{(x,y) \\in \\mathbb{R}^2 : y \\ge |x|\\},  \\{(x,y) \\in \\mathbb{R}^2 : x \\le -|y|\\}, \\{(x,y) \\in \\mathbb{R}^2 : y \\le -|x|\\}\\) est \\(\\mathbb{R}^2\\) tout entier. L‚Äôintersection des \\(2\\) premiers est \\(\\{(x,y) : x = y \\ge 0\\}\\), de mesure de Lebesgue nulle, et des consid√©rations similaires permettent d‚Äôassurer que c‚Äôest √©galement le cas pour l‚Äôintersection de n‚Äôimporte quelle paire parmi ces \\(4\\) ensembles. On conclut que\n\\[\\begin{align*}\n\\int_{\\mathbb{R}^2} f(x,y) dx dy  \n& =  \\frac{1}{4} \\int_{\\mathbb{R}^2}   \\frac{4}{\\pi \\sigma^2} \\exp\\left(-\\frac{x^2+y^2}{\\sigma^2}\\right) \\\\\n& =  \\int_{0}^{\\infty} \\int_0^{2\\pi} \\frac{1}{\\pi \\sigma^2} \\exp\\left(-\\frac{r^2}{\\sigma^2}\\right) r dr d\\theta\\\\\n& = \\left[ \\exp\\left(-\\frac{r^2}{\\sigma^2}\\right) \\right]_0^{\\infty} = 1,  \n\\end{align*}\\]\ncomme souhait√©. 1. Si \\(\\phi : \\mathbb{R} \\to \\mathbb{R}_+\\) est bor√©lienne\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(X)] & =  \\int_{\\mathbb{R}^2} \\phi(x) f(x,y) dx dy \\\\\n& =  \\int_{\\mathbb{R}_+} \\phi(x) \\frac{4}{\\pi \\sigma^2} \\exp\\left(-\\frac{x^2}{\\sigma^2}\\right) \\int_{-x}^x \\exp\\left(-\\frac{y^2}{\\sigma^2}\\right) dy dx\n\\end{align*}\\]\nOn d√©duit que \\(X\\) poss√®de la densit√© \\(f_X\\) telle que \\[f_X(x) =  \\frac{4}{\\pi \\sigma^2} \\exp\\left(-\\frac{x^2}{\\sigma^2}\\right) \\int_{-x}^x \\exp\\left(-\\frac{y^2}{\\sigma^2}\\right) dy \\mathbf{1}_{\\{x \\ge 0\\}}\\]\nRemarque : Avec \\(\\mathrm{erf}(x) = \\int_{0}^x \\frac{2}{\\sqrt{\\pi}} \\exp\\left(-u^2\\right) du\\), on peut r√©exprimer\n\\[\\frac{1}{\\sigma \\sqrt{\\pi}} \\int_{-x}^x \\exp\\left(-\\frac{y^2}{\\sigma^2}\\right) dy =  \\mathrm{erf}\\left(\\frac{x}{\\sigma}\\right),\\]\nde sorte que\n\\[f_X(x) =  \\frac{4}{\\sigma \\sqrt{\\pi} } \\exp\\left(-\\frac{x^2}{\\sigma^2}\\right) \\mathrm{erf}\\left(\\frac{x}{\\sigma}\\right) \\mathbf{1}_{\\{x \\ge 0\\}}\\]\nToujours pour \\(\\phi: \\mathbb{R} \\to \\mathbb{R}_+\\) bor√©lienne, on a\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(Y)] & =  \\int_{\\mathbb{R}^2} \\phi(y) f(x,y) dx dy \\\\\n& =  \\int_{\\mathbb{R}} \\phi(y) \\frac{4}{\\pi \\sigma^2} \\exp\\left(-\\frac{y^2}{\\sigma^2}\\right) \\int_{|y|}^{\\infty} \\exp\\left(-\\frac{x^2}{\\sigma^2}\\right) dx dy\n\\end{align*}\\]\nOn d√©duit que \\(Y\\) poss√®de la densit√© \\(f_Y\\) telle que \\[f_Y(y) =  \\frac{4}{\\pi \\sigma^2} \\exp\\left(-\\frac{y^2}{\\sigma^2}\\right) \\int_{|y|}^{\\infty} \\exp\\left(-\\frac{x^2}{\\sigma^2}\\right) dx \\]\nRemarque : On a \\[\\int_{|y|}^{\\infty} \\frac{2}{\\sqrt{\\pi}} \\exp\\left(-u^2\\right) du = \\frac{1}{2}(1 - \\mathrm{erf}(|y|))= \\frac{1}{2}\\mathrm{erfc}(|y|)\\] et donc \\[\\int_{|y|}^{\\infty} \\frac{1}{\\sigma \\sqrt{\\pi}} \\exp \\left( -\\frac{x^2}{\\sigma^2} \\right)  dx  = \\frac{1}{2}\\mathrm{erfc}\\left(\\frac{|y|}{\\sigma}\\right),\\]\nde sorte que \\[ f_Y(y) =  \\frac{2}{ \\sigma \\sqrt{\\pi}} \\exp\\left(-\\frac{y^2}{\\sigma^2}\\right)  \\mathrm{erfc}\\left(\\frac{|y|}{\\sigma}\\right).\\] Enfin puisque par exemple \\(\\mathbb{P}(X \\ge Y \\ge 1) =\\mathbb{P}(Y \\ge 1)\\) on a \\(\\mathbb{P}(X \\ge 1, Y \\ge 1) \\ne \\mathbb{P}(X \\ge 1) \\mathbb{P}(Y \\ge 1)\\) et les variables \\(X\\) et \\(Y\\) ne sont pas ind√©pendantes.\n\nSoit \\(\\psi : \\mathbb{R}^2 \\to \\mathbb{R}_+\\) bor√©lienne, on a \\[\\begin{align*}\n\\mathbb{E}[\\psi(X-Y,X+Y)] & =  \\int_{\\mathbb{R}^2} \\psi(x-y,x+y) f(x,y) dx dy \\\\\n& =  \\int_{\\mathbb{R}^2} \\psi(x-y,y+y)  \\frac{4}{\\pi \\sigma^2} \\exp\\left(-\\frac{x^2+y^2}{\\sigma^2}\\right)  \\mathbf{1}_{\\{x \\ge |y|\\}}\n\\end{align*}\\]\n\nNotons que \\(G: \\begin{cases} & \\{(x,y) \\in \\mathbb{R}^2 : x \\ge |y|\\} \\to \\{(u,v) \\in \\mathbb{R}_+^2\\} \\\\ & (x,y) \\to (u,v) =(x+y,x-y) \\end{cases}\\) est un \\(\\mathcal{C}^1\\)-diff√©omorphisme (d‚Äôinverse \\(G^{-1} : (u,v) \\to (x,y)\\) avec \\(x = \\frac{u+v}{2}, y = \\frac{u-v}{2}\\)), de jacobien \\(2\\). Par la formule de changement de variables, et en remarquant que \\(u^2 + v^2 = 2(x^2+y^2)\\), on obtient\n\\[\\begin{align*}\n\\mathbb{E}[\\psi(X-Y, X+Y)]\n& = \\int_{\\mathbb{R}_+^2}  \\psi(u,v) \\frac{2}{\\pi \\sigma^2} \\exp\\left(-\\frac{u^2 + v^2}{2\\sigma^2}\\right)  du dv \\\\\n& =  \\int_{\\mathbb{R}^2} \\psi(u,v) f_U(u) f_V(v) du dv\n\\end{align*}\\]\navec \\[f_U(u) = f_V(u) = \\frac{2}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2\\sigma^2} \\right) \\mathbf{1}_{\\{u \\ge 0\\}},\\] qui est la densit√© de \\(|Z|\\) o√π \\(Z \\sim \\mathcal{N}(0,1)\\).\nOn conclut que \\((X+Y, X-Y)\\) sont i.i.d. suivant la loi de \\(|Z|\\).\n\n\n\n\nExercice 21\n\nSoit \\(X_1,...,X_n\\) des variables i.i.d, \\(\\sim \\mathcal{N}(0,1)\\), et \\(Z=\\sum_{i=1}^n \\alpha_i X_i\\) (o√π les \\(\\alpha_i, i=1,...,n\\) sont de r√©√©ls fix√©s). Quelle est la loi de \\(Z\\)?\nSoit \\((X_1,...,X_n) \\sim \\mathcal{N}(0,A)\\). Quelle est la loi de \\(Z=\\sum_{i=1}^n \\alpha_i X_i\\)?\nSoit \\((X_1,...,X_n) \\sim \\mathcal{N}(0,A)\\). Quelle est la loi de \\((Z_1,Z_2)\\), o√π, pour des r√©√©ls \\(\\alpha_{i,1}, \\alpha_{i,2}, i=1,...,n\\) fix√©s, \\[  Z_1=\\sum_{i=1}^n \\alpha_{i,1} X_i,  Z_2=\\sum_{i=1}^n \\alpha_{i,2} X_i.\\]\nG√©n√©raliser la question pr√©c√©dente en exprimant la loi de \\[ (Z_1,...,Z_n) =  (X_1,...,X_n) P,\\] o√π \\(P\\) est une matrice \\(n \\times n\\).\nSoient \\(X,Y\\) deux variables ind√©pendantes, \\(\\sim \\mathrm{Unif}[0,1]\\). Quelle est la loi de \\(S=X+Y\\)?\nSoient \\(X, Y\\) des variables ind√©pendantes de loi respectives \\(\\Gamma(a,c), \\Gamma(b,c)\\), o√π \\(a,b,c&gt;0\\). On pose \\(S=X+Y,\nT= \\frac{X}{X+Y}\\) Quelle est la loi du couple \\((S,T)\\)?\nSoient \\(X,Y\\) deux variables ind√©pendantes, \\(\\sim \\mathrm{Unif}[0,1]\\). On pose \\(U = \\sqrt{-2\\log(X)} \\cdot \\cos(2\\pi Y), V = \\sqrt{-2\\log(X)} \\cdot \\sin(2\\pi Y)\\). Quelle est la loi du couple \\((X,Y)\\)?\nSoient \\(X,Y\\) deux variables ind√©pendantes, \\(\\sim \\mathcal{N}(0,1)\\). On pose \\(T = \\frac{Y}{X}\\). Quelle est la loi de \\(T\\)?\nSoient \\((X,Y)\\) un couple de variables ind√©pendantes, \\(\\sim \\mathcal{N}(0,1)\\). On pose \\(U=X, V= X^2 + Y^2\\). Quelle est la loi de \\((U,V)\\)?\nSoit \\(X\\) de densit√© \\(\\exp(-x) \\mathbf{1}_{\\mathbb{R}_+}(x)\\). On pose \\(U = [X]\\) et \\(V= X-[X]\\), la partie enti√®re, resp. la partie d√©cimale de \\(X\\). Quelle est la loi de \\((U,V)\\)?\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nEn utilisant d‚Äôabord l‚Äôind√©pendance des \\((X_k, 1 \\le k \\le n)\\) √† la deuxi√®me ligne ci-dessous, puis le fait que \\(\\Phi_{X_k}(u) =\\exp(-u^2/2)\\) √† la suivante, on obtient que pour \\(t \\in \\mathbb{R}\\),\n\n\\[\\begin{align*}\n\\Phi_{Z}(t) & =  \\mathbb{E}\\left[\\exp\\left(it \\sum_{k=1}^n \\alpha_k X_k \\right) \\right] \\\\\n& =  \\prod_{k=1}^n \\Phi_{X_k}(t \\alpha_k) \\\\\n& =  \\exp\\left( - \\frac{t^2}{2} \\sum_{k=1}^n \\alpha_k^2 \\right)\n\\end{align*}\\]\net on d√©duit que \\(Z \\sim \\mathcal{N}\\left(0, \\sum_{k=1}^n \\alpha_k^2\\right)\\). 1. Lorsque \\(X\\) est un vecteur gaussien, toute combinaison lin√©aire des coordonn√©es de \\(X\\) suit une loi gaussienne. Comme les coordonn√©es de \\(X\\) sont ici centr√©es, il en va de m√™me pour \\(Z\\). Par ailleurs\n\\[\\begin{align*}\n\\mathrm{Var}(Z)\n& = \\sum_{k=1}^n \\sum_{\\ell=1}^n \\alpha_k \\alpha_{\\ell} \\mathrm{Cov}(X_k, X_{\\ell}) \\\\\n& = \\alpha^T A \\alpha.\n\\end{align*}\\]\nFinalement \\(Z \\sim \\mathcal{N}(0,\\alpha^T A \\alpha)\\), autrement dit \\[\\Phi_Z(t) = \\exp\\left(-t^2\\frac{\\alpha^T A \\alpha}{2} \\right).\\]\n1. Soit \\((u,v) \\in \\mathbb{R}^2\\), on a \\[uZ_1+vZ_2 = \\sum_{i=1}^n (\\alpha_{i,1} + v \\alpha_{i,2}) X_i,\\] et d‚Äôapr√®s la question pr√©c√©dente, ceci est distribu√© suivant une loi \\(\\mathcal{N}(0, (u \\alpha_1 + v \\alpha_2)^T A (u\\alpha_1+v \\alpha_2))\\), et donc\n\\[\\Phi_{uZ_1+vZ_2}(1) = \\mathbb{E}[\\exp (iu Z_1+ivZ_2)] = \\Phi_{(Z_1,Z_2)}(u,v) = \\exp\\left( - \\frac{(u\\alpha_1+ v \\alpha_2)^T A (u \\alpha_1+v\\alpha_2)}{2} \\right).\\] Reste √† observer que \\(u\\alpha_1+v\\alpha_2\\) est le produit d‚Äôune matrice, disons \\(P\\) √† \\(n\\) lignes et deux colonnes, la premi√®re ayant les coordonn√©es de \\(\\alpha_1\\) la deuxi√®me celle de \\(\\alpha_2\\), par le vecteur \\(\\begin{pmatrix} u \\\\ v \\end{pmatrix}\\). On conclut que \\(Z \\sim \\mathcal{N}(0, P^T A P)\\)\n\nLa matrice \\(P\\) joue le m√™me r√¥le que la matrice de la question pr√©c√©dent (√† ceci pr√®s qu‚Äôelle poss√®de d√©sormais \\(n\\) lignes et \\(n\\) colonnes). Par le m√™me raisonnement qu‚Äô√† la question pr√©c√©dente, on trouve que \\(Z \\sim \\mathcal{N}(0,P^T A P)\\).\n\nPuisque \\(X\\) et \\(Y\\) sont ind√©pendantes et √† densit√©, \\((X,Y)\\) poss√®de la densit√© jointe \\(f_{(X,Y)}\\) telle que \\(f_{(X,Y)}(x,y) = f_X(x) f_Y(y)\\). On a donc pour \\(\\phi: \\mathbb{R}^2 \\to \\mathbb{R}_+\\) bor√©lienne,\n\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(X+Y)] & =  \\int_{[0,1]^2} \\phi(x+y) \\mathrm{d}x \\mathrm{d}y\n\\end{align*}\\]\nOn fait le changement de variables \\(\\begin{cases} & [0,1]^2 \\to \\{(s,t) \\in [0,2] \\times [0,1] :  t+1 \\ge s \\ge t \\} \\\\ & (x,y) \\to ( s=x+y, t=y) \\end{cases}\\), de jacobien \\(1\\), et on trouve\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(X+Y)]\n& =  \\int_{0}^2 ds \\phi(s) \\int_{\\max(s-1,0)}^{\\min(s,1)} \\mathrm{d}t\\\\\n& =   \\int_0^2 \\phi(s) \\min(s, 1-s) \\mathrm{d}s\n\\end{align*}\\]\net on d√©duit que \\(S\\) poss√®de la densit√© \\(f_S\\), o√π \\[f_S(s) = \\begin{cases} & s \\mbox{ si } 0 \\le s \\le 1 \\\\ & (1-s) \\mbox{ si } 1 \\le s \\le 2 \\\\ & 0 \\mbox{ sinon.} \\end{cases}\\]\n\nD‚Äôapr√®s l‚Äô√©nonc√©, \\((X,Y)\\) poss√®de la densit√©\n\\[f_{(X,Y)}(x,y) = \\frac{c^{a+b}}{\\Gamma(a)\\Gamma(b)} x^{a-1} y^{b-1} \\exp(-c(x+y)) \\mathbf{1}_{\\{x &gt; 0, y &gt; 0\\}}.\\] Pour \\(\\phi : \\mathbb{R}^2 \\to \\mathbb{R}_+\\) bor√©lienne on a donc \\[\\mathbb{E}[\\phi(S,T)] = \\int_{(\\mathbb{R}_+^*)^2} \\phi\\left(x+y, \\frac{x}{x+y}\\right)   \\frac{c^{a+b}}{\\Gamma(a)\\Gamma(b)} x^{a-1} y^{b-1} \\exp(-c(x+y)) dx dy \\] On effectue alors le changement de variables via le \\(\\mathcal{C}^1\\)-diff√©omorphisme :\n\\[G : \\begin{cases} & (\\mathbb{R}_+^*)^2 \\to \\mathbb{R}_+^* \\times (0,1) \\\\ & (x,y) \\to \\left(x+y, \\frac{x}{x+y}\\right) \\end{cases}\\] d‚Äôinverse \\[G^{-1} : \\begin{cases} &  \\mathbb{R}_+^* \\times (0,1)  \\to (\\mathbb{R}_+^*)^2  \\\\ & (s,t) \\to (st, s(1-t) \\end{cases}\\] dont le jacobien est \\(|J^{-1}| = s\\), pour obtenir \\[\\mathbb{E}[\\phi(S,T)]  =  \\int_{\\mathbb{R}_+^*} ds \\int_0^1 dt  \\phi(s,t)   \\frac{c^{a+b}}{\\Gamma(a)\\Gamma(b)} s^{a+b-1}  \\exp(-c s) t^{a-1}(1-t)^{b-1} \\] et on conclut que \\(S \\sim \\mathrm{Gamma}(a+b,c)\\) est ind√©pendant de \\(T \\sim \\mathrm{Beta}(a,b)\\).\nL‚Äôapplication \\[\\Psi : \\begin{cases}  & [0,1]^2 \\to \\mathbb{R}^2  \\\\ & (x,y) \\to (u,v) = \\left(\\sqrt{-2\\ln(x)} \\cos(2\\pi v),  \\sqrt{-2\\ln(x)} \\sin(2\\pi y)\\right) \\end{cases}\\] est un \\(\\mathcal{C}^1\\)-diff√©omorphisme, compos√©e de \\((x,y) \\to (r,\\theta) = (\\sqrt{-2\\ln(x)},2\\pi y)\\) et \\((r, \\theta) \\to (u,v) = (r \\cos(\\theta), r \\sin(\\theta))\\). Le Jacobien de \\(\\Psi\\) est \\(2\\pi \\exp((u^2+v^2)/2)\\) et on d√©duit que pour \\(\\phi\\) continue born√©e de \\(\\mathbb{R}^2\\) dans \\(\\mathbb{R}\\), \\[\\begin{align*}\n\\mathbb{E}[\\phi(U,V)] & =  \\int_{0}^1 \\int_0^1 dx dy \\phi \\left(\\sqrt{-2\\ln(x)} \\cos(2\\pi y), \\sqrt{-2\\ln(x)} \\sin(2\\pi y)\\right) \\\\ & =  \\int_{\\mathbb{R}^2} du dv \\phi(u,v) \\frac{1}{2\\pi} \\exp(-u^2/2) \\exp(-v^2/2),\n\\end{align*}\\]\n\net finalement que \\((U,V) \\sim \\mathcal{N}(0,I_2)\\).\n\nNotons d‚Äôabord que \\(\\mathbb{P}(X=0)=0\\) de sorte que \\(Z\\) est d√©finie p.s. Par ailleurs \\((X,Y) \\sim \\mathcal{N}(0,Id_2)\\) et a la densit√© correspondante.\n\nOn a, pour \\(\\phi: \\mathbb{R}^2 \\to \\mathbb{R}\\) born√©e mesurable, gr^ace au changement de variables de \\(\\mathbb{R}^* \\times \\mathbb{R}^*\\) dans lui-m√™me, qui √† \\((x,y)\\) associe \\((x,z)=(x,\\frac{y}{x})\\) (et dont l‚Äôinverse du jacobien vaut \\(|x|\\)) :\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(X,Z)]\n& = \\frac{1}{2\\pi} \\int_{(\\mathbb{R}^*)^2} \\phi(x, \\frac{y}{x}) \\exp(-x^2/2-y^2/2) dx dy \\\\\n& = \\frac{1}{2\\pi} \\int_{(\\mathbb{R}^*)^2} \\phi(x, z) |x| \\exp\\left(-\\frac{x^2}{2} (1+z^2 \\right) dx \\mathrm{d}z   \n\\end{align*}\\]\net donc \\((X,Z)\\) a densit√©\n\\[f_{(X,Z)}(x,z) = \\frac{1}{2\\pi}  |x| \\exp\\left(-\\frac{x^2}{2} (1+z^2)\\right).\\]\nOn en d√©duit que\n\\[\\begin{align*}\nf_Z(z) & =  2 \\int_{\\mathbb{R}_+} \\frac{1}{2\\pi}  x z^2 \\exp\\left(-\\frac{x^2}{2} (1+z^2)\\right) dx = \\frac{1}{\\pi} \\frac{1}{1+z^2},\n\\end{align*}\\]\nde sorte que \\(Z \\sim \\mathrm{Cauchy}(1)\\).\n\nQuitte √† consid√©rer les \\(\\mathcal{C}^1\\)-diff√©omorphisme\n\\[G : \\begin{cases} & \\mathbb{R} \\times \\mathbb{R}_-^* \\to \\{(u,v) \\in \\mathbb{R} \\times \\mathbb{R}_+^* : v \\ge u^2\\} \\\\ (x,y) \\to (x, x^2+y^2) \\end{cases}, \\ H: \\begin{cases} & \\mathbb{R} \\times \\mathbb{R}_+ \\to \\{(u,v) \\in \\mathbb{R} \\times \\mathbb{R}_+^* : v \\ge u^2\\} \\\\ (x,y) \\to (x, x^2+y^2) \\end{cases},\\]\ndont les jacobiens sont tous deux √©gaux √† \\(2|y| = 2 \\sqrt{u-v^2}\\), on obtient pour \\(\\phi : \\mathbb{R}^2 \\to \\mathbb{R}_+\\) bor√©lienne (les deux int√©grales fournissent des contributions identiques) :\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(U,V)]  \n&  =  2 \\int_{\\mathbb{R} \\times \\mathbb{R}_+} \\phi(u,v) \\frac{\\exp\\left(-\\frac{v}{2}\\right)}{4 \\pi \\sqrt{u-v^2}} \\mathbf{I}_{\\{v \\ge u^2\\}}du dv\n\\end{align*}\\]\net on conclut que \\((U,V)\\) poss√®de la densit√© \\(f_{(U,V)}\\) telle que pour tout \\((u,v) \\in \\mathbb{R}^2\\),\n\\[f_{(U,V)}(u,v) = \\frac{\\exp\\left(-\\frac{v}{2}\\right)}{2 \\pi \\sqrt{u-v^2}} \\mathbf{I}_{\\{v \\ge u^2\\}}.\\]\nRemarque : On peut recalculer √† partir de cette densit√© les marginales, mais il est √©vident que \\(X \\sim \\mathcal{N}(0,1)\\), et on avait vu plus haut que \\(X^2+Y^2 \\sim \\exp(1/2)\\).\nOn a pour \\(\\phi : \\mathbb{R}^2 \\to \\mathbb{R}_+\\) bor√©lienne\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(U,V)]\n& =  \\int_{\\mathbb{R}_+} \\phi( [x], x-[x])  \\exp(-x) dx \\\\\n& =  \\sum_{n \\ge 0} \\int_n^{n+1} \\phi(n, x-n) \\exp(-x) dx \\\\\n& =  \\sum_{n \\ge 0} \\int_0^1 \\phi(n,v) \\exp(-n) \\exp(-v) du\n\\end{align*}\\]\nSi \\(g : \\mathbb{R} \\to \\mathbb{R}_+\\), \\(h : \\mathbb{R} \\to \\mathbb{R}_+\\) bor√©liennes, quitte √† consid√©rer \\(\\phi(u,v) = g(u) h(v)\\) on obtient\n\\[\\begin{align*}\n\\mathbb{E}[g(U) h(V)]\n& =  \\sum_{n \\ge 0} g(n) \\exp(-1)^n (1-\\exp(-1)) \\int_0^1 h(v) \\frac{\\exp(-v)}{1-\\exp(-1)} du \\\\  \n& =  \\mathbb{E}[g(U)] \\mathbb{E}[h(V)]  \n\\end{align*}\\]\nOn conclut que \\(U\\) et \\(V\\) sont ind√©pendantes, avec \\(U + 1 \\sim  \\mathrm{Geom}(1-\\exp(-1))\\) et \\(V\\) de densit√© \\(f_V\\) avec, pour tout \\(v\\in \\mathbb{R}\\),\n\\[f_V(v) = \\frac{1}{1-\\exp(-1)} \\exp(-v) \\mathbf{1}_{(0,1)}(v).\\]\nRemarque : La loi de \\(V\\) est celle d‚Äôune variable exponentielle de param√®tre \\(1\\) conditionn√©e √† √™tre plus petite que \\(1\\).\n\n\n\n\n\nExercice 22\nSoient \\(X_1, X_2\\) deux variables ind√©pendantes et identiquement distribu√©es suivant la loi \\(\\mathrm{Unif}\\{1,2,3\\}\\).\nOn note \\(U = \\min\\{X_1,X_2\\}\\), \\(V= \\max\\{X_1,X_2\\}\\) et enfin \\(S= U+V\\).\n\nD√©terminer la loi jointe de \\((U, V)\\) et \\((V, S)\\).\nEn d√©duire les lois de \\(U, V\\), et \\(S\\). Calculer les lois de \\(UV\\) et \\(VS\\).\nCalculer les covariances et les coefficients de corr√©lation de \\((U, V)\\) et \\((V, S)\\).\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nPar hypoth√®se, la loi de \\((X_1,X_2)\\) est uniforme sur \\(\\{1,2,3\\}^2\\), et on d√©duit, quitte √† disjoindre les cas, que\n\\[\\begin{align*}\n& \\mathbb{P}((U,V) =(1,1)) = \\mathbb{P}(X_1=1, X_2=1) = 1/9 \\\\  \n& \\mathbb{P}((U,V)=(1,2)) = \\mathbb{P}(X_1=1,X_2=2) + \\mathbb{P}(X_1=2,X_2=1) = 2/9 \\\\\n& \\mathbb{P}((U,V) = (1,3)) =  \\mathbb{P}(X_1=1,X_2=3) + \\mathbb{P}(X_1=3,X_2=1) = 2/9 \\\\\n& \\mathbb{P}((U,V) = (2,2)) = \\mathbb{P}(X_1=2, X_2=2) = 1/9 \\\\  \n& \\mathbb{P}((U,V)=(2,3)) = \\mathbb{P}(X_1=2,X_2=3) + \\mathbb{P}(X_1=3,X_2=2) = 2/9 \\\\\n& \\mathbb{P}((U,V)=(3,3)) = \\mathbb{P}(X_1=3,X_2=3) = 1/9\n\\end{align*}\\]\nLa m√™me disjonction de cas conduit √† la loi de \\((V,S)\\) :\n\\[\\begin{align*}\n& \\mathbb{P}(V=1,S=2) = 1/9 \\\\  \n& \\mathbb{P}(V=2,S=3) = 2/9 \\\\  \n& \\mathbb{P}(V=3,S=4) = 2/9 \\\\\n& \\mathbb{P}(V=2,S=4) = 1/9 \\\\\n& \\mathbb{P}(V=3, S=5) = 2/9 \\\\  \n& \\mathbb{P}(V=3, S=6) = 1/9  \n\\end{align*}\\]\nOn en d√©duit (on peut √©galement faire un raisonnement direct)\n\\[\\begin{align*}\n& \\mathbb{P}(U=1) = 5/9, \\ \\mathbb{P}(U=2)=1/3, \\ \\mathbb{P}(U=3)=1/9 \\\\  \n& \\mathbb{P}(V=1) = 1/9, \\ \\mathbb{P}(V=2) = 1/3,\\ \\mathbb{P}(V=3)=5/9 \\\\\n& \\mathbb{P}(S=2) = \\mathbb{P}(S=6) = 1/9, \\ \\mathbb{P}(S=3)=\\mathbb{P}(S=5) = 2/9. \\ \\mathbb{P}(S=4)=1/3\n\\end{align*}\\]\nLa loi de \\(UV\\) se d√©duit facilement de la loi jointe de \\((U,V)\\) calcul√©e √† la question pr√©c√©dente\n\\[\\mathbb{P}(UV=1) = \\mathbb{P}(UV=4) = pp(UV=9) = 1/9, \\ \\mathbb{P}(UV=2) = \\mathbb{P}(UV=3) = \\mathbb{P}(UV=6) = 2/9.\\]\n\nDe m√™me pour la loi de \\(VS\\)\n$$\\mathbb{P}(VS=2) = \\mathbb{P}(VS=8) = \\mathbb{P}(VS=18) = 1/9, \\ \\mathbb{P}(VS=6) = \\mathbb{P}(VS=12) = \\mathbb{P}(VS=15) = 2/9$$ \n\nOn d√©duit de la question pr√©c√©dente\n\\[\\mathbb{E}[U]=\\frac{14}{9}, \\ \\mathbb{E}[V]=\\frac{22}{9}, \\ \\mathbb{E}[UV]=4,\\ \\mathrm{Cov}(U,V) = \\frac{16}{81},\\]\net\n\\[\\mathrm{Var}(U) = \\frac{38}{81} = \\mathrm{Var}(V), \\ \\ \\rho(U,V)= \\frac{8}{19}.\\]\nPar ailleurs\n\\[\\mathbb{E}[V]= \\frac{22}{9}, \\ \\mathbb{E}[S]=4, \\ \\mathbb{E}[VS]=\\frac{94}{9}, \\ \\mathrm{Cov}(V,S) = \\frac{2}{3}.\\]\net\n\\[\\mathrm{Var}(V) = \\frac{38}{9}, \\mathrm{Var}(S) = \\frac{2}{3}, \\rho(V,S) \\approx 0.397\\]"
  },
  {
    "objectID": "corriges/td1.html#le-cadre-gaussien",
    "href": "corriges/td1.html#le-cadre-gaussien",
    "title": "Variables al√©atoires r√©elles",
    "section": "Le cadre gaussien",
    "text": "Le cadre gaussien\n\nExercice 23\nOn consid√®re deux variables ind√©pendantes \\(Y \\sim \\mathcal{N}(0,1)\\) et\n\\[\\varepsilon= \\begin{cases} & 1 \\mbox{ avec probabilit√© } p \\\\ & -1 \\mbox{ avec probabilit√© } 1-p, \\end{cases}\\]\no√π \\(p \\in (0,1)\\).\n\nQuelle est la loi de \\(Z= \\varepsilon Y\\)\nQuelle est la loi de \\(Y+Z\\)?\nLe vecteur \\((Y,Z)\\) est-il un vecteur gaussien?\n\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nSoit \\(\\phi : \\mathbb{R} \\to \\mathbb{R}_+\\) bor√©lienne\n\\[\\begin{align*}\n\\mathbb{E}[\\phi(\\varepsilon)]\n& =  \\mathbb{E}[\\phi(Y) \\mathbf{1}_{\\varepsilon=1}] + \\mathbb{E}[\\phi(-Y) \\mathbf{1}_{\\varepsilon=-1}]  \\\\\n& =  p \\mathbb{E}[\\phi(Y)] + (1-p) \\mathbb{E}[\\phi(-Y)] \\\\\n& =  p \\int_{\\mathbb{R}} \\phi(z) \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2) \\mathrm{d}z + (1-p) \\int_{\\mathbb{R}} \\phi(-z) \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2) \\mathrm{d}z  \\\\\n& =  \\int_{\\mathbb{R}} \\phi(z) \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2) \\mathrm{d}z\n\\end{align*}\\]\no√π on a effectu√© le changement de variables \\(u=-z\\) pour voir que \\(\\int_{\\mathbb{R}} \\phi(-z) \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2) \\mathrm{d}z = \\int_{\\mathbb{R}} \\phi(u) \\frac{1}{\\sqrt{2\\pi}} \\exp(-u^2/2) du\\). On conclut que \\(Z \\sim \\mathcal{N}(0,1)\\).\nOn a $Y+Z = (1+et donc pour \\(\\phi\\) comme ci-dessus\n\\[\\mathbb{E}[\\phi(Y+Z)] = (1-p)\\phi(0) + p\\int_{\\mathbb{R}} \\phi(u) \\frac{1}{2 \\sqrt{2\\pi}} \\exp(-u^2/8) du.\\]\nEn particulier la loi de \\(Y+Z\\) n‚Äôest ni discr√®te ni √† densit√©, donc pas gaussienne.\nNon, puisque \\(Y+Z\\) n‚Äôest pas gaussienne.\n\n\n\n\n\nExercice 24\nSoit \\((X,Y,Z)\\) le vecteur al√©atoire gaussien d‚Äôesp√©rance \\((1,1,0)\\) et de matrice de covariance\n\\[K = \\begin{pmatrix} 2 & 1 & 1 \\\\ 1 & 2 & 2 \\\\ 1 & 2 & 2  \\end{pmatrix}.\\]\n\nEcrire la fonction caract√©ristique de \\((X,Y,Z)\\).\n\nTrouver la loi de \\(2X+Y+Z\\), de \\(4X-2Y+Z\\), enfin de \\(Y-Z\\).\nLe vecteur \\((X,Y)\\) admet-il une densit√© dans \\(\\mathbb{R}^2\\). Si oui, laquelle?\nPour \\(a \\in \\mathbb{R}\\) on d√©finit \\(u_a : \\mathbb{R}^3 \\to \\mathbb{R}^3\\) de matrice\n\\[A = \\begin{pmatrix} 1/\\sqrt{2} & 0 & 0 \\\\ a & -2a & 0 \\\\ 0 & 1 & -1\\end{pmatrix}.\\]\nD√©terminer la loi de \\(u_a(X-1,Y-1,Z)\\) en fonction de \\(a\\).\nPour quelle valeur de \\(a\\) les deux premi√®res coordonn√©es de \\(u_a(X-1,Y-1,Z)\\) suivent-ils une loi normale centr√©e r√©duite sur \\(\\mathbb{R}^2\\)?\n\n\n\n\n\n\n\nNoteSolution\n\n\n\nDans les questions 2,3,4 ci-dessous, on fait usage de la Prop 3 du cours : si \\(V \\sim \\mathcal{N}(m,K)\\) est un vecteur gaussien de dimension \\(d\\) et \\(P\\) est une matrice √† \\(p\\) lignes et \\(d\\) colonnes, on a \\(X \\sim \\mathcal{N}(Pm, P K P^T)\\). Ici \\(d=3\\), \\(m\\) est le vecteur de coordonn√©es \\((1,1,0)\\), et \\(K\\) la matrice pr√©cis√©e dans l‚Äô√©nonc√©.\n\nD‚Äôapr√®s le cours (Prop 2), pour tout \\(t \\in \\mathbb{R}^3\\) de coordonn√©es \\((t_1,t_2,t_3)\\),\n\\[\\begin{align*}\n\\Phi_X(t)\n& = \\exp(it^Tm + PKP^T) \\\\  \n&  =  \\exp\\bigg(i(t_1+t_2) - (t_1^2+t_2^2+t_3^2+t_1 t_2+t_1 t_3+2t_2 t_3)\\bigg)\n\\end{align*}\\]\nOn applique le r√©sultat g√©n√©ral avec \\(P = (2 \\ \\ 1 \\ \\ 1)\\) puis avec \\(P=(4 \\ -2 \\ \\ 1)\\), et enfn avec \\(P=(0 \\ \\ 1 \\ -1)\\) pour obtenir\n\\[2X+Y+Z \\sim \\mathcal{N}(3,24), \\quad 4X-2Y+Z \\sim \\mathcal{N}(2, 26), \\quad Y-Z \\sim \\mathcal{N}(1,0)\\]\nDans le troisi√®me cas notons que \\(\\mathbb{P}(Y-Z = 1)=1\\), de sorte que \\(Y-Z\\) n‚Äôa pas de densit√©.\nOn a \\(\\begin{pmatrix} X \\\\ Y \\end{pmatrix} \\sim \\mathcal{N} \\left( \\mu=\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\Sigma = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}\\right)\\). On a \\(\\det(\\Sigma)=3\\), et est \\(\\Sigma^{-1} = \\frac{1}{3} \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix}\\), et donc ce vecteur poss√®de la densit√© \\(f\\) sur \\(\\mathbb{R}^2\\), o√π pour \\(x \\in \\mathbb{R}^2\\) de coordonn√©es \\((x_1,x_2)\\),\n\\[\\begin{align*}\nf(x)\n& =  \\frac{1}{2\\pi\\sqrt{3}} \\exp(-\\frac{1}{2} (x-\\mu)^T \\Sigma^{-1} (x-\\mu) \\\\\n& =  \\frac{1}{2 \\pi \\sqrt{3}} \\exp\\left(-\\frac{1}{3} ((x_1-1)^2 + (x_2-1)^2 - (x_1-1)(x_2-1)) \\right)\n\\end{align*}\\]\nOn obtient ici que\n\\[A \\begin{pmatrix} X \\\\ Y \\\\ Z \\end{pmatrix} \\sim \\mathcal{N} \\left( \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 6a^2 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\right),\\]\nde sorte qu‚Äôon a le r√©sultat souhait√© pour \\(a \\in \\left\\{-\\frac{1}{\\sqrt{6}}, \\frac{1}{\\sqrt{6}} \\right\\}\\)\n\n\n\n\n\nExercice 25\nSoit \\(\\rho\\in ]-1,1[\\) et \\((X,Y)\\) un vecteur gaussien centr√© de matrice de covariances \\(M = \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix}\\). On notera \\(\\sigma = \\sqrt{1-\\rho^2}\\).\n\nCalculer det(\\(M\\)), \\(M^{-1}\\), puis exprimer la densit√© \\(f_{(X,Y)}\\) du vecteur \\((X,Y)\\).\nMontrer que\n\\[g_x(y) := \\frac{f_{(X,Y)}(x,y)}{f_X(x)} = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp \\left( - \\frac{1}{2(1-\\rho^2)} \\left(y-\\rho x\\right)^2\\right).\\]\nMontrer que pour tout \\(x \\in \\mathbb{R}\\), \\(y \\to g_x(y)\\) d√©finit une densit√©.\nSi on note \\(Y_x\\) une variable de densit√© \\(g_x\\), que pouvez-vous dire sur la loi de \\(Y_x\\)?\n\nTrouver \\(\\alpha\\), \\(\\beta\\) deux r√©els tels que \\((X, \\alpha X + \\beta Y)\\) suit la loi normale centr√©e r√©duite.\n\nRemarquer que l‚Äôon peut √©crire \\(Y= -\\frac{\\alpha}{\\beta} X +\\frac{1}{\\beta}(\\alpha X + \\beta Y)\\). Sauriez-vous dire pourquoi cette √©criture est int√©ressante?\n\n\n\n\n\n\nNoteSolution\n\n\n\n\nOn a \\(\\det(M) = 1-\\rho^2 \\ne 0\\), \\(M^{-1} =  \\frac{1}{1-\\rho^2}  \\begin{pmatrix} 1 & - \\rho \\\\ -\\rho & 1 \\end{pmatrix}\\), et donc \\(\\begin{pmatrix} X \\\\ Y \\end{pmatrix}\\) poss√®de la densit√© \\(f_{(X,Y)}\\) o√π, pour \\(\\begin{pmatrix} x \\\\ y \\end{pmatrix} \\in \\mathbb{R}^2\\),\n\\[\\begin{align*}\nf_{(X,Y)}(x)\n& = \\frac{1}{2\\pi \\sqrt{1-\\rho^2}} \\exp\\left(-\\frac{1}{2} \\begin{pmatrix} x \\\\ y \\end{pmatrix}^T M^{-1} \\begin{pmatrix} x \\\\ y \\end{pmatrix}  \\right)\\\\  \n& =  \\frac{1}{2\\pi \\sigma} \\exp\\left(- \\frac{1}{2 \\sigma^2} \\left(x^2 + y^2 - 2 \\rho x y \\right) \\right)\n\\end{align*}\\]\n\\(X \\sim \\mathcal{N}(0,1)\\) donc \\(f_X(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-x^2/2), x \\in \\mathbb{R}\\). On a donc, pour \\(y \\in \\mathbb{R}\\)\n\\[\\begin{align*}\ng_x(y)\n& =  \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp\\left( \\frac{1}{2(1-\\rho^2)} (x^2+y^2 - 2\\rho x y) + \\frac{1}{2} x^2 \\right) \\\\  \n& = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left( \\frac{1}{2(1-\\rho^2)} \\left( - \\frac{1}{2} (\\rho^2 x^2 - 2 \\rho x y + y ^2) \\right)\\right) \\\\\n& =   \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left( \\frac{1}{2(1-\\rho^2)} \\left( - \\frac{1}{2} (y-\\rho x)^2 \\right) \\right)\n\\end{align*}\\]\ncomme souhait√©, et donc \\(Y_x \\sim \\mathcal{N}(\\rho x, 1-\\rho^2)\\).\nComme \\(\\begin{pmatrix} X \\\\ \\alpha X + \\beta Y \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ \\alpha & \\beta \\end{pmatrix}\\) d‚Äôapr√®s Prop 3 du cours\n\\[\\begin{pmatrix} X \\\\ \\alpha X + \\beta Y \\end{pmatrix}  \\sim \\mathcal{N}\\left( \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 1 & 0 \\\\ \\alpha & \\beta \\end{pmatrix} \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ \\alpha & \\beta \\end{pmatrix}^T\\right)\\]\net donc\n\\[\\begin{pmatrix} X \\\\ \\alpha X + \\beta Y \\end{pmatrix}  \\sim \\mathcal{N}\\left( \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 1 & 0 \\\\ \\alpha & \\beta \\end{pmatrix}\\begin{pmatrix} 1 & \\alpha+\\rho \\beta \\\\ \\rho & \\rho \\alpha + \\beta \\end{pmatrix} \\right) \\sim \\mathcal{N}\\left( \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 1 & \\alpha+ \\rho \\beta \\\\ \\alpha + \\rho \\beta  & \\alpha^2 + 2 \\rho \\alpha \\beta + \\beta^2  \\end{pmatrix} \\right)\\]\nPour obtenir le r√©sultat souhait√© il faut et il suffit que \\(\\begin{cases} & \\alpha + \\rho \\beta = 0 \\\\ & \\alpha^2 + 2\\rho \\alpha \\beta + \\beta ^2 = 1 \\end{cases}\\),\nEn rempla√ßant \\(\\alpha= -\\rho \\beta\\) dans la deuxi√®me √©quation il vient que n√©cessairement\n\\[\\rho^2 \\beta^2 - 2 \\rho \\alpha \\beta + \\beta ^2  = (1-\\rho)^2 \\beta ^2 = 1,\\]\net on obtient que \\((\\alpha,\\beta) \\in \\left\\{ \\left( \\frac{\\rho}{1-\\rho}, -\\frac{1}{1-\\rho}\\right), \\left(\\frac{-\\rho}{1-\\rho},\\frac{1}{1-\\rho}\\right) \\right\\}\\)\nOn a alors, comme indiqu√© dans l‚Äô√©nonc√©\n\\[Y =  \\rho X + (1-\\rho) \\left(-\\frac{\\rho}{1-\\rho} X + \\frac{1}{1-\\rho} Y \\right),\\]\net quitte √† poser \\(Z =  -\\frac{\\rho}{1-\\rho} X + \\frac{1}{1-\\rho} Y\\) qui est une normale centr√©e r√©duite ind√©pendante de \\(X\\), on a\n\\[Y = \\rho X + (1-\\rho) Z,\\]\nqui permet de comprendre comment \\(Y\\) d√©pend de \\(X\\).\n\nLa d√©composition sera en particulier tr√®s utile pour caculer esp√©rance et loi conditionnelle de \\(Y\\) sachant \\(X\\).\n\n\n\n\nExercice 26\nMontrer que le vecteur al√©atoire de dimension \\(3\\) de moyenne \\(m = (7,0,1)\\) et de matrice de covariances\n\\[K = \\begin{pmatrix} 10 & -1 & 4 \\\\ -1 & 1 & -1 \\\\ 4 & -1 & 2 \\end{pmatrix}\\]\nappartient presque s√ªrement √† un hyperplan affine de \\(\\mathbb{R}^3\\) que l‚Äôon d√©terminera.\n\n\n\n\n\n\nNoteSolution\n\n\n\nEn r√©solvant \\(K x = 0\\) on trouve \\(\\ker(K) = \\mathrm{Vect} \\left\\{ \\begin{pmatrix} -1\\\\ 2\\\\  3 \\end{pmatrix}  \\right\\}\\). On a donc\n\\[\\ker(K)^{\\perp} = \\left\\{ (x,y,z) \\in \\mathbb{R}^3 : -x + 2y + z =0 \\right\\}\\]\nD‚Äôapr√®s le cours, \\(\\mathbb{P}(X - m \\in \\ker(K)^{\\perp}) =1\\), de sorte que p.s.\n\\[ X \\in \\left\\{  (x,y,z) \\in \\mathbb{R}^3 : -x + 2y + z = -6 \\right\\}.\\]"
  }
]